#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šç©ºåˆ†é›¢åˆ†æå™¨
å¾batch_experiment_gui.pyçš„å¯¦é©—çµæœä¸­ç”Ÿæˆåªåšå¤šå’Œåªåšç©ºçš„ç­–ç•¥å ±å‘Š
"""

import sqlite3
import csv
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LongShortSeparationAnalyzer:
    """å¤šç©ºåˆ†é›¢åˆ†æå™¨"""
    
    def __init__(self, db_path: str = "batch_experiments.db", output_subdir: Optional[str] = None):
        self.db_path = db_path
        self.base_output_dir = Path("batch_result")
        self.base_output_dir.mkdir(exist_ok=True)

        # å¦‚æœæŒ‡å®šäº†å­ç›®éŒ„ï¼Œä½¿ç”¨å­ç›®éŒ„ï¼›å¦å‰‡ç›´æ¥ä½¿ç”¨batch_result
        if output_subdir:
            self.output_dir = self.base_output_dir / output_subdir
            self.output_dir.mkdir(exist_ok=True)
        else:
            self.output_dir = self.base_output_dir
    
    def generate_separation_reports(self) -> Dict[str, str]:
        """ç”Ÿæˆå¤šç©ºåˆ†é›¢å ±å‘Š"""
        try:
            # å¾è³‡æ–™åº«æå–æ•¸æ“š
            experiments_data = self._extract_experiments_data()
            
            if not experiments_data:
                logger.warning("æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å¯¦é©—æ•¸æ“š")
                return {"success": False, "error": "æ²’æœ‰æœ‰æ•ˆçš„å¯¦é©—æ•¸æ“š"}
            
            # ç”Ÿæˆæ™‚é–“æˆ³
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ç”Ÿæˆå¤šæ–¹å ±å‘Š
            long_report_path = self._generate_long_only_report(experiments_data, timestamp)
            
            # ç”Ÿæˆç©ºæ–¹å ±å‘Š  
            short_report_path = self._generate_short_only_report(experiments_data, timestamp)
            
            logger.info(f"âœ… å¤šç©ºåˆ†é›¢å ±å‘Šç”Ÿæˆå®Œæˆ")
            logger.info(f"ğŸ“Š å¤šæ–¹å ±å‘Š: {long_report_path}")
            logger.info(f"ğŸ“Š ç©ºæ–¹å ±å‘Š: {short_report_path}")
            
            return {
                "success": True,
                "long_report": str(long_report_path),
                "short_report": str(short_report_path),
                "record_count": len(experiments_data)
            }
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤šç©ºåˆ†é›¢å ±å‘Šå¤±æ•—: {e}")
            return {"success": False, "error": str(e)}
    
    def _extract_experiments_data(self) -> List[Dict[str, Any]]:
        """å¾è³‡æ–™åº«æå–å¯¦é©—æ•¸æ“š"""
        experiments = []
        
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT experiment_id, parameters, total_pnl, long_pnl, short_pnl,
                       max_drawdown, win_rate, total_trades, long_trades, short_trades,
                       winning_trades, losing_trades
                FROM experiments 
                WHERE success = 1
                ORDER BY experiment_id
            """)
            
            for row in cursor.fetchall():
                try:
                    # è§£æåƒæ•¸
                    params = json.loads(row['parameters'])
                    
                    # æå–æ™‚é–“å€é–“
                    start_time = params.get('range_start_time', '08:46')
                    end_time = params.get('range_end_time', '08:47')
                    time_range = f"{start_time}-{end_time}"
                    
                    # æå–åƒæ•¸å­—ç¬¦ä¸²ï¼ˆåŒ…å«è§¸ç™¼é»å’Œå›æª”ç¯„åœï¼‰
                    lot1_str = f"{params.get('lot1_trigger', 0)}({params.get('lot1_trailing', 0)}%)"
                    lot2_str = f"{params.get('lot2_trigger', 0)}({params.get('lot2_trailing', 0)}%)"
                    lot3_str = f"{params.get('lot3_trigger', 0)}({params.get('lot3_trailing', 0)}%)"
                    param_str = f"{lot1_str}/{lot2_str}/{lot3_str}"
                    
                    experiment = {
                        'experiment_id': row['experiment_id'],
                        'time_range': time_range,
                        'param_str': param_str,
                        'total_pnl': row['total_pnl'],
                        'long_pnl': row['long_pnl'],
                        'short_pnl': row['short_pnl'],
                        'max_drawdown': row['max_drawdown'],
                        'win_rate': row['win_rate'],
                        'total_trades': row['total_trades'],
                        'long_trades': row['long_trades'],
                        'short_trades': row['short_trades'],
                        'winning_trades': row['winning_trades'],
                        'losing_trades': row['losing_trades']
                    }
                    
                    experiments.append(experiment)
                    
                except (json.JSONDecodeError, KeyError) as e:
                    logger.warning(f"è§£æå¯¦é©— {row['experiment_id']} å¤±æ•—: {e}")
                    continue
        
        logger.info(f"ğŸ“Š æˆåŠŸæå– {len(experiments)} å€‹å¯¦é©—æ•¸æ“š")
        return experiments
    
    def _estimate_mdd(self, total_mdd: float, direction_pnl: float, total_pnl: float) -> float:
        """ä¼°ç®—å–®æ–¹å‘MDD"""
        if total_pnl == 0:
            return 0.0
        
        # æ–¹æ³•1ï¼šå¦‚æœè©²æ–¹å‘è™§æï¼ŒMDDè‡³å°‘ç­‰æ–¼è™§æé‡‘é¡
        if direction_pnl < 0:
            return abs(direction_pnl)
        
        # æ–¹æ³•2ï¼šåŸºæ–¼æ¯”ä¾‹ä¼°ç®—ï¼Œä½†è¨­å®šæœ€å°å€¼
        proportion_mdd = total_mdd * abs(direction_pnl) / abs(total_pnl) if total_pnl != 0 else 0
        
        # ä¿å®ˆä¼°è¨ˆï¼šå³ä½¿ç²åˆ©ä¹Ÿå¯èƒ½æœ‰ä¸€å®šå›æ’¤
        conservative_mdd = total_mdd * 0.3
        
        return max(proportion_mdd, conservative_mdd)
    
    def _estimate_win_rate(self, total_win_rate: float, direction_pnl: float, total_pnl: float) -> float:
        """ä¼°ç®—å–®æ–¹å‘å‹ç‡"""
        if total_pnl == 0:
            return total_win_rate
        
        # åŸºæ–¼æç›Šè¡¨ç¾èª¿æ•´å‹ç‡ä¼°è¨ˆ
        pnl_ratio = direction_pnl / total_pnl if total_pnl != 0 else 0.5
        
        # å¦‚æœè©²æ–¹å‘æç›Šä½”æ¯”è¼ƒé«˜ï¼Œå‡è¨­å‹ç‡ä¹Ÿè¼ƒé«˜
        if pnl_ratio > 0.6:
            return min(total_win_rate * 1.1, 100.0)
        elif pnl_ratio < 0.4:
            return max(total_win_rate * 0.9, 0.0)
        else:
            return total_win_rate
    
    def _generate_long_only_report(self, experiments_data: List[Dict], timestamp: str) -> Path:
        """ç”Ÿæˆåªåšå¤šç­–ç•¥å ±å‘Š"""
        filename = f"long_only_results_{timestamp}.csv"
        filepath = self.output_dir / filename
        
        # æº–å‚™CSVæ•¸æ“š
        csv_data = []
        for exp in experiments_data:
            # ä¼°ç®—å¤šæ–¹MDDå’Œå‹ç‡
            long_mdd = self._estimate_mdd(exp['max_drawdown'], exp['long_pnl'], exp['total_pnl'])
            long_win_rate = self._estimate_win_rate(exp['win_rate'], exp['long_pnl'], exp['total_pnl'])
            
            csv_row = {
                'å¯¦é©—ID': exp['experiment_id'],
                'æ™‚é–“å€é–“': exp['time_range'],
                'å¤šæ–¹æç›Š': round(exp['long_pnl'], 1),
                'å¤šæ–¹MDDä¼°ç®—': round(long_mdd, 1),
                'å¤šæ–¹å‹ç‡ä¼°ç®—': f"{round(long_win_rate, 1)}%",
                'å¤šæ–¹äº¤æ˜“æ¬¡æ•¸': exp['long_trades'],
                'åƒæ•¸': exp['param_str'],
                'å‚™è¨»': 'MDD/å‹ç‡ç‚ºä¼°ç®—å€¼'
            }
            csv_data.append(csv_row)
        
        # æŒ‰å¤šæ–¹æç›Šæ’åºï¼ˆé™åºï¼‰
        csv_data.sort(key=lambda x: x['å¤šæ–¹æç›Š'], reverse=True)
        
        # å¯«å…¥CSVæ–‡ä»¶
        fieldnames = ['å¯¦é©—ID', 'æ™‚é–“å€é–“', 'å¤šæ–¹æç›Š', 'å¤šæ–¹MDDä¼°ç®—', 'å¤šæ–¹å‹ç‡ä¼°ç®—', 'å¤šæ–¹äº¤æ˜“æ¬¡æ•¸', 'åƒæ•¸', 'å‚™è¨»']
        
        with open(filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(csv_data)
        
        logger.info(f"âœ… å¤šæ–¹å ±å‘Šå·²ç”Ÿæˆ: {filepath}")
        return filepath
    
    def _generate_short_only_report(self, experiments_data: List[Dict], timestamp: str) -> Path:
        """ç”Ÿæˆåªåšç©ºç­–ç•¥å ±å‘Š"""
        filename = f"short_only_results_{timestamp}.csv"
        filepath = self.output_dir / filename
        
        # æº–å‚™CSVæ•¸æ“š
        csv_data = []
        for exp in experiments_data:
            # ä¼°ç®—ç©ºæ–¹MDDå’Œå‹ç‡
            short_mdd = self._estimate_mdd(exp['max_drawdown'], exp['short_pnl'], exp['total_pnl'])
            short_win_rate = self._estimate_win_rate(exp['win_rate'], exp['short_pnl'], exp['total_pnl'])
            
            csv_row = {
                'å¯¦é©—ID': exp['experiment_id'],
                'æ™‚é–“å€é–“': exp['time_range'],
                'ç©ºæ–¹æç›Š': round(exp['short_pnl'], 1),
                'ç©ºæ–¹MDDä¼°ç®—': round(short_mdd, 1),
                'ç©ºæ–¹å‹ç‡ä¼°ç®—': f"{round(short_win_rate, 1)}%",
                'ç©ºæ–¹äº¤æ˜“æ¬¡æ•¸': exp['short_trades'],
                'åƒæ•¸': exp['param_str'],
                'å‚™è¨»': 'MDD/å‹ç‡ç‚ºä¼°ç®—å€¼'
            }
            csv_data.append(csv_row)
        
        # æŒ‰ç©ºæ–¹æç›Šæ’åºï¼ˆé™åºï¼‰
        csv_data.sort(key=lambda x: x['ç©ºæ–¹æç›Š'], reverse=True)
        
        # å¯«å…¥CSVæ–‡ä»¶
        fieldnames = ['å¯¦é©—ID', 'æ™‚é–“å€é–“', 'ç©ºæ–¹æç›Š', 'ç©ºæ–¹MDDä¼°ç®—', 'ç©ºæ–¹å‹ç‡ä¼°ç®—', 'ç©ºæ–¹äº¤æ˜“æ¬¡æ•¸', 'åƒæ•¸', 'å‚™è¨»']
        
        with open(filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(csv_data)
        
        logger.info(f"âœ… ç©ºæ–¹å ±å‘Šå·²ç”Ÿæˆ: {filepath}")
        return filepath
    
    def get_top_performers(self, direction: str = "long", limit: int = 10) -> List[Dict]:
        """ç²å–æœ€ä½³è¡¨ç¾çš„å¯¦é©—ï¼ˆç”¨æ–¼å¿«é€ŸæŸ¥çœ‹ï¼‰"""
        experiments_data = self._extract_experiments_data()
        
        if direction == "long":
            # æŒ‰å¤šæ–¹æç›Šæ’åº
            sorted_data = sorted(experiments_data, key=lambda x: x['long_pnl'], reverse=True)
            return sorted_data[:limit]
        else:
            # æŒ‰ç©ºæ–¹æç›Šæ’åº
            sorted_data = sorted(experiments_data, key=lambda x: x['short_pnl'], reverse=True)
            return sorted_data[:limit]

def main():
    """ä¸»å‡½æ•¸ - ç”¨æ–¼æ¸¬è©¦"""
    analyzer = LongShortSeparationAnalyzer()
    
    # ç”Ÿæˆå ±å‘Š
    result = analyzer.generate_separation_reports()
    
    if result["success"]:
        print(f"âœ… å ±å‘Šç”ŸæˆæˆåŠŸ")
        print(f"ğŸ“Š å¤šæ–¹å ±å‘Š: {result['long_report']}")
        print(f"ğŸ“Š ç©ºæ–¹å ±å‘Š: {result['short_report']}")
        print(f"ğŸ“ˆ è™•ç†äº† {result['record_count']} å€‹å¯¦é©—")
        
        # é¡¯ç¤ºå‰5å
        print("\nğŸ† å¤šæ–¹æç›Šå‰5å:")
        top_long = analyzer.get_top_performers("long", 5)
        for i, exp in enumerate(top_long, 1):
            print(f"  {i}. å¯¦é©—{exp['experiment_id']} ({exp['time_range']}): {exp['long_pnl']:.1f}é»")
        
        print("\nğŸ† ç©ºæ–¹æç›Šå‰5å:")
        top_short = analyzer.get_top_performers("short", 5)
        for i, exp in enumerate(top_short, 1):
            print(f"  {i}. å¯¦é©—{exp['experiment_id']} ({exp['time_range']}): {exp['short_pnl']:.1f}é»")
    else:
        print(f"âŒ å ±å‘Šç”Ÿæˆå¤±æ•—: {result['error']}")

if __name__ == "__main__":
    main()
