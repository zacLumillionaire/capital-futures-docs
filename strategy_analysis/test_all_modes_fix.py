#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¬è©¦å…¨æ¨¡å¼å¯¦é©—IDä¿®å¾©
é©—è­‰å¯¦é©—IDä¸é‡è¤‡ï¼Œæ‰€æœ‰å¯¦é©—éƒ½è¢«æ­£ç¢ºä¿å­˜
"""

import json
import logging
import sqlite3
from parameter_matrix_generator import ExperimentConfig, ParameterMatrixGenerator, ParameterRange, LotParameterConfig, TimeRange

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_experiment_id_generation():
    """æ¸¬è©¦å¯¦é©—IDç”Ÿæˆé‚è¼¯"""
    logger.info("ğŸ§ª æ¸¬è©¦å¯¦é©—IDç”Ÿæˆé‚è¼¯...")
    
    # å‰µå»ºå°è¦æ¨¡æ¸¬è©¦é…ç½®
    config = ExperimentConfig(
        trade_lots=3,
        date_ranges=[("2024-11-04", "2024-11-06")],  # 1å€‹æ—¥æœŸç¯„åœ
        time_ranges=TimeRange(
            start_times=["08:46"],  # 1å€‹æ™‚é–“ç¯„åœ
            end_times=["08:47"]
        ),
        lot1_config=LotParameterConfig(
            trigger_range=ParameterRange(15, 20, 5),  # 2å€‹å€¼: 15, 20
            trailing_range=ParameterRange(10, 20, 10)  # 2å€‹å€¼: 10, 20
        ),
        lot2_config=LotParameterConfig(
            trigger_range=ParameterRange(35, 40, 5),  # 2å€‹å€¼: 35, 40
            trailing_range=ParameterRange(10, 20, 10),  # 2å€‹å€¼: 10, 20
            protection_range=ParameterRange(2.0, 2.0, 1.0)  # 1å€‹å€¼: 2.0
        ),
        lot3_config=LotParameterConfig(
            trigger_range=ParameterRange(50, 55, 5),  # 2å€‹å€¼: 50, 55
            trailing_range=ParameterRange(15, 25, 10),  # 2å€‹å€¼: 15, 25
            protection_range=ParameterRange(2.0, 2.0, 1.0)  # 1å€‹å€¼: 2.0
        )
    )
    
    # ç”Ÿæˆåƒæ•¸çŸ©é™£
    generator = ParameterMatrixGenerator(config)
    experiments = generator.generate_full_parameter_matrix()
    
    logger.info(f"âœ… åŸå§‹å¯¦é©—æ•¸é‡: {len(experiments)}")
    
    # é æœŸ: 1æ—¥æœŸ Ã— 1æ™‚é–“ Ã— (2Ã—2) lot1 Ã— (2Ã—2Ã—1) lot2 Ã— (2Ã—2Ã—1) lot3 = 1Ã—1Ã—4Ã—4Ã—4 = 64å€‹å¯¦é©—
    expected_count = 1 * 1 * 2 * 2 * 2 * 2 * 1 * 2 * 2 * 1  # 64
    logger.info(f"ğŸ“Š é æœŸå¯¦é©—æ•¸é‡: {expected_count}")
    
    # æª¢æŸ¥å¯¦é©—IDæ˜¯å¦é€£çºŒä¸”å”¯ä¸€
    experiment_ids = [exp['experiment_id'] for exp in experiments]
    unique_ids = set(experiment_ids)
    
    logger.info(f"ğŸ” å¯¦é©—IDç¯„åœ: {min(experiment_ids)} - {max(experiment_ids)}")
    logger.info(f"ğŸ” å”¯ä¸€IDæ•¸é‡: {len(unique_ids)}")
    logger.info(f"ğŸ” ç¸½å¯¦é©—æ•¸é‡: {len(experiment_ids)}")
    
    if len(unique_ids) == len(experiment_ids):
        logger.info("âœ… åŸå§‹å¯¦é©—IDå”¯ä¸€æ€§æª¢æŸ¥é€šé")
    else:
        logger.error("âŒ åŸå§‹å¯¦é©—IDæœ‰é‡è¤‡")
        return False
    
    return experiments

def test_all_modes_expansion(experiments):
    """æ¸¬è©¦å…¨æ¨¡å¼æ“´å±•é‚è¼¯"""
    logger.info("ğŸ§ª æ¸¬è©¦å…¨æ¨¡å¼æ“´å±•é‚è¼¯...")
    
    # æ¨¡æ“¬å…¨æ¨¡å¼æ“´å±•ï¼ˆè¤‡è£½batch_experiment_gui.pyçš„é‚è¼¯ï¼‰
    trading_direction = 'ALL_MODES'
    
    if trading_direction == 'ALL_MODES':
        # å…¨æ¨¡å¼ï¼šç‚ºæ¯å€‹åƒæ•¸çµ„åˆç”Ÿæˆä¸‰ç¨®äº¤æ˜“æ–¹å‘çš„å¯¦é©—
        original_experiments = experiments.copy()
        expanded_experiments = []
        
        # é‡æ–°åˆ†é…å¯¦é©—IDï¼Œé¿å…é‡è¤‡
        experiment_id = 1
        
        for exp in original_experiments:
            # ç”Ÿæˆä¸‰ç¨®æ¨¡å¼çš„å¯¦é©—
            for mode in ['LONG_ONLY', 'SHORT_ONLY', 'BOTH']:
                new_exp = exp.copy()
                new_exp['trading_direction'] = mode
                new_exp['experiment_id'] = experiment_id  # ğŸš€ é‡æ–°åˆ†é…ID
                expanded_experiments.append(new_exp)
                experiment_id += 1
    
    logger.info(f"âœ… æ“´å±•å¾Œå¯¦é©—æ•¸é‡: {len(expanded_experiments)}")
    logger.info(f"ğŸ“Š é æœŸæ“´å±•æ•¸é‡: {len(experiments) * 3}")
    
    # æª¢æŸ¥æ“´å±•å¾Œçš„å¯¦é©—IDå”¯ä¸€æ€§
    expanded_ids = [exp['experiment_id'] for exp in expanded_experiments]
    unique_expanded_ids = set(expanded_ids)
    
    logger.info(f"ğŸ” æ“´å±•å¾ŒIDç¯„åœ: {min(expanded_ids)} - {max(expanded_ids)}")
    logger.info(f"ğŸ” æ“´å±•å¾Œå”¯ä¸€IDæ•¸é‡: {len(unique_expanded_ids)}")
    logger.info(f"ğŸ” æ“´å±•å¾Œç¸½å¯¦é©—æ•¸é‡: {len(expanded_ids)}")
    
    if len(unique_expanded_ids) == len(expanded_ids):
        logger.info("âœ… æ“´å±•å¾Œå¯¦é©—IDå”¯ä¸€æ€§æª¢æŸ¥é€šé")
    else:
        logger.error("âŒ æ“´å±•å¾Œå¯¦é©—IDæœ‰é‡è¤‡")
        return False, []
    
    # æª¢æŸ¥äº¤æ˜“æ–¹å‘åˆ†å¸ƒ
    direction_counts = {}
    for exp in expanded_experiments:
        direction = exp['trading_direction']
        direction_counts[direction] = direction_counts.get(direction, 0) + 1
    
    logger.info("ğŸ“Š äº¤æ˜“æ–¹å‘åˆ†å¸ƒ:")
    for direction, count in direction_counts.items():
        logger.info(f"   {direction}: {count} å€‹å¯¦é©—")
    
    # é©—è­‰æ¯ç¨®æ–¹å‘çš„æ•¸é‡æ˜¯å¦ç›¸ç­‰
    expected_per_direction = len(experiments)
    for direction, count in direction_counts.items():
        if count != expected_per_direction:
            logger.error(f"âŒ {direction} æ–¹å‘å¯¦é©—æ•¸é‡éŒ¯èª¤: é æœŸ {expected_per_direction}, å¯¦éš› {count}")
            return False, []
    
    logger.info("âœ… äº¤æ˜“æ–¹å‘åˆ†å¸ƒæª¢æŸ¥é€šé")
    return True, expanded_experiments

def test_database_storage(experiments):
    """æ¸¬è©¦æ•¸æ“šåº«å­˜å„²"""
    logger.info("ğŸ§ª æ¸¬è©¦æ•¸æ“šåº«å­˜å„²...")
    
    # æ¸…ç†æ•¸æ“šåº«
    with sqlite3.connect("test_batch_experiments.db") as conn:
        conn.execute("DROP TABLE IF EXISTS experiments")
        conn.execute("""
            CREATE TABLE experiments (
                experiment_id INTEGER PRIMARY KEY,
                parameters TEXT NOT NULL,
                success BOOLEAN NOT NULL,
                execution_time REAL NOT NULL,
                total_trades INTEGER DEFAULT 0,
                winning_trades INTEGER DEFAULT 0,
                losing_trades INTEGER DEFAULT 0,
                win_rate REAL DEFAULT 0.0,
                total_pnl REAL DEFAULT 0.0,
                max_drawdown REAL DEFAULT 0.0,
                long_trades INTEGER DEFAULT 0,
                short_trades INTEGER DEFAULT 0,
                long_pnl REAL DEFAULT 0.0,
                short_pnl REAL DEFAULT 0.0,
                error_message TEXT DEFAULT '',
                stdout_log TEXT DEFAULT '',
                stderr_log TEXT DEFAULT '',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
    
    # æ¨¡æ“¬å­˜å„²æ‰€æœ‰å¯¦é©—
    stored_count = 0
    for exp in experiments:
        with sqlite3.connect("test_batch_experiments.db") as conn:
            conn.execute("""
                INSERT OR REPLACE INTO experiments (
                    experiment_id, parameters, success, execution_time,
                    total_trades, winning_trades, losing_trades, win_rate,
                    total_pnl, max_drawdown, long_trades, short_trades,
                    long_pnl, short_pnl, error_message, stdout_log, stderr_log
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                exp['experiment_id'], json.dumps(exp), True, 1.0,
                10, 6, 4, 60.0, 100.0, -20.0, 5, 5, 50.0, 50.0, "", "", ""
            ))
            stored_count += 1
    
    # æª¢æŸ¥å­˜å„²çµæœ
    with sqlite3.connect("test_batch_experiments.db") as conn:
        cursor = conn.execute("SELECT COUNT(*) FROM experiments")
        db_count = cursor.fetchone()[0]
        
        cursor = conn.execute("SELECT COUNT(DISTINCT experiment_id) FROM experiments")
        unique_count = cursor.fetchone()[0]
        
        cursor = conn.execute("SELECT json_extract(parameters, '$.trading_direction') as direction, COUNT(*) FROM experiments GROUP BY direction")
        direction_distribution = dict(cursor.fetchall())
    
    logger.info(f"ğŸ“Š å­˜å„²çµ±è¨ˆ:")
    logger.info(f"   å˜—è©¦å­˜å„²: {stored_count} å€‹å¯¦é©—")
    logger.info(f"   æ•¸æ“šåº«è¨˜éŒ„: {db_count} æ¢")
    logger.info(f"   å”¯ä¸€IDæ•¸: {unique_count} å€‹")
    logger.info(f"   äº¤æ˜“æ–¹å‘åˆ†å¸ƒ: {direction_distribution}")
    
    if db_count == len(experiments) and unique_count == len(experiments):
        logger.info("âœ… æ•¸æ“šåº«å­˜å„²æª¢æŸ¥é€šé")
        return True
    else:
        logger.error("âŒ æ•¸æ“šåº«å­˜å„²æª¢æŸ¥å¤±æ•—")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    logger.info("ğŸš€ é–‹å§‹å…¨æ¨¡å¼å¯¦é©—IDä¿®å¾©æ¸¬è©¦")
    
    # æ¸¬è©¦1ï¼šåŸå§‹å¯¦é©—IDç”Ÿæˆ
    experiments = test_experiment_id_generation()
    if not experiments:
        logger.error("âŒ åŸå§‹å¯¦é©—IDç”Ÿæˆæ¸¬è©¦å¤±æ•—")
        return
    
    # æ¸¬è©¦2ï¼šå…¨æ¨¡å¼æ“´å±•
    success, expanded_experiments = test_all_modes_expansion(experiments)
    if not success:
        logger.error("âŒ å…¨æ¨¡å¼æ“´å±•æ¸¬è©¦å¤±æ•—")
        return
    
    # æ¸¬è©¦3ï¼šæ•¸æ“šåº«å­˜å„²
    if not test_database_storage(expanded_experiments):
        logger.error("âŒ æ•¸æ“šåº«å­˜å„²æ¸¬è©¦å¤±æ•—")
        return
    
    logger.info("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼å…¨æ¨¡å¼å¯¦é©—IDä¿®å¾©æˆåŠŸï¼")
    
    # æ¸…ç†æ¸¬è©¦æ•¸æ“šåº«
    import os
    if os.path.exists("test_batch_experiments.db"):
        os.remove("test_batch_experiments.db")
        logger.info("ğŸ—‘ï¸ æ¸¬è©¦æ•¸æ“šåº«å·²æ¸…ç†")

if __name__ == "__main__":
    main()
