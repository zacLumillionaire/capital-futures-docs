#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è³‡æ–™åº«ç®¡ç†å™¨ - è™•ç†æ‰€æœ‰è³‡æ–™åº«æ“ä½œ
æ”¯æ´æ‰¹é‡æ’å…¥ã€è³‡æ–™å»é‡ã€å®Œæ•´æ€§é©—è­‰ã€çµ±è¨ˆæŸ¥è©¢ç­‰åŠŸèƒ½
"""

import sqlite3
import logging
import os
import json
import sys
from datetime import datetime, timedelta
from contextlib import contextmanager

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from history_config import DATABASE_PATH, DATA_DIR

logger = logging.getLogger(__name__)

class DatabaseManager:
    """è³‡æ–™åº«ç®¡ç†å™¨"""

    def __init__(self, db_path=DATABASE_PATH):
        """
        åˆå§‹åŒ–è³‡æ–™åº«ç®¡ç†å™¨
        
        Args:
            db_path: è³‡æ–™åº«æª”æ¡ˆè·¯å¾‘
        """
        self.db_path = db_path
        
        # ç¢ºä¿è³‡æ–™ç›®éŒ„å­˜åœ¨
        os.makedirs(DATA_DIR, exist_ok=True)
        
        # åˆå§‹åŒ–è³‡æ–™åº«
        self.initialize_database()

    def initialize_database(self):
        """åˆå§‹åŒ–è³‡æ–™åº«çµæ§‹"""
        try:
            # è®€å–SQLçµæ§‹æª”æ¡ˆ
            schema_path = os.path.join(os.path.dirname(__file__), 'schema.sql')
            
            if not os.path.exists(schema_path):
                logger.error(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™åº«çµæ§‹æª”æ¡ˆ: {schema_path}")
                raise FileNotFoundError(f"Schema file not found: {schema_path}")

            with open(schema_path, 'r', encoding='utf-8') as f:
                schema_sql = f.read()

            # åŸ·è¡Œå»ºè¡¨èªå¥
            with self.get_connection() as conn:
                conn.executescript(schema_sql)
                conn.commit()

            logger.info("âœ… è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    @contextmanager
    def get_connection(self):
        """
        å–å¾—è³‡æ–™åº«é€£ç·šï¼ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰
        
        Yields:
            sqlite3.Connection: è³‡æ–™åº«é€£ç·š
        """
        conn = None
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row  # è®“æŸ¥è©¢çµæœå¯ä»¥ç”¨æ¬„ä½åç¨±å­˜å–
            yield conn
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"âŒ è³‡æ–™åº«æ“ä½œå¤±æ•—: {e}")
            raise
        finally:
            if conn:
                conn.close()

    def insert_tick_data(self, tick_data):
        """
        æ’å…¥å–®ç­†é€ç­†è³‡æ–™
        
        Args:
            tick_data: é€ç­†è³‡æ–™å­—å…¸
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ’å…¥
        """
        sql = """
        INSERT OR IGNORE INTO tick_data
        (symbol, market_no, index_code, ptr, trade_date, trade_time, trade_time_ms,
         bid_price, ask_price, close_price, volume, simulate_flag, data_type)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """

        values = (
            tick_data.get('symbol'),
            tick_data.get('market_no'),
            tick_data.get('index_code'),
            tick_data.get('ptr'),
            tick_data.get('trade_date'),
            tick_data.get('trade_time'),
            tick_data.get('trade_time_ms'),
            tick_data.get('bid_price'),
            tick_data.get('ask_price'),
            tick_data.get('close_price'),
            tick_data.get('volume'),
            tick_data.get('simulate_flag', 0),
            tick_data.get('data_type', 'HISTORY')
        )

        try:
            with self.get_connection() as conn:
                cursor = conn.execute(sql, values)
                conn.commit()
                return cursor.rowcount > 0
        except Exception as e:
            logger.error(f"âŒ æ’å…¥é€ç­†è³‡æ–™å¤±æ•—: {e}")
            return False

    def batch_insert_tick_data(self, tick_data_list):
        """
        æ‰¹é‡æ’å…¥é€ç­†è³‡æ–™
        
        Args:
            tick_data_list: é€ç­†è³‡æ–™åˆ—è¡¨
            
        Returns:
            int: æˆåŠŸæ’å…¥çš„ç­†æ•¸
        """
        if not tick_data_list:
            return 0

        sql = """
        INSERT OR IGNORE INTO tick_data
        (symbol, market_no, index_code, ptr, trade_date, trade_time, trade_time_ms,
         bid_price, ask_price, close_price, volume, simulate_flag, data_type)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """

        values_list = []
        for tick_data in tick_data_list:
            values = (
                tick_data.get('symbol'),
                tick_data.get('market_no'),
                tick_data.get('index_code'),
                tick_data.get('ptr'),
                tick_data.get('trade_date'),
                tick_data.get('trade_time'),
                tick_data.get('trade_time_ms'),
                tick_data.get('bid_price'),
                tick_data.get('ask_price'),
                tick_data.get('close_price'),
                tick_data.get('volume'),
                tick_data.get('simulate_flag', 0),
                tick_data.get('data_type', 'HISTORY')
            )
            values_list.append(values)

        try:
            with self.get_connection() as conn:
                cursor = conn.executemany(sql, values_list)
                conn.commit()
                inserted_count = cursor.rowcount
                logger.debug(f"ğŸ’¾ æ‰¹é‡æ’å…¥ {inserted_count}/{len(values_list)} ç­†é€ç­†è³‡æ–™")
                return inserted_count
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æ’å…¥é€ç­†è³‡æ–™å¤±æ•—: {e}")
            return 0

    def batch_insert_best5_data(self, best5_data_list):
        """
        æ‰¹é‡æ’å…¥äº”æª”è³‡æ–™
        
        Args:
            best5_data_list: äº”æª”è³‡æ–™åˆ—è¡¨
            
        Returns:
            int: æˆåŠŸæ’å…¥çš„ç­†æ•¸
        """
        if not best5_data_list:
            return 0

        sql = """
        INSERT OR IGNORE INTO best5_data
        (symbol, market_no, index_code, trade_date, trade_time,
         bid_price_1, bid_volume_1, bid_price_2, bid_volume_2, bid_price_3, bid_volume_3,
         bid_price_4, bid_volume_4, bid_price_5, bid_volume_5,
         ask_price_1, ask_volume_1, ask_price_2, ask_volume_2, ask_price_3, ask_volume_3,
         ask_price_4, ask_volume_4, ask_price_5, ask_volume_5,
         extend_bid, extend_bid_qty, extend_ask, extend_ask_qty, simulate_flag)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """

        values_list = []
        for best5_data in best5_data_list:
            values = (
                best5_data.get('symbol'),
                best5_data.get('market_no'),
                best5_data.get('index_code'),
                best5_data.get('trade_date'),
                best5_data.get('trade_time'),
                best5_data.get('bid_price_1'), best5_data.get('bid_volume_1'),
                best5_data.get('bid_price_2'), best5_data.get('bid_volume_2'),
                best5_data.get('bid_price_3'), best5_data.get('bid_volume_3'),
                best5_data.get('bid_price_4'), best5_data.get('bid_volume_4'),
                best5_data.get('bid_price_5'), best5_data.get('bid_volume_5'),
                best5_data.get('ask_price_1'), best5_data.get('ask_volume_1'),
                best5_data.get('ask_price_2'), best5_data.get('ask_volume_2'),
                best5_data.get('ask_price_3'), best5_data.get('ask_volume_3'),
                best5_data.get('ask_price_4'), best5_data.get('ask_volume_4'),
                best5_data.get('ask_price_5'), best5_data.get('ask_volume_5'),
                best5_data.get('extend_bid'), best5_data.get('extend_bid_qty'),
                best5_data.get('extend_ask'), best5_data.get('extend_ask_qty'),
                best5_data.get('simulate_flag', 0)
            )
            values_list.append(values)

        try:
            with self.get_connection() as conn:
                cursor = conn.executemany(sql, values_list)
                conn.commit()
                inserted_count = cursor.rowcount
                logger.debug(f"ğŸ’¾ æ‰¹é‡æ’å…¥ {inserted_count}/{len(values_list)} ç­†äº”æª”è³‡æ–™")
                return inserted_count
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æ’å…¥äº”æª”è³‡æ–™å¤±æ•—: {e}")
            return 0

    def batch_insert_kline_data(self, kline_data_list):
        """
        æ‰¹é‡æ’å…¥Kç·šè³‡æ–™

        Args:
            kline_data_list: Kç·šè³‡æ–™åˆ—è¡¨

        Returns:
            int: æˆåŠŸæ’å…¥çš„ç­†æ•¸
        """
        if not kline_data_list:
            return 0

        sql = """
        INSERT OR IGNORE INTO kline_data
        (symbol, kline_type, trade_date, trade_time, open_price, high_price, low_price, close_price, volume)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """

        values_list = []
        for kline_data in kline_data_list:
            values = (
                kline_data.get('symbol'),
                kline_data.get('kline_type', 'MINUTE'),
                kline_data.get('trade_date'),
                kline_data.get('trade_time'),
                kline_data.get('open_price'),
                kline_data.get('high_price'),
                kline_data.get('low_price'),
                kline_data.get('close_price'),
                kline_data.get('volume')
            )
            values_list.append(values)

        try:
            with self.get_connection() as conn:
                cursor = conn.executemany(sql, values_list)
                conn.commit()
                inserted_count = cursor.rowcount
                logger.debug(f"ğŸ’¾ æ‰¹é‡æ’å…¥ {inserted_count}/{len(values_list)} ç­†Kç·šè³‡æ–™")
                return inserted_count
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æ’å…¥Kç·šè³‡æ–™å¤±æ•—: {e}")
            return 0

    def log_collection_start(self, collection_type, symbol, parameters=None):
        """
        è¨˜éŒ„æ”¶é›†é–‹å§‹

        Args:
            collection_type: æ”¶é›†é¡å‹
            symbol: å•†å“ä»£ç¢¼
            parameters: æ”¶é›†åƒæ•¸

        Returns:
            int: è¨˜éŒ„IDï¼Œå¤±æ•—æ™‚è¿”å›None
        """
        sql = """
        INSERT INTO collection_log
        (collection_type, symbol, start_time, status, parameters)
        VALUES (?, ?, ?, 'RUNNING', ?)
        """

        try:
            with self.get_connection() as conn:
                cursor = conn.execute(sql, (
                    collection_type, symbol, datetime.now(),
                    json.dumps(parameters, ensure_ascii=False) if parameters else None
                ))
                conn.commit()
                return cursor.lastrowid
        except Exception as e:
            logger.error(f"âŒ è¨˜éŒ„æ”¶é›†é–‹å§‹å¤±æ•—: {e}")
            return None

    def log_collection_end(self, log_id, records_count, status='COMPLETED', error_message=None):
        """
        è¨˜éŒ„æ”¶é›†çµæŸ

        Args:
            log_id: è¨˜éŒ„ID
            records_count: æ”¶é›†ç­†æ•¸
            status: å®Œæˆç‹€æ…‹
            error_message: éŒ¯èª¤è¨Šæ¯

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ›´æ–°
        """
        sql = """
        UPDATE collection_log
        SET end_time = ?, records_count = ?, status = ?, error_message = ?
        WHERE id = ?
        """

        try:
            with self.get_connection() as conn:
                cursor = conn.execute(sql, (
                    datetime.now(), records_count, status, error_message, log_id
                ))
                conn.commit()
                return cursor.rowcount > 0
        except Exception as e:
            logger.error(f"âŒ è¨˜éŒ„æ”¶é›†çµæŸå¤±æ•—: {e}")
            return False

    def get_data_statistics(self, symbol=None):
        """
        å–å¾—è³‡æ–™çµ±è¨ˆ

        Args:
            symbol: å•†å“ä»£ç¢¼ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰å•†å“

        Returns:
            dict: çµ±è¨ˆè³‡è¨Š
        """
        try:
            with self.get_connection() as conn:
                # åŸºæœ¬çµ±è¨ˆæŸ¥è©¢
                if symbol:
                    where_clause = "WHERE symbol = ?"
                    params = (symbol,)
                else:
                    where_clause = ""
                    params = ()

                # é€ç­†è³‡æ–™çµ±è¨ˆ
                tick_sql = f"SELECT COUNT(*) FROM tick_data {where_clause}"
                tick_count = conn.execute(tick_sql, params).fetchone()[0]

                # äº”æª”è³‡æ–™çµ±è¨ˆ
                best5_sql = f"SELECT COUNT(*) FROM best5_data {where_clause}"
                best5_count = conn.execute(best5_sql, params).fetchone()[0]

                # Kç·šè³‡æ–™çµ±è¨ˆ
                kline_sql = f"SELECT COUNT(*) FROM kline_data {where_clause}"
                kline_count = conn.execute(kline_sql, params).fetchone()[0]

                # æœ€æ–°è³‡æ–™æ™‚é–“
                latest_tick_sql = f"""
                SELECT MAX(trade_date || trade_time)
                FROM tick_data {where_clause}
                """
                latest_tick = conn.execute(latest_tick_sql, params).fetchone()[0]

                # æ—¥æœŸç¯„åœ
                date_range_sql = f"""
                SELECT MIN(trade_date) as min_date, MAX(trade_date) as max_date
                FROM tick_data {where_clause}
                """
                date_range = conn.execute(date_range_sql, params).fetchone()

                return {
                    'symbol': symbol or 'ALL',
                    'tick_count': tick_count,
                    'best5_count': best5_count,
                    'kline_count': kline_count,
                    'total_count': tick_count + best5_count + kline_count,
                    'latest_tick_time': latest_tick,
                    'date_range': {
                        'min_date': date_range['min_date'],
                        'max_date': date_range['max_date']
                    } if date_range['min_date'] else None
                }
        except Exception as e:
            logger.error(f"âŒ å–å¾—è³‡æ–™çµ±è¨ˆå¤±æ•—: {e}")
            return None

    def get_collection_history(self, limit=10):
        """
        å–å¾—æ”¶é›†æ­·å²è¨˜éŒ„

        Args:
            limit: é™åˆ¶ç­†æ•¸

        Returns:
            list: æ”¶é›†è¨˜éŒ„åˆ—è¡¨
        """
        sql = """
        SELECT
            collection_type, symbol, start_time, end_time,
            records_count, status, error_message, parameters
        FROM collection_log
        ORDER BY start_time DESC
        LIMIT ?
        """

        try:
            with self.get_connection() as conn:
                cursor = conn.execute(sql, (limit,))
                records = []
                for row in cursor.fetchall():
                    record = dict(row)
                    # è§£æåƒæ•¸JSON
                    if record['parameters']:
                        try:
                            record['parameters'] = json.loads(record['parameters'])
                        except json.JSONDecodeError:
                            record['parameters'] = {}
                    records.append(record)
                return records
        except Exception as e:
            logger.error(f"âŒ å–å¾—æ”¶é›†æ­·å²å¤±æ•—: {e}")
            return []

    def query_tick_data(self, symbol, start_date=None, end_date=None, limit=1000):
        """
        æŸ¥è©¢é€ç­†è³‡æ–™

        Args:
            symbol: å•†å“ä»£ç¢¼
            start_date: èµ·å§‹æ—¥æœŸ (YYYYMMDD)
            end_date: çµæŸæ—¥æœŸ (YYYYMMDD)
            limit: é™åˆ¶ç­†æ•¸

        Returns:
            list: é€ç­†è³‡æ–™åˆ—è¡¨
        """
        sql = """
        SELECT symbol, trade_date, trade_time, close_price, volume,
               bid_price, ask_price, data_type
        FROM tick_data
        WHERE symbol = ?
        """
        params = [symbol]

        if start_date:
            sql += " AND trade_date >= ?"
            params.append(start_date)

        if end_date:
            sql += " AND trade_date <= ?"
            params.append(end_date)

        sql += " ORDER BY trade_date DESC, trade_time DESC LIMIT ?"
        params.append(limit)

        try:
            with self.get_connection() as conn:
                cursor = conn.execute(sql, params)
                return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            logger.error(f"âŒ æŸ¥è©¢é€ç­†è³‡æ–™å¤±æ•—: {e}")
            return []

    def query_kline_data(self, symbol, kline_type='MINUTE', start_date=None, end_date=None, limit=1000):
        """
        æŸ¥è©¢Kç·šè³‡æ–™

        Args:
            symbol: å•†å“ä»£ç¢¼
            kline_type: Kç·šé¡å‹
            start_date: èµ·å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            limit: é™åˆ¶ç­†æ•¸

        Returns:
            list: Kç·šè³‡æ–™åˆ—è¡¨
        """
        sql = """
        SELECT symbol, kline_type, trade_date, trade_time,
               open_price, high_price, low_price, close_price, volume
        FROM kline_data
        WHERE symbol = ? AND kline_type = ?
        """
        params = [symbol, kline_type]

        if start_date:
            sql += " AND trade_date >= ?"
            params.append(start_date)

        if end_date:
            sql += " AND trade_date <= ?"
            params.append(end_date)

        sql += " ORDER BY trade_date DESC, trade_time DESC LIMIT ?"
        params.append(limit)

        try:
            with self.get_connection() as conn:
                cursor = conn.execute(sql, params)
                return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            logger.error(f"âŒ æŸ¥è©¢Kç·šè³‡æ–™å¤±æ•—: {e}")
            return []

    def cleanup_old_data(self, days_to_keep=90):
        """
        æ¸…ç†èˆŠè³‡æ–™

        Args:
            days_to_keep: ä¿ç•™å¤©æ•¸

        Returns:
            dict: æ¸…ç†çµæœ
        """
        cutoff_date = (datetime.now() - timedelta(days=days_to_keep)).strftime('%Y%m%d')

        try:
            with self.get_connection() as conn:
                # æ¸…ç†é€ç­†è³‡æ–™
                tick_sql = "DELETE FROM tick_data WHERE trade_date < ?"
                tick_cursor = conn.execute(tick_sql, (cutoff_date,))
                tick_deleted = tick_cursor.rowcount

                # æ¸…ç†äº”æª”è³‡æ–™
                best5_sql = "DELETE FROM best5_data WHERE trade_date < ?"
                best5_cursor = conn.execute(best5_sql, (cutoff_date,))
                best5_deleted = best5_cursor.rowcount

                # æ¸…ç†Kç·šè³‡æ–™
                kline_sql = "DELETE FROM kline_data WHERE trade_date < ?"
                kline_cursor = conn.execute(kline_sql, (cutoff_date,))
                kline_deleted = kline_cursor.rowcount

                # æ¸…ç†æ”¶é›†è¨˜éŒ„
                log_sql = "DELETE FROM collection_log WHERE start_time < datetime('now', '-90 days')"
                log_cursor = conn.execute(log_sql)
                log_deleted = log_cursor.rowcount

                conn.commit()

                result = {
                    'cutoff_date': cutoff_date,
                    'tick_deleted': tick_deleted,
                    'best5_deleted': best5_deleted,
                    'kline_deleted': kline_deleted,
                    'log_deleted': log_deleted,
                    'total_deleted': tick_deleted + best5_deleted + kline_deleted
                }

                logger.info(f"âœ… æ¸…ç†èˆŠè³‡æ–™å®Œæˆ: {result}")
                return result

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†èˆŠè³‡æ–™å¤±æ•—: {e}")
            return None

    def vacuum_database(self):
        """
        å£“ç¸®è³‡æ–™åº«ä»¥å›æ”¶ç©ºé–“

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            with self.get_connection() as conn:
                conn.execute("VACUUM")
                conn.commit()
            logger.info("âœ… è³‡æ–™åº«å£“ç¸®å®Œæˆ")
            return True
        except Exception as e:
            logger.error(f"âŒ è³‡æ–™åº«å£“ç¸®å¤±æ•—: {e}")
            return False

    def get_database_info(self):
        """
        å–å¾—è³‡æ–™åº«è³‡è¨Š

        Returns:
            dict: è³‡æ–™åº«è³‡è¨Š
        """
        try:
            # æª”æ¡ˆå¤§å°
            file_size = os.path.getsize(self.db_path) if os.path.exists(self.db_path) else 0

            with self.get_connection() as conn:
                # è³‡æ–™è¡¨è³‡è¨Š
                tables_sql = """
                SELECT name FROM sqlite_master
                WHERE type='table' AND name NOT LIKE 'sqlite_%'
                ORDER BY name
                """
                tables = [row[0] for row in conn.execute(tables_sql).fetchall()]

                # ç´¢å¼•è³‡è¨Š
                indexes_sql = """
                SELECT name FROM sqlite_master
                WHERE type='index' AND name NOT LIKE 'sqlite_%'
                ORDER BY name
                """
                indexes = [row[0] for row in conn.execute(indexes_sql).fetchall()]

                return {
                    'database_path': self.db_path,
                    'file_size_mb': round(file_size / (1024 * 1024), 2),
                    'tables': tables,
                    'indexes': indexes,
                    'table_count': len(tables),
                    'index_count': len(indexes)
                }

        except Exception as e:
            logger.error(f"âŒ å–å¾—è³‡æ–™åº«è³‡è¨Šå¤±æ•—: {e}")
            return None
