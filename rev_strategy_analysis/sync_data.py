#!/usr/bin/env python3
"""
æ•¸æ“šåŒæ­¥å·¥å…·
ç”¨æ–¼å¾PostgreSQLåŒæ­¥æœ€æ–°æ•¸æ“šåˆ°SQLite
"""

import sqlite3
import logging
from datetime import datetime
from pathlib import Path
import sys

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s [%(name)s.%(funcName)s:%(lineno)d] %(message)s',
    datefmt='%Y-%m-%dT%H:%M:%S%z'
)
logger = logging.getLogger(__name__)

def check_sqlite_status():
    """æª¢æŸ¥SQLiteæ•¸æ“šåº«ç‹€æ…‹"""
    db_path = Path(__file__).parent / "stock_data.sqlite"
    
    if not db_path.exists():
        logger.error("âŒ SQLiteæ•¸æ“šåº«æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        logger.info("ğŸ’¡ è«‹å…ˆé‹è¡Œ: python simple_export.py")
        return False
    
    try:
        conn = sqlite3.connect(db_path)
        cur = conn.cursor()
        
        # æª¢æŸ¥è¨˜éŒ„æ•¸
        cur.execute("SELECT COUNT(*) FROM stock_prices")
        count = cur.fetchone()[0]
        
        # æª¢æŸ¥æ—¥æœŸç¯„åœ
        cur.execute("SELECT MIN(date(trade_datetime)), MAX(date(trade_datetime)) FROM stock_prices")
        min_date, max_date = cur.fetchone()
        
        logger.info(f"âœ… SQLiteç‹€æ…‹æ­£å¸¸")
        logger.info(f"ğŸ“Š è¨˜éŒ„æ•¸: {count:,}")
        logger.info(f"ğŸ“… æ—¥æœŸç¯„åœ: {min_date} è‡³ {max_date}")
        
        conn.close()
        return True, count, min_date, max_date
        
    except Exception as e:
        logger.error(f"âŒ SQLiteæª¢æŸ¥å¤±æ•—: {e}")
        return False

def check_postgresql_status():
    """æª¢æŸ¥PostgreSQLæ•¸æ“šåº«ç‹€æ…‹"""
    try:
        # å°å…¥PostgreSQLç›¸é—œæ¨¡çµ„
        import shared
        from app_setup import init_all_db_pools
        
        logger.info("ğŸ”Œ é€£æ¥PostgreSQL...")
        init_all_db_pools()
        
        with shared.get_conn_cur_from_pool_b(as_dict=True) as (conn, cur):
            # æª¢æŸ¥è¨˜éŒ„æ•¸
            cur.execute("SELECT COUNT(*) FROM stock_prices")
            count = cur.fetchone()['count']
            
            # æª¢æŸ¥æ—¥æœŸç¯„åœ
            cur.execute("SELECT MIN(trade_datetime::date), MAX(trade_datetime::date) FROM stock_prices")
            result = cur.fetchone()
            min_date, max_date = result['min'], result['max']
            
            logger.info(f"âœ… PostgreSQLç‹€æ…‹æ­£å¸¸")
            logger.info(f"ğŸ“Š è¨˜éŒ„æ•¸: {count:,}")
            logger.info(f"ğŸ“… æ—¥æœŸç¯„åœ: {min_date} è‡³ {max_date}")
            
            return True, count, str(min_date), str(max_date)
            
    except Exception as e:
        logger.error(f"âŒ PostgreSQLæª¢æŸ¥å¤±æ•—: {e}")
        return False

def compare_databases():
    """æ¯”è¼ƒå…©å€‹æ•¸æ“šåº«çš„ç‹€æ…‹"""
    logger.info("ğŸ” é–‹å§‹æ•¸æ“šåº«ç‹€æ…‹æ¯”è¼ƒ...")
    
    # æª¢æŸ¥SQLite
    sqlite_result = check_sqlite_status()
    if not sqlite_result:
        return False
    
    sqlite_ok, sqlite_count, sqlite_min, sqlite_max = sqlite_result
    
    # æª¢æŸ¥PostgreSQL
    pg_result = check_postgresql_status()
    if not pg_result:
        return False
    
    pg_ok, pg_count, pg_min, pg_max = pg_result
    
    # æ¯”è¼ƒçµæœ
    logger.info(f"\nğŸ“Š æ•¸æ“šåº«æ¯”è¼ƒçµæœ:")
    logger.info(f"  PostgreSQL: {pg_count:,} ç­†è¨˜éŒ„ ({pg_min} è‡³ {pg_max})")
    logger.info(f"  SQLite:     {sqlite_count:,} ç­†è¨˜éŒ„ ({sqlite_min} è‡³ {sqlite_max})")
    
    missing_records = pg_count - sqlite_count
    sync_percentage = (sqlite_count / pg_count) * 100 if pg_count > 0 else 0
    
    logger.info(f"  åŒæ­¥å®Œæˆåº¦: {sync_percentage:.1f}%")
    
    if missing_records > 0:
        logger.warning(f"âš ï¸  SQLiteç¼ºå°‘ {missing_records:,} ç­†è¨˜éŒ„")
        logger.info(f"ğŸ’¡ å»ºè­°é‹è¡Œ: python simple_export.py")
        return False
    elif missing_records == 0:
        logger.info(f"âœ… æ•¸æ“šå®Œå…¨åŒæ­¥ï¼")
        return True
    else:
        logger.warning(f"âš ï¸  SQLiteè¨˜éŒ„æ•¸è¶…éPostgreSQLï¼Ÿé€™ä¸æ‡‰è©²ç™¼ç”Ÿã€‚")
        return False

def sync_data():
    """åŸ·è¡Œæ•¸æ“šåŒæ­¥"""
    logger.info("ğŸš€ é–‹å§‹æ•¸æ“šåŒæ­¥...")
    
    try:
        # å°å…¥ä¸¦åŸ·è¡Œsimple_export
        import subprocess
        import sys
        
        result = subprocess.run([
            sys.executable, 
            'simple_export.py'
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info("âœ… æ•¸æ“šåŒæ­¥å®Œæˆï¼")
            logger.info("ğŸ” é‡æ–°æª¢æŸ¥æ•¸æ“šåº«ç‹€æ…‹...")
            compare_databases()
        else:
            logger.error(f"âŒ æ•¸æ“šåŒæ­¥å¤±æ•—: {result.stderr}")
            
    except Exception as e:
        logger.error(f"âŒ åŒæ­¥éç¨‹å‡ºéŒ¯: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    logger.info("ğŸ”„ SQLiteæ•¸æ“šåŒæ­¥å·¥å…·")
    logger.info("=" * 50)
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "check":
            logger.info("ğŸ“‹ åŸ·è¡Œæ•¸æ“šåº«ç‹€æ…‹æª¢æŸ¥...")
            compare_databases()
            
        elif command == "sync":
            logger.info("ğŸ”„ åŸ·è¡Œæ•¸æ“šåŒæ­¥...")
            sync_data()
            
        elif command == "sqlite":
            logger.info("ğŸ“‹ æª¢æŸ¥SQLiteç‹€æ…‹...")
            check_sqlite_status()
            
        elif command == "postgres":
            logger.info("ğŸ“‹ æª¢æŸ¥PostgreSQLç‹€æ…‹...")
            check_postgresql_status()
            
        else:
            print("âŒ æœªçŸ¥å‘½ä»¤")
            print_usage()
    else:
        # é»˜èªåŸ·è¡Œæ¯”è¼ƒ
        compare_databases()

def print_usage():
    """æ‰“å°ä½¿ç”¨èªªæ˜"""
    print("""
ğŸ”„ SQLiteæ•¸æ“šåŒæ­¥å·¥å…·ä½¿ç”¨èªªæ˜:

python sync_data.py [å‘½ä»¤]

å‘½ä»¤é¸é …:
  check     - æ¯”è¼ƒPostgreSQLå’ŒSQLiteæ•¸æ“šç‹€æ…‹ (é»˜èª)
  sync      - åŸ·è¡Œå®Œæ•´æ•¸æ“šåŒæ­¥
  sqlite    - åƒ…æª¢æŸ¥SQLiteç‹€æ…‹
  postgres  - åƒ…æª¢æŸ¥PostgreSQLç‹€æ…‹

ä½¿ç”¨ç¯„ä¾‹:
  python sync_data.py check    # æª¢æŸ¥åŒæ­¥ç‹€æ…‹
  python sync_data.py sync     # åŸ·è¡Œæ•¸æ“šåŒæ­¥
  python sync_data.py          # é»˜èªæª¢æŸ¥ç‹€æ…‹
    """)

if __name__ == "__main__":
    main()
