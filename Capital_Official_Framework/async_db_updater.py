#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éé˜»å¡è³‡æ–™åº«æ›´æ–°ç®¡ç†å™¨
ç”¨æ–¼å»¶é²æ›´æ–°æ–¹æ¡ˆï¼Œç¢ºä¿ä¸å½±éŸ¿ç¾æœ‰ä¸‹å–®åŠŸèƒ½
"""

import threading
import queue
import time
import logging
from datetime import datetime
from typing import Dict, Any, Optional
from dataclasses import dataclass

# è¨­ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

@dataclass
class UpdateTask:
    """æ›´æ–°ä»»å‹™æ•¸æ“šçµæ§‹"""
    task_type: str  # 'position_fill', 'risk_state', 'position_status', 'position_exit'
    position_id: int
    data: Dict[str, Any]
    timestamp: float
    retry_count: int = 0
    max_retries: int = 3
    on_success_callback: callable = None  # ğŸ”§ æ–°å¢ï¼šæˆåŠŸå¾Œçš„å›å‘¼å‡½æ•¸

class AsyncDatabaseUpdater:
    """
    éé˜»å¡è³‡æ–™åº«æ›´æ–°ç®¡ç†å™¨
    
    ç‰¹é»ï¼š
    1. ä¸å½±éŸ¿ç¾æœ‰åŒæ­¥é‚è¼¯
    2. æä¾›å…§å­˜ç·©å­˜åŠ é€Ÿ
    3. å»¶é²æ›´æ–°æ¸›å°‘é˜»å¡
    4. è©³ç´°çš„æ€§èƒ½è¿½è¹¤
    """
    
    def __init__(self, db_manager, console_enabled=True):
        self.db_manager = db_manager
        self.console_enabled = console_enabled

        # ğŸ”‡ æ—¥èªŒæ§åˆ¶é¸é …
        self.enable_peak_update_logs = False  # é—œé–‰å³°å€¼æ›´æ–°æ—¥èªŒ
        self.enable_task_completion_logs = False  # é—œé–‰ä»»å‹™å®Œæˆæ—¥èªŒ
        
        # ğŸ”„ æ›´æ–°éšŠåˆ—
        self.update_queue = queue.Queue(maxsize=1000)
        self.worker_thread = None
        self.running = False

        # ğŸ§¹ æ¸…ç†æ©Ÿåˆ¶
        self.cleanup_interval = 3600  # 1å°æ™‚æ¸…ç†ä¸€æ¬¡
        self.cache_max_age = 7200     # ç·©å­˜æœ€å¤§ä¿ç•™2å°æ™‚
        self.last_cleanup_time = time.time()
        
        # ğŸ’¾ å…§å­˜ç·©å­˜
        self.memory_cache = {
            'positions': {},  # position_id -> position_data
            'risk_states': {},  # position_id -> risk_data
            'exit_positions': {},  # position_id -> exit_data (ğŸ”§ æ–°å¢ï¼šå¹³å€‰ç·©å­˜)
            'peak_updates': {},  # ğŸš€ æ–°å¢ï¼šposition_id -> peak_update_data (é›¶é¢¨éšªå³°å€¼æ›´æ–°)
            'trailing_states': {},  # ğŸ¯ æ–°å¢ï¼šposition_id -> trailing_state_data (ç§»å‹•åœåˆ©ç‹€æ…‹)
            'protection_states': {},  # ğŸ›¡ï¸ æ–°å¢ï¼šposition_id -> protection_state_data (ä¿è­·æ€§åœæç‹€æ…‹)
            'position_status': {},  # ğŸ“Š æ–°å¢ï¼šposition_id -> position_status_data (éƒ¨ä½ç‹€æ…‹)
            'last_updates': {}  # position_id -> timestamp
        }
        
        # ğŸ“Š æ€§èƒ½çµ±è¨ˆ
        self.stats = {
            'total_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'cache_hits': 0,
            'avg_delay': 0.0,
            'max_delay': 0.0,
            'queue_size_peak': 0,
            'trailing_stop_updates': 0  # ğŸ”§ æ–°å¢ï¼šç§»å‹•åœåˆ©æ›´æ–°çµ±è¨ˆ
        }
        
        # ğŸ”’ ç·šç¨‹å®‰å…¨
        self.cache_lock = threading.RLock()
        self.stats_lock = threading.RLock()
        
        # â° æ™‚é–“è¿½è¹¤
        self.start_time = time.time()
        self.last_stats_report = time.time()
        
        if self.console_enabled:
            print("[ASYNC_DB] ğŸš€ éé˜»å¡è³‡æ–™åº«æ›´æ–°å™¨åˆå§‹åŒ–å®Œæˆ")

    def set_log_options(self, enable_peak_logs=False, enable_task_logs=False):
        """è¨­ç½®æ—¥èªŒé¸é …"""
        self.enable_peak_update_logs = enable_peak_logs
        self.enable_task_completion_logs = enable_task_logs
        if self.console_enabled:
            print(f"[ASYNC_DB] ğŸ”‡ æ—¥èªŒé¸é …æ›´æ–°: å³°å€¼æ—¥èªŒ={enable_peak_logs}, ä»»å‹™æ—¥èªŒ={enable_task_logs}")

    def start(self):
        """å•Ÿå‹•ç•°æ­¥æ›´æ–°å·¥ä½œç·šç¨‹"""
        if self.running:
            return
            
        self.running = True
        self.worker_thread = threading.Thread(target=self._worker_loop, daemon=True)
        self.worker_thread.start()
        
        if self.console_enabled:
            print("[ASYNC_DB] âœ… ç•°æ­¥æ›´æ–°å·¥ä½œç·šç¨‹å·²å•Ÿå‹•")
    
    def stop(self):
        """åœæ­¢ç•°æ­¥æ›´æ–°"""
        self.running = False
        if self.worker_thread:
            self.worker_thread.join(timeout=5.0)
            
        if self.console_enabled:
            print("[ASYNC_DB] ğŸ›‘ ç•°æ­¥æ›´æ–°å·¥ä½œç·šç¨‹å·²åœæ­¢")
    
    def schedule_position_fill_update(self, position_id: int, fill_price: float,
                                    fill_time: str, order_status: str = 'FILLED',
                                    on_success_callback=None):
        """
        æ’ç¨‹éƒ¨ä½æˆäº¤æ›´æ–°ï¼ˆéé˜»å¡ï¼‰

        Args:
            position_id: éƒ¨ä½ID
            fill_price: æˆäº¤åƒ¹æ ¼
            fill_time: æˆäº¤æ™‚é–“
            order_status: è¨‚å–®ç‹€æ…‹
            on_success_callback: æˆåŠŸå¾Œçš„å›å‘¼å‡½æ•¸ (å¯é¸)
        """
        start_time = time.time()
        
        # ğŸš€ ç«‹å³æ›´æ–°å…§å­˜ç·©å­˜
        with self.cache_lock:
            self.memory_cache['positions'][position_id] = {
                'id': position_id,
                'fill_price': fill_price,
                'fill_time': fill_time,
                'order_status': order_status,
                'updated_at': start_time
            }
            self.memory_cache['last_updates'][position_id] = start_time
            self.stats['cache_hits'] += 1
        
        # ğŸ“ æ’ç¨‹è³‡æ–™åº«æ›´æ–°
        task = UpdateTask(
            task_type='position_fill',
            position_id=position_id,
            data={
                'fill_price': fill_price,
                'fill_time': fill_time,
                'order_status': order_status
            },
            timestamp=start_time,
            on_success_callback=on_success_callback  # ğŸ”§ æ–°å¢ï¼šå‚³éå›å‘¼å‡½æ•¸
        )
        
        try:
            self.update_queue.put_nowait(task)
            with self.stats_lock:
                self.stats['total_tasks'] += 1
                current_queue_size = self.update_queue.qsize()
                if current_queue_size > self.stats['queue_size_peak']:
                    self.stats['queue_size_peak'] = current_queue_size
                    
            if self.console_enabled:
                elapsed = (time.time() - start_time) * 1000
                print(f"[ASYNC_DB] ğŸ“ æ’ç¨‹éƒ¨ä½{position_id}æˆäº¤æ›´æ–° @{fill_price} (è€—æ™‚:{elapsed:.1f}ms)")
                
        except queue.Full:
            logger.warning(f"æ›´æ–°éšŠåˆ—å·²æ»¿ï¼Œè·³ééƒ¨ä½{position_id}çš„ç•°æ­¥æ›´æ–°")
            if self.console_enabled:
                print(f"[ASYNC_DB] âš ï¸ éšŠåˆ—å·²æ»¿ï¼Œè·³ééƒ¨ä½{position_id}ç•°æ­¥æ›´æ–°")

    def schedule_position_exit_update(self, position_id: int, exit_price: float,
                                    exit_time: str, exit_reason: str = 'æ‰‹å‹•å‡ºå ´',
                                    order_id: str = None, pnl: float = 0.0):
        """
        æ’ç¨‹éƒ¨ä½å¹³å€‰æ›´æ–°ï¼ˆéé˜»å¡ï¼‰- ğŸ”§ æ–°å¢ï¼šåƒè€ƒå»ºå€‰é‚è¼¯

        Args:
            position_id: éƒ¨ä½ID
            exit_price: å¹³å€‰åƒ¹æ ¼
            exit_time: å¹³å€‰æ™‚é–“
            exit_reason: å¹³å€‰åŸå› 
            order_id: è¨‚å–®ID
            pnl: æç›Š
        """
        start_time = time.time()

        # ğŸš€ ç«‹å³æ›´æ–°å…§å­˜ç·©å­˜ï¼ˆåƒè€ƒå»ºå€‰é‚è¼¯ï¼‰
        with self.cache_lock:
            self.memory_cache['exit_positions'][position_id] = {
                'id': position_id,
                'status': 'EXITED',
                'exit_price': exit_price,
                'exit_time': exit_time,
                'exit_reason': exit_reason,
                'order_id': order_id,
                'pnl': pnl,
                'updated_at': start_time
            }
            self.memory_cache['last_updates'][position_id] = start_time
            self.stats['cache_hits'] += 1

        # ğŸ“ æ’ç¨‹è³‡æ–™åº«æ›´æ–°ï¼ˆåƒè€ƒå»ºå€‰é‚è¼¯ï¼‰
        task = UpdateTask(
            task_type='position_exit',
            position_id=position_id,
            data={
                'exit_price': exit_price,
                'exit_time': exit_time,
                'exit_reason': exit_reason,
                'order_id': order_id,
                'pnl': pnl
            },
            timestamp=start_time
        )

        try:
            self.update_queue.put_nowait(task)
            with self.stats_lock:
                self.stats['total_tasks'] += 1
                current_queue_size = self.update_queue.qsize()
                if current_queue_size > self.stats['queue_size_peak']:
                    self.stats['queue_size_peak'] = current_queue_size

            if self.console_enabled:
                elapsed = (time.time() - start_time) * 1000
                print(f"[ASYNC_DB] ğŸ“ æ’ç¨‹éƒ¨ä½{position_id}å¹³å€‰æ›´æ–° @{exit_price} åŸå› :{exit_reason} (è€—æ™‚:{elapsed:.1f}ms)")

        except queue.Full:
            logger.warning(f"æ›´æ–°éšŠåˆ—å·²æ»¿ï¼Œè·³ééƒ¨ä½{position_id}çš„å¹³å€‰ç•°æ­¥æ›´æ–°")
            if self.console_enabled:
                print(f"[ASYNC_DB] âš ï¸ éšŠåˆ—å·²æ»¿ï¼Œè·³ééƒ¨ä½{position_id}å¹³å€‰ç•°æ­¥æ›´æ–°")
    
    def schedule_risk_state_creation(self, position_id: int, peak_price: float,
                                   current_time: str, update_category: str = "åˆå§‹åŒ–",
                                   update_message: str = "ç•°æ­¥åˆå§‹åŒ–"):
        """
        æ’ç¨‹é¢¨éšªç®¡ç†ç‹€æ…‹å‰µå»ºï¼ˆéé˜»å¡ï¼‰

        Args:
            position_id: éƒ¨ä½ID
            peak_price: å³°å€¼åƒ¹æ ¼
            current_time: ç•¶å‰æ™‚é–“
            update_category: æ›´æ–°åˆ†é¡
            update_message: æ›´æ–°è©³ç´°è¨Šæ¯
        """
        start_time = time.time()
        
        # ğŸš€ ç«‹å³æ›´æ–°å…§å­˜ç·©å­˜
        with self.cache_lock:
            self.memory_cache['risk_states'][position_id] = {
                'position_id': position_id,
                'peak_price': peak_price,
                'current_time': current_time,
                'update_category': update_category,
                'update_message': update_message,
                'updated_at': start_time
            }
            self.stats['cache_hits'] += 1

        # ğŸ“ æ’ç¨‹è³‡æ–™åº«æ›´æ–°
        task = UpdateTask(
            task_type='risk_state',
            position_id=position_id,
            data={
                'peak_price': peak_price,
                'current_time': current_time,
                'update_category': update_category,
                'update_message': update_message
            },
            timestamp=start_time
        )
        
        try:
            self.update_queue.put_nowait(task)
            with self.stats_lock:
                self.stats['total_tasks'] += 1
                
            if self.console_enabled:
                elapsed = (time.time() - start_time) * 1000
                print(f"[ASYNC_DB] ğŸ“ æ’ç¨‹é¢¨éšªç‹€æ…‹{position_id}å‰µå»º å³°å€¼:{peak_price} (è€—æ™‚:{elapsed:.1f}ms)")
                
        except queue.Full:
            logger.warning(f"æ›´æ–°éšŠåˆ—å·²æ»¿ï¼Œè·³ééƒ¨ä½{position_id}çš„é¢¨éšªç‹€æ…‹ç•°æ­¥æ›´æ–°")

    def schedule_peak_update(self, position_id: int, peak_price: float,
                           update_time: str, update_category: str = "åƒ¹æ ¼æ›´æ–°",
                           update_message: str = "å³°å€¼æ›´æ–°"):
        """
        ğŸš€ é›¶é¢¨éšªå³°å€¼æ›´æ–°æ’ç¨‹ï¼ˆå¯é¸åŠŸèƒ½ï¼Œé è¨­ä¸å•Ÿç”¨ï¼‰

        Args:
            position_id: éƒ¨ä½ID
            peak_price: æ–°å³°å€¼åƒ¹æ ¼
            update_time: æ›´æ–°æ™‚é–“
            update_category: æ›´æ–°åˆ†é¡
            update_message: æ›´æ–°è©³ç´°è¨Šæ¯
        """
        start_time = time.time()

        # ğŸš€ ç«‹å³æ›´æ–°å…§å­˜ç·©å­˜
        with self.cache_lock:
            self.memory_cache['peak_updates'][position_id] = {
                'position_id': position_id,
                'peak_price': peak_price,
                'update_time': update_time,
                'update_category': update_category,
                'update_message': update_message,
                'updated_at': start_time
            }
            self.stats['cache_hits'] += 1

        # ğŸ“ æ’ç¨‹è³‡æ–™åº«æ›´æ–°
        task = UpdateTask(
            task_type='peak_update',
            position_id=position_id,
            data={
                'peak_price': peak_price,
                'update_time': update_time,
                'update_category': update_category,
                'update_message': update_message
            },
            timestamp=start_time
        )

        try:
            self.update_queue.put_nowait(task)
            with self.stats_lock:
                self.stats['total_tasks'] += 1

            # ğŸ”‡ é—œé–‰å³°å€¼æ›´æ–°æ’ç¨‹æ—¥èªŒï¼ˆé¿å…éå¤šè¼¸å‡ºï¼‰
            if self.console_enabled and False:  # æš«æ™‚é—œé–‰
                elapsed = (time.time() - start_time) * 1000
                print(f"[ASYNC_DB] ğŸ“ˆ æ’ç¨‹å³°å€¼æ›´æ–° éƒ¨ä½{position_id} å³°å€¼:{peak_price} (è€—æ™‚:{elapsed:.1f}ms)")

        except queue.Full:
            logger.warning(f"æ›´æ–°éšŠåˆ—å·²æ»¿ï¼Œè·³ééƒ¨ä½{position_id}çš„å³°å€¼ç•°æ­¥æ›´æ–°")

    def get_cached_peak(self, position_id: int) -> Optional[Dict]:
        """å¾å…§å­˜ç·©å­˜ç²å–æœ€æ–°å³°å€¼"""
        with self.cache_lock:
            return self.memory_cache['peak_updates'].get(position_id)

    def schedule_trailing_activation_update(self, position_id: int, trailing_activated: bool,
                                          peak_price: float, update_time: str,
                                          update_category: str = "ç§»å‹•åœåˆ©å•Ÿå‹•",
                                          update_message: str = "ç§»å‹•åœåˆ©å•Ÿå‹•"):
        """
        ğŸš€ æ’ç¨‹ç§»å‹•åœåˆ©å•Ÿå‹•æ›´æ–°ï¼ˆéé˜»å¡ï¼Œè§£æ±ºå»¶é²å•é¡Œï¼‰

        Args:
            position_id: éƒ¨ä½ID
            trailing_activated: ç§»å‹•åœåˆ©å•Ÿå‹•ç‹€æ…‹
            peak_price: å³°å€¼åƒ¹æ ¼
            update_time: æ›´æ–°æ™‚é–“
            update_category: æ›´æ–°åˆ†é¡
            update_message: æ›´æ–°è©³ç´°è¨Šæ¯
        """
        start_time = time.time()

        # ğŸš€ ç«‹å³æ›´æ–°å…§å­˜ç·©å­˜ï¼ˆç§»å‹•åœåˆ©ç‹€æ…‹ï¼‰
        with self.cache_lock:
            # æ›´æ–°ç§»å‹•åœåˆ©ç‹€æ…‹ç·©å­˜
            if 'trailing_states' not in self.memory_cache:
                self.memory_cache['trailing_states'] = {}

            self.memory_cache['trailing_states'][position_id] = {
                'position_id': position_id,
                'trailing_activated': trailing_activated,
                'peak_price': peak_price,
                'update_time': update_time,
                'update_category': update_category,
                'update_message': update_message,
                'updated_at': start_time
            }

            # åŒæ™‚æ›´æ–°å³°å€¼ç·©å­˜
            self.memory_cache['peak_updates'][position_id] = {
                'position_id': position_id,
                'peak_price': peak_price,
                'update_time': update_time,
                'update_category': update_category,
                'update_message': update_message,
                'updated_at': start_time
            }

            self.stats['cache_hits'] += 1

        # ğŸ“ æ’ç¨‹è³‡æ–™åº«æ›´æ–°
        task = UpdateTask(
            task_type='trailing_activation',
            position_id=position_id,
            data={
                'trailing_activated': trailing_activated,
                'peak_price': peak_price,
                'update_time': update_time,
                'update_category': update_category,
                'update_message': update_message
            },
            timestamp=start_time
        )

        try:
            self.update_queue.put_nowait(task)
            with self.stats_lock:
                self.stats['total_tasks'] += 1

            if self.console_enabled:
                elapsed = (time.time() - start_time) * 1000
                print(f"[ASYNC_DB] ğŸ¯ æ’ç¨‹ç§»å‹•åœåˆ©å•Ÿå‹• éƒ¨ä½{position_id} (è€—æ™‚:{elapsed:.1f}ms)")

        except queue.Full:
            logger.warning(f"æ›´æ–°éšŠåˆ—å·²æ»¿ï¼Œè·³ééƒ¨ä½{position_id}çš„ç§»å‹•åœåˆ©å•Ÿå‹•ç•°æ­¥æ›´æ–°")

    def get_cached_trailing_state(self, position_id: int) -> Optional[Dict]:
        """å¾å…§å­˜ç·©å­˜ç²å–æœ€æ–°ç§»å‹•åœåˆ©ç‹€æ…‹"""
        with self.cache_lock:
            return self.memory_cache.get('trailing_states', {}).get(position_id)

    def schedule_protection_update(self, position_id: int, current_stop_loss: float,
                                 protection_activated: bool, update_time: str,
                                 update_category: str = "ä¿è­·æ€§åœææ›´æ–°",
                                 update_message: str = "ä¿è­·æ€§åœææ›´æ–°"):
        """
        ğŸš€ æ’ç¨‹ä¿è­·æ€§åœææ›´æ–°ï¼ˆéé˜»å¡ï¼Œè§£æ±ºå»¶é²å•é¡Œï¼‰

        Args:
            position_id: éƒ¨ä½ID
            current_stop_loss: æ–°åœæåƒ¹æ ¼
            protection_activated: ä¿è­·æ€§åœæå•Ÿå‹•ç‹€æ…‹
            update_time: æ›´æ–°æ™‚é–“
            update_category: æ›´æ–°åˆ†é¡
            update_message: æ›´æ–°è©³ç´°è¨Šæ¯
        """
        start_time = time.time()

        # ğŸš€ ç«‹å³æ›´æ–°å…§å­˜ç·©å­˜ï¼ˆä¿è­·æ€§åœæç‹€æ…‹ï¼‰
        with self.cache_lock:
            # æ›´æ–°ä¿è­·æ€§åœæç‹€æ…‹ç·©å­˜
            if 'protection_states' not in self.memory_cache:
                self.memory_cache['protection_states'] = {}

            self.memory_cache['protection_states'][position_id] = {
                'position_id': position_id,
                'current_stop_loss': current_stop_loss,
                'protection_activated': protection_activated,
                'update_time': update_time,
                'update_category': update_category,
                'update_message': update_message,
                'updated_at': start_time
            }

            self.stats['cache_hits'] += 1

        # ğŸ“ æ’ç¨‹è³‡æ–™åº«æ›´æ–°
        task = UpdateTask(
            task_type='protection_update',
            position_id=position_id,
            data={
                'current_stop_loss': current_stop_loss,
                'protection_activated': protection_activated,
                'update_time': update_time,
                'update_category': update_category,
                'update_message': update_message
            },
            timestamp=start_time
        )

        try:
            self.update_queue.put_nowait(task)
            with self.stats_lock:
                self.stats['total_tasks'] += 1

            if self.console_enabled:
                elapsed = (time.time() - start_time) * 1000
                print(f"[ASYNC_DB] ğŸ›¡ï¸ æ’ç¨‹ä¿è­·æ€§åœææ›´æ–° éƒ¨ä½{position_id} åœæ:{current_stop_loss:.0f} (è€—æ™‚:{elapsed:.1f}ms)")

        except queue.Full:
            logger.warning(f"æ›´æ–°éšŠåˆ—å·²æ»¿ï¼Œè·³ééƒ¨ä½{position_id}çš„ä¿è­·æ€§åœæç•°æ­¥æ›´æ–°")

    def schedule_position_status_update(self, position_id: int, status: str,
                                      exit_reason: str = None, exit_price: float = None,
                                      update_reason: str = "éƒ¨ä½ç‹€æ…‹æ›´æ–°"):
        """
        ğŸš€ æ’ç¨‹éƒ¨ä½ç‹€æ…‹æ›´æ–°ï¼ˆéé˜»å¡ï¼Œè§£æ±ºå¹³å€‰å»¶é²å•é¡Œï¼‰

        Args:
            position_id: éƒ¨ä½ID
            status: éƒ¨ä½ç‹€æ…‹
            exit_reason: å‡ºå ´åŸå› 
            exit_price: å‡ºå ´åƒ¹æ ¼
            update_reason: æ›´æ–°åŸå› 
        """
        start_time = time.time()

        # ğŸš€ ç«‹å³æ›´æ–°å…§å­˜ç·©å­˜ï¼ˆéƒ¨ä½ç‹€æ…‹ï¼‰
        with self.cache_lock:
            # æ›´æ–°éƒ¨ä½ç‹€æ…‹ç·©å­˜
            if 'position_status' not in self.memory_cache:
                self.memory_cache['position_status'] = {}

            self.memory_cache['position_status'][position_id] = {
                'position_id': position_id,
                'status': status,
                'exit_reason': exit_reason,
                'exit_price': exit_price,
                'update_reason': update_reason,
                'updated_at': start_time
            }

            self.stats['cache_hits'] += 1

        # ğŸ“ æ’ç¨‹è³‡æ–™åº«æ›´æ–°
        task = UpdateTask(
            task_type='position_status',
            position_id=position_id,
            data={
                'status': status,
                'exit_reason': exit_reason,
                'exit_price': exit_price,
                'update_reason': update_reason
            },
            timestamp=start_time
        )

        try:
            self.update_queue.put_nowait(task)
            with self.stats_lock:
                self.stats['total_tasks'] += 1

            if self.console_enabled:
                elapsed = (time.time() - start_time) * 1000
                print(f"[ASYNC_DB] ğŸ“Š æ’ç¨‹éƒ¨ä½ç‹€æ…‹æ›´æ–° éƒ¨ä½{position_id} ç‹€æ…‹:{status} (è€—æ™‚:{elapsed:.1f}ms)")

        except queue.Full:
            logger.warning(f"æ›´æ–°éšŠåˆ—å·²æ»¿ï¼Œè·³ééƒ¨ä½{position_id}çš„ç‹€æ…‹ç•°æ­¥æ›´æ–°")

    def get_cached_position(self, position_id: int) -> Optional[Dict]:
        """å¾å…§å­˜ç·©å­˜ç²å–éƒ¨ä½ä¿¡æ¯"""
        with self.cache_lock:
            return self.memory_cache['positions'].get(position_id)
    
    def get_cached_risk_state(self, position_id: int) -> Optional[Dict]:
        """å¾å…§å­˜ç·©å­˜ç²å–é¢¨éšªç‹€æ…‹ä¿¡æ¯"""
        with self.cache_lock:
            return self.memory_cache['risk_states'].get(position_id)

    def get_cached_exit_status(self, position_id: int) -> Optional[Dict]:
        """å¾å…§å­˜ç·©å­˜ç²å–å¹³å€‰ç‹€æ…‹ä¿¡æ¯ - ğŸ”§ æ–°å¢ï¼šåƒè€ƒå»ºå€‰ç·©å­˜é‚è¼¯"""
        with self.cache_lock:
            return self.memory_cache['exit_positions'].get(position_id)

    def is_position_exited_in_cache(self, position_id: int) -> bool:
        """æª¢æŸ¥éƒ¨ä½æ˜¯å¦åœ¨ç·©å­˜ä¸­æ¨™è¨˜ç‚ºå·²å¹³å€‰ - ğŸ”§ æ–°å¢ï¼šå¿«é€Ÿç‹€æ…‹æª¢æŸ¥"""
        cached_exit = self.get_cached_exit_status(position_id)
        return cached_exit is not None and cached_exit.get('status') == 'EXITED'

    def cleanup_old_cache_entries(self, force_cleanup: bool = False):
        """
        ğŸ§¹ æ¸…ç†éæœŸçš„å…§å­˜ç·©å­˜æ¢ç›®ï¼ˆé˜²æ­¢é•·æ™‚é–“é‹è¡Œçš„å…§å­˜ç´¯ç©ï¼‰

        Args:
            force_cleanup: æ˜¯å¦å¼·åˆ¶æ¸…ç†
        """
        current_time = time.time()

        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†
        if not force_cleanup and (current_time - self.last_cleanup_time) < self.cleanup_interval:
            return

        try:
            with self.cache_lock:
                cleaned_count = 0

                # æ¸…ç†å„é¡ç·©å­˜ä¸­çš„éæœŸæ¢ç›®
                for cache_type in ['positions', 'risk_states', 'exit_positions',
                                 'peak_updates', 'trailing_states', 'protection_states',
                                 'position_status']:

                    if cache_type not in self.memory_cache:
                        continue

                    cache = self.memory_cache[cache_type]
                    expired_keys = []

                    for key, data in cache.items():
                        if isinstance(data, dict) and 'updated_at' in data:
                            age = current_time - data['updated_at']
                            if age > self.cache_max_age:
                                expired_keys.append(key)

                    # ç§»é™¤éæœŸæ¢ç›®
                    for key in expired_keys:
                        del cache[key]
                        cleaned_count += 1

                # æ¸…ç†last_updates
                if 'last_updates' in self.memory_cache:
                    expired_keys = []
                    for position_id, timestamp in self.memory_cache['last_updates'].items():
                        if (current_time - timestamp) > self.cache_max_age:
                            expired_keys.append(position_id)

                    for key in expired_keys:
                        del self.memory_cache['last_updates'][key]
                        cleaned_count += 1

                self.last_cleanup_time = current_time

                if self.console_enabled and cleaned_count > 0:
                    print(f"[ASYNC_DB] ğŸ§¹ æ¸…ç†éæœŸç·©å­˜æ¢ç›®: {cleaned_count}å€‹")

        except Exception as e:
            logger.error(f"æ¸…ç†å…§å­˜ç·©å­˜å¤±æ•—: {e}")
            if self.console_enabled:
                print(f"[ASYNC_DB] âŒ æ¸…ç†å…§å­˜ç·©å­˜å¤±æ•—: {e}")
    
    def _worker_loop(self):
        """å·¥ä½œç·šç¨‹ä¸»å¾ªç’°"""
        if self.console_enabled:
            print("[ASYNC_DB] ğŸ”„ ç•°æ­¥æ›´æ–°å·¥ä½œç·šç¨‹é–‹å§‹é‹è¡Œ")
            
        while self.running:
            try:
                # ç­‰å¾…æ›´æ–°ä»»å‹™ï¼ˆæœ€å¤šç­‰å¾…1ç§’ï¼‰
                task = self.update_queue.get(timeout=1.0)
                self._process_update_task(task)
                self.update_queue.task_done()
                
            except queue.Empty:
                # å®šæœŸå ±å‘Šçµ±è¨ˆä¿¡æ¯
                self._report_stats_if_needed()

                # ğŸ§¹ å®šæœŸæ¸…ç†å…§å­˜ç·©å­˜ï¼ˆåœ¨ç©ºé–’æ™‚åŸ·è¡Œï¼‰
                self.cleanup_old_cache_entries()
                continue
            except Exception as e:
                logger.error(f"ç•°æ­¥æ›´æ–°å·¥ä½œç·šç¨‹éŒ¯èª¤: {e}")
                if self.console_enabled:
                    print(f"[ASYNC_DB] âŒ å·¥ä½œç·šç¨‹éŒ¯èª¤: {e}")
    
    def _process_update_task(self, task: UpdateTask):
        """è™•ç†å–®å€‹æ›´æ–°ä»»å‹™"""
        start_time = time.time()
        delay = start_time - task.timestamp
        
        try:
            if task.task_type == 'position_fill':
                # ä»»å‹™4è¨ºæ–·ï¼šæ·»åŠ è©³ç´°çš„è™•ç†æ—¥èªŒ
                if self.console_enabled:
                    print(f"[ASYNC_DB] ğŸ”„ è™•ç†éƒ¨ä½æˆäº¤ä»»å‹™: éƒ¨ä½{task.position_id}")
                    print(f"[ASYNC_DB]   æˆäº¤åƒ¹æ ¼: {task.data['fill_price']}")
                    print(f"[ASYNC_DB]   æˆäº¤æ™‚é–“: {task.data['fill_time']}")
                    print(f"[ASYNC_DB]   è¨‚å–®ç‹€æ…‹: {task.data['order_status']}")

                success = self.db_manager.confirm_position_filled(
                    position_id=task.position_id,
                    actual_fill_price=task.data['fill_price'],
                    fill_time=task.data['fill_time'],
                    order_status=task.data['order_status']
                )

                # âœ… ä»»å‹™1ï¼šæ·»åŠ æˆåŠŸæ—¥èªŒï¼Œç¢ºèªç•°æ­¥è³‡æ–™åº«å¯«å…¥ä»»å‹™æœ€çµ‚æˆåŠŸåŸ·è¡Œ
                if success:
                    if self.console_enabled:
                        print(f"âœ… [ASYNC_DB] è³‡æ–™åº«å¯«å…¥æˆåŠŸ: éƒ¨ä½ {task.position_id}ï¼Œentry_price æ›´æ–°ç‚º {task.data['fill_price']}")
                else:
                    if self.console_enabled:
                        print(f"âŒ [ASYNC_DB] éƒ¨ä½ {task.position_id} æˆäº¤ç¢ºèªå¤±æ•—")

                # ğŸ”§ æ–°å¢ï¼šæˆåŠŸå¾ŒåŸ·è¡Œå›å‘¼å‡½æ•¸
                if success and task.on_success_callback:
                    try:
                        task.on_success_callback(task.position_id)
                        if self.console_enabled:
                            print(f"[ASYNC_DB] âœ… éƒ¨ä½{task.position_id}æˆäº¤ç¢ºèªå›å‘¼åŸ·è¡ŒæˆåŠŸ")
                    except Exception as callback_error:
                        logger.error(f"æˆäº¤ç¢ºèªå›å‘¼åŸ·è¡Œå¤±æ•—: {callback_error}")
                        if self.console_enabled:
                            print(f"[ASYNC_DB] âŒ éƒ¨ä½{task.position_id}æˆäº¤ç¢ºèªå›å‘¼å¤±æ•—: {callback_error}")
            elif task.task_type == 'risk_state':
                # ğŸ”§ ä¿®å¾©ï¼šæª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨é¢¨éšªç®¡ç†ç‹€æ…‹ï¼Œé¿å…é‡è¤‡å‰µå»º
                try:
                    # å…ˆå˜—è©¦å‰µå»º
                    success = self.db_manager.create_risk_management_state(
                        position_id=task.position_id,
                        peak_price=task.data['peak_price'],
                        current_time=task.data['current_time'],
                        update_category=task.data['update_category'],
                        update_message=task.data['update_message']
                    )
                except Exception as create_error:
                    # å¦‚æœå‰µå»ºå¤±æ•—ï¼ˆå¯èƒ½æ˜¯é‡è¤‡ï¼‰ï¼Œå˜—è©¦æ›´æ–°
                    if "UNIQUE constraint failed" in str(create_error) or "already exists" in str(create_error):
                        try:
                            success = self.db_manager.update_risk_management_state(
                                position_id=task.position_id,
                                peak_price=task.data['peak_price'],
                                update_time=task.data['current_time'],
                                update_category=task.data['update_category'],
                                update_message=f"ç•°æ­¥æ›´æ–°-{task.data['update_message']}"
                            )
                            if self.console_enabled:
                                print(f"[ASYNC_DB] ğŸ”„ é¢¨éšªç‹€æ…‹å·²å­˜åœ¨ï¼Œæ”¹ç‚ºæ›´æ–°: éƒ¨ä½{task.position_id}")
                        except Exception as update_error:
                            success = False
                            logger.error(f"é¢¨éšªç‹€æ…‹æ›´æ–°ä¹Ÿå¤±æ•—: {update_error}")
                    else:
                        success = False
                        logger.error(f"é¢¨éšªç‹€æ…‹å‰µå»ºå¤±æ•—: {create_error}")
                        raise create_error
            elif task.task_type == 'position_exit':
                # ğŸ”§ æ–°å¢ï¼šè™•ç†å¹³å€‰ä»»å‹™ï¼ˆåƒè€ƒå»ºå€‰è™•ç†é‚è¼¯ï¼‰
                success = self._process_position_exit_task(task)
            elif task.task_type == 'peak_update':
                # ğŸš€ æ–°å¢ï¼šè™•ç†å³°å€¼æ›´æ–°ä»»å‹™ï¼ˆé›¶é¢¨éšªï¼‰
                success = self.db_manager.update_risk_management_state(
                    position_id=task.position_id,
                    peak_price=task.data['peak_price'],
                    update_time=task.data['update_time'],
                    update_category=task.data['update_category'],
                    update_message=task.data['update_message']
                )

                # ğŸ”‡ é—œé–‰å³°å€¼æ›´æ–°å®Œæˆæ—¥èªŒï¼ˆé¿å…éå¤šè¼¸å‡ºï¼‰
                if self.console_enabled and success and False:  # æš«æ™‚é—œé–‰
                    processing_time = (time.time() - start_time) * 1000
                    print(f"[ASYNC_DB] âœ… å®Œæˆå³°å€¼æ›´æ–° éƒ¨ä½:{task.position_id} å³°å€¼:{task.data['peak_price']} å»¶é²:{delay*1000:.1f}ms è™•ç†:{processing_time:.1f}ms")
            elif task.task_type == 'trailing_activation':
                # ğŸ¯ æ–°å¢ï¼šè™•ç†ç§»å‹•åœåˆ©å•Ÿå‹•ä»»å‹™ï¼ˆè§£æ±ºå»¶é²å•é¡Œï¼‰
                success = self.db_manager.update_risk_management_state(
                    position_id=task.position_id,
                    trailing_activated=task.data['trailing_activated'],
                    peak_price=task.data['peak_price'],
                    update_time=task.data['update_time'],
                    update_category=task.data['update_category'],
                    update_message=task.data['update_message']
                )

                if self.console_enabled and success:
                    processing_time = (time.time() - start_time) * 1000
                    print(f"[ASYNC_DB] âœ… å®Œæˆç§»å‹•åœåˆ©å•Ÿå‹• éƒ¨ä½:{task.position_id} å»¶é²:{delay*1000:.1f}ms è™•ç†:{processing_time:.1f}ms")
            elif task.task_type == 'protection_update':
                # ğŸ›¡ï¸ æ–°å¢ï¼šè™•ç†ä¿è­·æ€§åœææ›´æ–°ä»»å‹™ï¼ˆè§£æ±ºå»¶é²å•é¡Œï¼‰
                success = self.db_manager.update_risk_management_state(
                    position_id=task.position_id,
                    current_stop_loss=task.data['current_stop_loss'],
                    protection_activated=task.data['protection_activated'],
                    update_time=task.data['update_time'],
                    update_category=task.data['update_category'],
                    update_message=task.data['update_message']
                )

                if self.console_enabled and success:
                    processing_time = (time.time() - start_time) * 1000
                    print(f"[ASYNC_DB] âœ… å®Œæˆä¿è­·æ€§åœææ›´æ–° éƒ¨ä½:{task.position_id} åœæ:{task.data['current_stop_loss']:.0f} å»¶é²:{delay*1000:.1f}ms è™•ç†:{processing_time:.1f}ms")
            elif task.task_type == 'position_status':
                # ğŸ“Š æ–°å¢ï¼šè™•ç†éƒ¨ä½ç‹€æ…‹æ›´æ–°ä»»å‹™ï¼ˆè§£æ±ºå¹³å€‰å»¶é²å•é¡Œï¼‰
                success = self.db_manager.update_position_status(
                    position_id=task.position_id,
                    status=task.data['status'],
                    exit_reason=task.data.get('exit_reason'),
                    exit_price=task.data.get('exit_price')
                )

                if self.console_enabled and success:
                    processing_time = (time.time() - start_time) * 1000
                    print(f"[ASYNC_DB] âœ… å®Œæˆéƒ¨ä½ç‹€æ…‹æ›´æ–° éƒ¨ä½:{task.position_id} ç‹€æ…‹:{task.data['status']} å»¶é²:{delay*1000:.1f}ms è™•ç†:{processing_time:.1f}ms")
            elif task.task_type == 'trailing_stop_update':
                # ğŸ”§ æ–°å¢ï¼šè™•ç†ç§»å‹•åœåˆ©æ›´æ–°ä»»å‹™
                success = self._process_trailing_stop_update_task(task)
            else:
                logger.warning(f"æœªçŸ¥çš„ä»»å‹™é¡å‹: {task.task_type}")
                return
            
            # ğŸ“Š æ›´æ–°çµ±è¨ˆ
            with self.stats_lock:
                if success:
                    self.stats['completed_tasks'] += 1
                else:
                    self.stats['failed_tasks'] += 1
                
                # æ›´æ–°å»¶é²çµ±è¨ˆ
                if delay > self.stats['max_delay']:
                    self.stats['max_delay'] = delay
                
                total_completed = self.stats['completed_tasks'] + self.stats['failed_tasks']
                if total_completed > 0:
                    self.stats['avg_delay'] = (
                        (self.stats['avg_delay'] * (total_completed - 1) + delay) / total_completed
                    )
            
            # ğŸ”‡ å¯æ§çš„ä»»å‹™å®Œæˆæ—¥èªŒï¼ˆé¿å…peak_updateç­‰éå¤šè¼¸å‡ºï¼‰
            if self.console_enabled and self.enable_task_completion_logs:
                elapsed = (time.time() - start_time) * 1000
                status = "âœ…" if success else "âŒ"
                print(f"[ASYNC_DB] {status} å®Œæˆ{task.task_type}æ›´æ–° éƒ¨ä½:{task.position_id} "
                      f"å»¶é²:{delay*1000:.1f}ms è™•ç†:{elapsed:.1f}ms")
                
        except Exception as e:
            logger.error(f"è™•ç†æ›´æ–°ä»»å‹™å¤±æ•—: {e}")
            with self.stats_lock:
                self.stats['failed_tasks'] += 1
            
            # é‡è©¦æ©Ÿåˆ¶
            if task.retry_count < task.max_retries:
                task.retry_count += 1
                try:
                    self.update_queue.put_nowait(task)
                    if self.console_enabled:
                        print(f"[ASYNC_DB] ğŸ”„ é‡è©¦ä»»å‹™ éƒ¨ä½:{task.position_id} æ¬¡æ•¸:{task.retry_count}")
                except queue.Full:
                    logger.warning(f"é‡è©¦éšŠåˆ—å·²æ»¿ï¼Œæ”¾æ£„éƒ¨ä½{task.position_id}çš„æ›´æ–°")
    
    def _report_stats_if_needed(self):
        """å®šæœŸå ±å‘Šçµ±è¨ˆä¿¡æ¯"""
        current_time = time.time()
        if current_time - self.last_stats_report >= 30.0:  # æ¯30ç§’å ±å‘Šä¸€æ¬¡
            self.report_performance_stats()
            self.last_stats_report = current_time
    
    def report_performance_stats(self):
        """å ±å‘Šæ€§èƒ½çµ±è¨ˆ"""
        with self.stats_lock:
            uptime = time.time() - self.start_time
            queue_size = self.update_queue.qsize()
            
            if self.console_enabled:
                print(f"\n[ASYNC_DB] ğŸ“Š æ€§èƒ½çµ±è¨ˆå ±å‘Š (é‹è¡Œæ™‚é–“: {uptime:.1f}s)")
                print(f"  ç¸½ä»»å‹™æ•¸: {self.stats['total_tasks']}")
                print(f"  å®Œæˆä»»å‹™: {self.stats['completed_tasks']}")
                print(f"  å¤±æ•—ä»»å‹™: {self.stats['failed_tasks']}")
                print(f"  ç·©å­˜å‘½ä¸­: {self.stats['cache_hits']}")
                print(f"  å¹³å‡å»¶é²: {self.stats['avg_delay']*1000:.1f}ms")
                print(f"  æœ€å¤§å»¶é²: {self.stats['max_delay']*1000:.1f}ms")
                print(f"  ç•¶å‰éšŠåˆ—: {queue_size}")
                print(f"  éšŠåˆ—å³°å€¼: {self.stats['queue_size_peak']}")
                
                if self.stats['total_tasks'] > 0:
                    success_rate = (self.stats['completed_tasks'] / self.stats['total_tasks']) * 100
                    print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
                print()
    
    def get_stats(self) -> Dict:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        with self.stats_lock:
            return self.stats.copy()

    def _process_position_exit_task(self, task: UpdateTask) -> bool:
        """
        è™•ç†å¹³å€‰ä»»å‹™ - ğŸ”§ æ–°å¢ï¼šåƒè€ƒå»ºå€‰ä»»å‹™è™•ç†é‚è¼¯

        Args:
            task: å¹³å€‰æ›´æ–°ä»»å‹™

        Returns:
            bool: è™•ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            # æª¢æŸ¥è³‡æ–™åº«ç®¡ç†å™¨æ˜¯å¦æœ‰å¹³å€‰æ›´æ–°æ–¹æ³•
            if hasattr(self.db_manager, 'update_position_exit_status'):
                # ä½¿ç”¨å°ˆç”¨çš„å¹³å€‰æ›´æ–°æ–¹æ³•
                success = self.db_manager.update_position_exit_status(
                    position_id=task.position_id,  # ä¿æŒèˆ‡db_manageråƒæ•¸ä¸€è‡´
                    exit_price=task.data['exit_price'],
                    exit_time=task.data['exit_time'],
                    exit_reason=task.data['exit_reason'],
                    order_id=task.data.get('order_id'),
                    pnl=task.data.get('pnl', 0.0)
                )
            else:
                # å›é€€åˆ°é€šç”¨çš„è³‡æ–™åº«æ›´æ–°æ–¹æ³•
                success = self._update_position_exit_fallback(task)

            if self.console_enabled and success:
                print(f"[ASYNC_DB] âœ… å¹³å€‰ç‹€æ…‹æ›´æ–°æˆåŠŸ: éƒ¨ä½{task.position_id} "
                      f"@{task.data['exit_price']} åŸå› :{task.data['exit_reason']}")

            return success

        except Exception as e:
            logger.error(f"è™•ç†å¹³å€‰ä»»å‹™å¤±æ•—: {e}")
            if self.console_enabled:
                print(f"[ASYNC_DB] âŒ å¹³å€‰ä»»å‹™è™•ç†å¤±æ•—: éƒ¨ä½{task.position_id} éŒ¯èª¤:{e}")
            return False

    def _update_position_exit_fallback(self, task: UpdateTask) -> bool:
        """
        å¹³å€‰æ›´æ–°å›é€€æ–¹æ³• - ğŸ”§ æ–°å¢ï¼šç•¶å°ˆç”¨æ–¹æ³•ä¸å­˜åœ¨æ™‚ä½¿ç”¨

        Args:
            task: å¹³å€‰æ›´æ–°ä»»å‹™

        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            # ä½¿ç”¨åŸæœ‰çš„è³‡æ–™åº«é€£æ¥æ–¹å¼æ›´æ–°
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()

                # æ›´æ–° position_records è¡¨
                cursor.execute('''
                    UPDATE position_records
                    SET status = 'EXITED',
                        exit_price = ?,
                        exit_time = ?,
                        exit_reason = ?,
                        pnl = ?,
                        updated_at = CURRENT_TIMESTAMP
                    WHERE id = ?
                ''', (
                    task.data['exit_price'],
                    task.data['exit_time'],
                    task.data['exit_reason'],
                    task.data.get('pnl', 0.0),
                    task.position_id
                ))

                # æª¢æŸ¥æ˜¯å¦æœ‰æ›´æ–°åˆ°è¨˜éŒ„
                if cursor.rowcount == 0:
                    logger.warning(f"å¹³å€‰æ›´æ–°æœªå½±éŸ¿ä»»ä½•è¨˜éŒ„: éƒ¨ä½{task.position_id}")
                    return False

                conn.commit()
                return True

        except Exception as e:
            logger.error(f"å¹³å€‰æ›´æ–°å›é€€æ–¹æ³•å¤±æ•—: {e}")
            return False

    def schedule_trailing_stop_update(self, position_id: int, peak_price: float,
                                    stop_price: float, is_activated: bool) -> bool:
        """
        æ’ç¨‹ç§»å‹•åœåˆ©æ›´æ–°ä»»å‹™ - ğŸ”§ æ–°å¢ï¼šæ”¯æ´ç§»å‹•åœåˆ©è¨ˆç®—å™¨

        Args:
            position_id: éƒ¨ä½ID
            peak_price: å³°å€¼åƒ¹æ ¼
            stop_price: åœåˆ©åƒ¹æ ¼
            is_activated: æ˜¯å¦å·²å•Ÿå‹•

        Returns:
            bool: æ’ç¨‹æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç«‹å³æ›´æ–°å…§å­˜ç·©å­˜
            with self.cache_lock:
                if 'trailing_stops' not in self.memory_cache:
                    self.memory_cache['trailing_stops'] = {}

                cache_key = f"trailing_stop_{position_id}"
                self.memory_cache['trailing_stops'][cache_key] = {
                    'position_id': position_id,
                    'peak_price': peak_price,
                    'stop_price': stop_price,
                    'is_activated': is_activated,
                    'update_time': time.time()
                }

            # å‰µå»ºæ›´æ–°ä»»å‹™
            task = UpdateTask(
                task_type='trailing_stop_update',
                position_id=position_id,
                data={
                    'peak_price': peak_price,
                    'stop_price': stop_price,
                    'is_activated': is_activated,
                    'update_time': time.time()
                },
                priority=3,  # ä¸­ç­‰å„ªå…ˆç´š
                timestamp=time.time()
            )

            # æ’ç¨‹åˆ°æ›´æ–°éšŠåˆ—
            self.update_queue.put_nowait(task)

            # æ›´æ–°çµ±è¨ˆ
            with self.stats_lock:
                self.stats['total_tasks'] += 1
                self.stats['trailing_stop_updates'] += 1

            if self.console_enabled:
                print(f"[ASYNC_DB] ğŸ“ æ’ç¨‹ç§»å‹•åœåˆ©æ›´æ–°: éƒ¨ä½{position_id} "
                      f"å³°å€¼{peak_price:.0f} åœåˆ©{stop_price:.0f} å•Ÿå‹•:{is_activated}")

            return True

        except Exception as e:
            logger.error(f"æ’ç¨‹ç§»å‹•åœåˆ©æ›´æ–°å¤±æ•—: {e}")
            if self.console_enabled:
                print(f"[ASYNC_DB] âŒ æ’ç¨‹ç§»å‹•åœåˆ©æ›´æ–°å¤±æ•—: {e}")
            return False

    def _process_trailing_stop_update_task(self, task: UpdateTask) -> bool:
        """
        è™•ç†ç§»å‹•åœåˆ©æ›´æ–°ä»»å‹™ - ğŸ”§ æ–°å¢ï¼šæ”¯æ´ç§»å‹•åœåˆ©è¨ˆç®—å™¨

        Args:
            task: ç§»å‹•åœåˆ©æ›´æ–°ä»»å‹™

        Returns:
            bool: è™•ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            position_id = task.position_id
            data = task.data

            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()

                # æª¢æŸ¥æ˜¯å¦å­˜åœ¨ç§»å‹•åœåˆ©è¨˜éŒ„
                cursor.execute('''
                    SELECT id AS record_pk FROM trailing_stop_records
                    WHERE position_id = ? AND status = 'ACTIVE'
                ''', (position_id,))

                existing_record = cursor.fetchone()

                if existing_record:
                    # æ›´æ–°ç¾æœ‰è¨˜éŒ„
                    cursor.execute('''
                        UPDATE trailing_stop_records
                        SET peak_price = ?,
                            current_stop_price = ?,
                            is_activated = ?,
                            last_update_time = CURRENT_TIMESTAMP,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE position_id = ? AND status = 'ACTIVE'
                    ''', (
                        data['peak_price'],
                        data['stop_price'],
                        1 if data['is_activated'] else 0,
                        position_id
                    ))
                else:
                    # å‰µå»ºæ–°è¨˜éŒ„
                    cursor.execute('''
                        INSERT INTO trailing_stop_records (
                            position_id, peak_price, current_stop_price,
                            is_activated, last_update_time, status, created_at
                        ) VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP, 'ACTIVE', CURRENT_TIMESTAMP)
                    ''', (
                        position_id,
                        data['peak_price'],
                        data['stop_price'],
                        1 if data['is_activated'] else 0
                    ))

                conn.commit()

                if self.console_enabled:
                    action = "æ›´æ–°" if existing_record else "å‰µå»º"
                    print(f"[ASYNC_DB] âœ… {action}ç§»å‹•åœåˆ©è¨˜éŒ„: éƒ¨ä½{position_id} "
                          f"å³°å€¼{data['peak_price']:.0f} åœåˆ©{data['stop_price']:.0f}")

                return True

        except Exception as e:
            logger.error(f"è™•ç†ç§»å‹•åœåˆ©æ›´æ–°ä»»å‹™å¤±æ•—: {e}")
            if self.console_enabled:
                print(f"[ASYNC_DB] âŒ ç§»å‹•åœåˆ©æ›´æ–°å¤±æ•—: {e}")
            return False

# å…¨åŸŸå¯¦ä¾‹ï¼ˆå¯é¸ï¼‰
_global_async_updater = None

def get_global_async_updater():
    """ç²å–å…¨åŸŸç•°æ­¥æ›´æ–°å™¨å¯¦ä¾‹"""
    return _global_async_updater

def initialize_global_async_updater(db_manager, console_enabled=True):
    """åˆå§‹åŒ–å…¨åŸŸç•°æ­¥æ›´æ–°å™¨"""
    global _global_async_updater
    if _global_async_updater is None:
        _global_async_updater = AsyncDatabaseUpdater(db_manager, console_enabled)
        _global_async_updater.start()
    return _global_async_updater
