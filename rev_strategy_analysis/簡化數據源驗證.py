#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç°¡åŒ–ç‰ˆæ•¸æ“šæºé©—è­‰æ¸¬è©¦
æª¢æŸ¥å…©å€‹ç³»çµ±ä½¿ç”¨çš„æ•¸æ“šæºæ˜¯å¦ä¸€è‡´
"""

import os
import logging
from datetime import time
from pathlib import Path
import hashlib
import json

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_sqlite_database():
    """æª¢æŸ¥SQLiteæ•¸æ“šåº«"""
    logger.info("ğŸ” æª¢æŸ¥SQLiteæ•¸æ“šåº«...")
    
    db_path = Path("stock_data.sqlite")
    
    if not db_path.exists():
        logger.error(f"âŒ SQLiteæ•¸æ“šåº«ä¸å­˜åœ¨: {db_path}")
        return None
    
    db_info = {
        'database_path': str(db_path.absolute()),
        'database_size': db_path.stat().st_size,
        'database_mtime': db_path.stat().st_mtime,
        'database_exists': True
    }
    
    logger.info(f"âœ… æ•¸æ“šåº«è·¯å¾‘: {db_info['database_path']}")
    logger.info(f"âœ… æ•¸æ“šåº«å¤§å°: {db_info['database_size']:,} bytes")
    
    return db_info

def check_data_consistency():
    """æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§"""
    logger.info("ğŸ” æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§...")
    
    try:
        import sqlite_connection
        
        # åˆå§‹åŒ–é€£æ¥
        sqlite_connection.init_sqlite_connection()
        
        test_date = "2024-11-15"
        
        with sqlite_connection.get_conn_cur_from_sqlite_with_adapter(as_dict=True) as (conn, cur):
            # ç²å–æ¸¬è©¦æ—¥æœŸçš„æ•¸æ“š
            cur.execute(
                "SELECT * FROM stock_prices WHERE trade_datetime::date = %s ORDER BY trade_datetime;", 
                (test_date,)
            )
            all_data = cur.fetchall()
            
            if not all_data:
                logger.warning(f"âš ï¸ æ¸¬è©¦æ—¥æœŸ {test_date} æ²’æœ‰æ•¸æ“š")
                return None
            
            # éæ¿¾äº¤æ˜“æ™‚æ®µæ•¸æ“š
            session_data = [
                c for c in all_data 
                if time(8, 45) <= c['trade_datetime'].time() <= time(13, 45)
            ]
            
            # ç²å–é–‹ç›¤å€é–“æ•¸æ“š
            range_data = [
                c for c in session_data 
                if c['trade_datetime'].time() in [time(8, 46), time(8, 47)]
            ]
            
            data_info = {
                'test_date': test_date,
                'total_records': len(all_data),
                'session_records': len(session_data),
                'range_records': len(range_data),
                'data_available': len(session_data) > 0
            }
            
            if session_data:
                # è¨ˆç®—æ•¸æ“šæ‘˜è¦
                first_record = session_data[0]
                last_record = session_data[-1]
                
                data_info.update({
                    'first_time': first_record['trade_datetime'].isoformat(),
                    'last_time': last_record['trade_datetime'].isoformat(),
                    'first_close': float(first_record['close_price']),
                    'last_close': float(last_record['close_price'])
                })
                
                # è¨ˆç®—ç°¡å–®å“ˆå¸Œ
                price_sum = sum(float(c['close_price']) for c in session_data[:10])  # åªç”¨å‰10ç­†
                data_info['price_checksum'] = round(price_sum, 2)
            
            logger.info(f"âœ… æ¸¬è©¦æ—¥æœŸ: {data_info['test_date']}")
            logger.info(f"âœ… ç¸½è¨˜éŒ„æ•¸: {data_info['total_records']}")
            logger.info(f"âœ… äº¤æ˜“æ™‚æ®µè¨˜éŒ„æ•¸: {data_info['session_records']}")
            logger.info(f"âœ… é–‹ç›¤å€é–“è¨˜éŒ„æ•¸: {data_info['range_records']}")
            
            if 'price_checksum' in data_info:
                logger.info(f"âœ… åƒ¹æ ¼æ ¡é©—å’Œ: {data_info['price_checksum']}")
            
            return data_info
            
    except Exception as e:
        logger.error(f"âŒ æ•¸æ“šæª¢æŸ¥å¤±æ•—: {e}")
        return None

def check_core_engines():
    """æª¢æŸ¥æ ¸å¿ƒå¼•æ“æ–‡ä»¶"""
    logger.info("ğŸ” æª¢æŸ¥æ ¸å¿ƒå¼•æ“æ–‡ä»¶...")
    
    engines = {
        'rev_web_trading_gui': 'rev_multi_Profit-Funded Risk_å¤šå£.py',
        'mdd_gui': 'experiment_analysis/exp_rev_multi_Profit-Funded Risk_å¤šå£.py'
    }
    
    engine_info = {}
    
    for name, path in engines.items():
        file_path = Path(path)
        if file_path.exists():
            engine_info[name] = {
                'file_path': str(file_path),
                'file_size': file_path.stat().st_size,
                'file_mtime': file_path.stat().st_mtime,
                'exists': True
            }
            logger.info(f"âœ… {name}: {path} (å¤§å°: {file_path.stat().st_size:,} bytes)")
        else:
            engine_info[name] = {
                'file_path': str(file_path),
                'exists': False
            }
            logger.warning(f"âš ï¸ {name}: {path} ä¸å­˜åœ¨")
    
    return engine_info

def compare_engines():
    """æ¯”è¼ƒå…©å€‹å¼•æ“çš„é—œéµå·®ç•°"""
    logger.info("ğŸ” æ¯”è¼ƒå¼•æ“å·®ç•°...")
    
    try:
        # è®€å–å…©å€‹æ–‡ä»¶çš„é—œéµéƒ¨åˆ†
        rev_web_file = Path('rev_multi_Profit-Funded Risk_å¤šå£.py')
        mdd_file = Path('experiment_analysis/exp_rev_multi_Profit-Funded Risk_å¤šå£.py')
        
        differences = []
        
        if rev_web_file.exists() and mdd_file.exists():
            # æª¢æŸ¥æ–‡ä»¶å¤§å°å·®ç•°
            rev_size = rev_web_file.stat().st_size
            mdd_size = mdd_file.stat().st_size
            
            if rev_size != mdd_size:
                differences.append(f"æ–‡ä»¶å¤§å°ä¸åŒ: rev_web({rev_size}) vs mdd({mdd_size})")
            
            # æª¢æŸ¥é—œéµå­—ç¬¦ä¸²
            with open(rev_web_file, 'r', encoding='utf-8') as f:
                rev_content = f.read()
            
            with open(mdd_file, 'r', encoding='utf-8') as f:
                mdd_content = f.read()
            
            # æª¢æŸ¥é—œéµå·®ç•°
            key_patterns = [
                'USE_SQLITE',
                'max_drawdown',
                'total_pnl',
                'Decimal',
                'float'
            ]
            
            for pattern in key_patterns:
                rev_count = rev_content.count(pattern)
                mdd_count = mdd_content.count(pattern)
                
                if rev_count != mdd_count:
                    differences.append(f"'{pattern}' å‡ºç¾æ¬¡æ•¸ä¸åŒ: rev_web({rev_count}) vs mdd({mdd_count})")
            
            logger.info(f"âœ… ç™¼ç¾ {len(differences)} å€‹å·®ç•°")
            for diff in differences:
                logger.warning(f"âŒ {diff}")
        
        return differences
        
    except Exception as e:
        logger.error(f"âŒ æ¯”è¼ƒå¼•æ“å¤±æ•—: {e}")
        return []

def main():
    """ä¸»å‡½æ•¸"""
    logger.info("ğŸš€ é–‹å§‹ç°¡åŒ–æ•¸æ“šæºé©—è­‰...")
    logger.info("=" * 60)
    
    # 1. æª¢æŸ¥SQLiteæ•¸æ“šåº«
    db_info = check_sqlite_database()
    
    logger.info("=" * 60)
    
    # 2. æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§
    data_info = check_data_consistency()
    
    logger.info("=" * 60)
    
    # 3. æª¢æŸ¥æ ¸å¿ƒå¼•æ“æ–‡ä»¶
    engine_info = check_core_engines()
    
    logger.info("=" * 60)
    
    # 4. æ¯”è¼ƒå¼•æ“å·®ç•°
    differences = compare_engines()
    
    logger.info("=" * 60)
    
    # 5. ç”Ÿæˆå ±å‘Š
    report = {
        'database_info': db_info,
        'data_info': data_info,
        'engine_info': engine_info,
        'differences': differences,
        'summary': {
            'database_available': db_info is not None,
            'data_available': data_info is not None and data_info.get('data_available', False),
            'engines_available': all(info.get('exists', False) for info in engine_info.values()),
            'differences_found': len(differences) > 0
        }
    }
    
    # ä¿å­˜å ±å‘Š
    try:
        with open('ä»»å‹™2_ç°¡åŒ–æ•¸æ“šæºé©—è­‰å ±å‘Š.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        logger.info("ğŸ“‹ å ±å‘Šå·²ä¿å­˜: ä»»å‹™2_ç°¡åŒ–æ•¸æ“šæºé©—è­‰å ±å‘Š.json")
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜å ±å‘Šå¤±æ•—: {e}")
    
    # ç¸½çµ
    logger.info("=" * 60)
    logger.info("é©—è­‰ç¸½çµ")
    logger.info("=" * 60)
    
    if report['summary']['database_available']:
        logger.info("âœ… æ•¸æ“šåº«å¯ç”¨")
    else:
        logger.error("âŒ æ•¸æ“šåº«ä¸å¯ç”¨")
    
    if report['summary']['data_available']:
        logger.info("âœ… æ¸¬è©¦æ•¸æ“šå¯ç”¨")
    else:
        logger.error("âŒ æ¸¬è©¦æ•¸æ“šä¸å¯ç”¨")
    
    if report['summary']['engines_available']:
        logger.info("âœ… æ ¸å¿ƒå¼•æ“æ–‡ä»¶éƒ½å­˜åœ¨")
    else:
        logger.error("âŒ éƒ¨åˆ†æ ¸å¿ƒå¼•æ“æ–‡ä»¶ç¼ºå¤±")
    
    if report['summary']['differences_found']:
        logger.warning(f"âš ï¸ ç™¼ç¾ {len(differences)} å€‹å·®ç•°")
    else:
        logger.info("âœ… æœªç™¼ç¾æ˜é¡¯å·®ç•°")

if __name__ == "__main__":
    main()
