#!/usr/bin/env python3
"""
æ™‚é–“å€é–“å„ªåŒ–å™¨
å°ˆé–€ç”¨æ–¼å¤šæ™‚é–“å€é–“çš„MDDå„ªåŒ–åˆ†æ
æ•´åˆ enhanced_mdd_optimizer åŠŸèƒ½ä¸¦é©é…ç•¶å‰ç­–ç•¥
"""

import logging
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

from time_interval_config import TimeIntervalConfig
from enhanced_mdd_optimizer_adapted import EnhancedMDDOptimizer
from mdd_search_config_adapted import MDDSearchConfig

logger = logging.getLogger(__name__)

class TimeIntervalOptimizer:
    """æ™‚é–“å€é–“å„ªåŒ–å™¨"""
    
    def __init__(self, start_date: str = None, end_date: str = None):
        self.config_manager = TimeIntervalConfig()
        self.start_date = start_date or "2024-11-04"
        self.end_date = end_date or "2025-06-27"
        
        # çµæœå­˜å„²
        self.results_dir = Path("data/processed")
        self.results_dir.mkdir(exist_ok=True)
        
        logger.info("ğŸ¯ æ™‚é–“å€é–“å„ªåŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“… å›æ¸¬æœŸé–“: {self.start_date} åˆ° {self.end_date}")
    
    def set_date_range(self, start_date: str, end_date: str):
        """è¨­å®šå›æ¸¬æ—¥æœŸç¯„åœ"""
        self.start_date = start_date
        self.end_date = end_date
        logger.info(f"ğŸ“… æ›´æ–°å›æ¸¬æœŸé–“: {start_date} åˆ° {end_date}")
    
    def list_available_configs(self) -> Dict[str, str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é…ç½®"""
        return self.config_manager.list_available_configs()
    
    def run_time_interval_analysis(self, 
                                 config_name: str = 'standard_analysis',
                                 max_workers: int = 2,
                                 sample_size: Optional[int] = None) -> Dict[str, Any]:
        """åŸ·è¡Œæ™‚é–“å€é–“åˆ†æ"""
        
        logger.info(f"ğŸš€ é–‹å§‹æ™‚é–“å€é–“åˆ†æ: {config_name}")
        
        # ç²å–é…ç½®
        config = self.config_manager.get_config(config_name)
        logger.info(f"ğŸ“Š {self.config_manager.get_config_summary(config)}")
        
        # é©—è­‰é…ç½®
        is_valid, errors = self.config_manager.validate_config(config)
        if not is_valid:
            error_msg = f"é…ç½®é©—è­‰å¤±æ•—: {'; '.join(errors)}"
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        # è½‰æ›ç‚º enhanced_mdd_optimizer æ ¼å¼
        mdd_config = self._convert_to_mdd_config(config)
        
        # å‰µå»º MDD å„ªåŒ–å™¨
        optimizer = EnhancedMDDOptimizer(config_name)
        optimizer.config = mdd_config
        optimizer.set_date_range(self.start_date, self.end_date)
        
        # åŸ·è¡Œå„ªåŒ–
        results = optimizer.run_optimization(
            max_workers=max_workers,
            sample_size=sample_size,
            individual_tp=True
        )
        
        # è™•ç†å’Œåˆ†æçµæœ
        analysis_results = self._analyze_time_interval_results(results, config)
        
        # ä¿å­˜çµæœ
        self._save_analysis_results(analysis_results, config_name)
        
        return analysis_results
    
    def _convert_to_mdd_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """å°‡æ™‚é–“å€é–“é…ç½®è½‰æ›ç‚º MDD å„ªåŒ–å™¨é…ç½®æ ¼å¼"""
        
        mdd_config = {
            'analysis_mode': 'per_time_interval',
            'time_intervals': config['time_intervals'],
            'stop_loss_ranges': config['stop_loss_ranges'],
            'take_profit_ranges': config['take_profit_ranges'],
            'optimization_target': config.get('optimization_target', 'mdd_minimization'),
            'stop_loss_modes': config.get('stop_loss_modes', {'fixed_points': True}),
            'trailing_stop_config': config.get('trailing_stop_config', {})
        }
        
        # ä¼°ç®—çµ„åˆæ•¸
        interval_count = len(config['time_intervals'])
        stop_loss_combinations = (
            len(config['stop_loss_ranges']['lot1']) *
            len(config['stop_loss_ranges']['lot2']) *
            len(config['stop_loss_ranges']['lot3'])
        )
        
        unified_tp = len(config['take_profit_ranges']['unified'])
        individual_tp = len(config['take_profit_ranges']['individual']) ** 3
        boundary_tp = 1
        
        total_combinations = interval_count * stop_loss_combinations * (unified_tp + individual_tp + boundary_tp)
        
        mdd_config['estimated_combinations'] = {
            'per_interval_analysis': total_combinations,
            'breakdown': f"{stop_loss_combinations} åœæçµ„åˆ Ã— {unified_tp + individual_tp + boundary_tp} åœåˆ©æ¨¡å¼ Ã— {interval_count} æ™‚é–“å€é–“"
        }
        
        return mdd_config
    
    def _analyze_time_interval_results(self, results: List[Dict], config: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ™‚é–“å€é–“çµæœ"""
        
        logger.info("ğŸ“Š é–‹å§‹åˆ†ææ™‚é–“å€é–“çµæœ...")
        
        # éæ¿¾æˆåŠŸçš„çµæœ
        successful_results = [r for r in results if r.get('status') == 'success']
        
        if not successful_results:
            logger.error("âŒ æ²’æœ‰æˆåŠŸçš„å¯¦é©—çµæœ")
            return {'status': 'failed', 'error': 'No successful results'}
        
        # è½‰æ›ç‚º DataFrame
        df = pd.DataFrame(successful_results)
        
        # æŒ‰æ™‚é–“å€é–“åˆ†çµ„åˆ†æ
        interval_analysis = {}
        time_intervals = df['time_interval'].unique()
        
        for interval in sorted(time_intervals):
            interval_df = df[df['time_interval'] == interval]
            interval_analysis[interval] = self._analyze_single_interval(interval_df)
        
        # ç”Ÿæˆæ¯æ—¥äº¤æ˜“å»ºè­°
        daily_recommendations = self._generate_daily_recommendations(interval_analysis)
        
        # è¨ˆç®—ç¸½é«”çµ±è¨ˆ
        overall_stats = self._calculate_overall_stats(daily_recommendations)
        
        analysis_results = {
            'status': 'success',
            'config_name': config.get('name', 'æœªå‘½å'),
            'total_experiments': len(results),
            'successful_experiments': len(successful_results),
            'time_intervals_analyzed': len(time_intervals),
            'interval_analysis': interval_analysis,
            'daily_recommendations': daily_recommendations,
            'overall_stats': overall_stats,
            'raw_results': successful_results,
            'timestamp': datetime.now().isoformat()
        }
        
        return analysis_results
    
    def _analyze_single_interval(self, interval_df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æå–®ä¸€æ™‚é–“å€é–“çš„çµæœ"""
        
        # åˆ†åˆ¥æ‰¾å›ºå®šåœåˆ©å’Œå€é–“é‚Šç·£åœåˆ©çš„æœ€ä½³çµæœ
        fixed_tp_df = interval_df[
            (interval_df.get('take_profit_mode', '') != 'range_boundary') &
            (~interval_df['experiment_id'].str.contains('RangeBoundary', na=False))
        ]
        boundary_df = interval_df[
            (interval_df.get('take_profit_mode', '') == 'range_boundary') |
            (interval_df['experiment_id'].str.contains('RangeBoundary', na=False))
        ]
        
        analysis = {
            'total_experiments': len(interval_df),
            'best_fixed_tp': None,
            'best_boundary_tp': None,
            'recommended_config': None,
            'stats': {
                'avg_mdd': interval_df['mdd'].mean(),
                'avg_pnl': interval_df['total_pnl'].mean(),
                'avg_win_rate': interval_df['win_rate'].mean()
            }
        }
        
        # åˆ†æå›ºå®šåœåˆ©çµæœ
        if not fixed_tp_df.empty:
            best_fixed_idx = fixed_tp_df['mdd'].idxmax()  # MDDæœ€å¤§(æœ€å°è² å€¼)
            analysis['best_fixed_tp'] = fixed_tp_df.loc[best_fixed_idx].to_dict()
        
        # åˆ†æå€é–“é‚Šç·£åœåˆ©çµæœ
        if not boundary_df.empty:
            best_boundary_idx = boundary_df['mdd'].idxmax()
            analysis['best_boundary_tp'] = boundary_df.loc[best_boundary_idx].to_dict()
        
        # æ±ºå®šæ¨è–¦é…ç½®
        if analysis['best_fixed_tp'] and analysis['best_boundary_tp']:
            if analysis['best_boundary_tp']['mdd'] > analysis['best_fixed_tp']['mdd']:
                analysis['recommended_config'] = analysis['best_boundary_tp']
                analysis['recommendation_reason'] = 'boundary_better_mdd'
            else:
                analysis['recommended_config'] = analysis['best_fixed_tp']
                analysis['recommendation_reason'] = 'fixed_better_mdd'
        elif analysis['best_boundary_tp']:
            analysis['recommended_config'] = analysis['best_boundary_tp']
            analysis['recommendation_reason'] = 'boundary_only'
        elif analysis['best_fixed_tp']:
            analysis['recommended_config'] = analysis['best_fixed_tp']
            analysis['recommendation_reason'] = 'fixed_only'
        
        return analysis
    
    def _generate_daily_recommendations(self, interval_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ¯æ—¥äº¤æ˜“é…ç½®å»ºè­°"""
        
        recommendations = []
        
        for interval, analysis in interval_analysis.items():
            if analysis['recommended_config']:
                config = analysis['recommended_config']
                
                # ç¢ºå®šåœåˆ©æ¨¡å¼æè¿°
                if config.get('take_profit_mode') == 'range_boundary':
                    tp_mode = "å€é–“é‚Šç·£åœåˆ©"
                elif 'take_profit' in config and pd.notna(config['take_profit']):
                    tp_mode = f"çµ±ä¸€åœåˆ© TP:{int(config['take_profit'])}"
                elif 'lot1_take_profit' in config:
                    tp_mode = f"å„å£ç¨ç«‹åœåˆ© L1:{int(config['lot1_take_profit'])} L2:{int(config['lot2_take_profit'])} L3:{int(config['lot3_take_profit'])}"
                else:
                    tp_mode = "æœªçŸ¥åœåˆ©æ¨¡å¼"
                
                recommendation = {
                    'time_interval': interval,
                    'mode': tp_mode,
                    'lot1_stop_loss': config['lot1_stop_loss'],
                    'lot2_stop_loss': config['lot2_stop_loss'],
                    'lot3_stop_loss': config['lot3_stop_loss'],
                    'mdd': config['mdd'],
                    'total_pnl': config['total_pnl'],
                    'win_rate': config['win_rate'],
                    'experiment_id': config['experiment_id'],
                    'recommendation_reason': analysis['recommendation_reason']
                }
                
                recommendations.append(recommendation)
        
        return recommendations
    
    def _calculate_overall_stats(self, recommendations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è¨ˆç®—ç¸½é«”çµ±è¨ˆ"""
        
        if not recommendations:
            return {}
        
        total_mdd = sum(rec['mdd'] for rec in recommendations)
        total_pnl = sum(rec['total_pnl'] for rec in recommendations)
        avg_win_rate = sum(rec['win_rate'] for rec in recommendations) / len(recommendations)
        
        # çµ±è¨ˆåœåˆ©æ¨¡å¼åˆ†å¸ƒ
        mode_distribution = {}
        for rec in recommendations:
            mode_type = rec['mode'].split()[0]  # å–ç¬¬ä¸€å€‹è©ä½œç‚ºé¡å‹
            mode_distribution[mode_type] = mode_distribution.get(mode_type, 0) + 1
        
        return {
            'total_intervals': len(recommendations),
            'expected_daily_mdd': total_mdd,
            'expected_daily_pnl': total_pnl,
            'average_win_rate': avg_win_rate,
            'mode_distribution': mode_distribution,
            'risk_adjusted_return': total_pnl / (abs(total_mdd) + 1) if total_mdd != 0 else 0
        }
    
    def _save_analysis_results(self, results: Dict[str, Any], config_name: str):
        """ä¿å­˜åˆ†æçµæœ"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜å®Œæ•´çµæœ JSON
        results_file = self.results_dir / f"time_interval_analysis_{config_name}_{timestamp}.json"
        
        import json
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"ğŸ’¾ åˆ†æçµæœå·²ä¿å­˜: {results_file}")
        
        # ä¿å­˜æ¯æ—¥å»ºè­° CSV
        if results.get('daily_recommendations'):
            recommendations_df = pd.DataFrame(results['daily_recommendations'])
            csv_file = self.results_dir / f"daily_recommendations_{config_name}_{timestamp}.csv"
            recommendations_df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            logger.info(f"ğŸ’¾ æ¯æ—¥å»ºè­°å·²ä¿å­˜: {csv_file}")
        
        return results_file
