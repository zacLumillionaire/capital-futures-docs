# data_import.py
import csv
import logging
import os
from app_setup import init_all_db_pools
import shared
from psycopg2.extras import execute_values # å°ˆç‚ºæ‰¹æ¬¡åŒ¯å…¥å„ªåŒ–çš„å‡½å¼

# --- è¨­å®šæ—¥èªŒ ---
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s [%(name)s.%(funcName)s:%(lineno)d] %(message)s',
    datefmt='%Y-%m-%dT%H:%M:%S%z'
)
logger = logging.getLogger(__name__)

def import_stock_data(file_path, batch_size=1000):
    """
    å¾æŒ‡å®šçš„ CSV æª”æ¡ˆé«˜æ•ˆåœ°æ‰¹æ¬¡åŒ¯å…¥è‚¡ç¥¨è³‡æ–™åˆ°è³‡æ–™åº«ã€‚
    """
    logger.info(f"ğŸ” æ­£åœ¨æª¢æŸ¥æª”æ¡ˆè·¯å¾‘: {file_path}")
    if not os.path.exists(file_path):
        logger.error(f"âŒ æª”æ¡ˆä¸å­˜åœ¨æˆ–è·¯å¾‘éŒ¯èª¤: {file_path}")
        return
    logger.info(f"âœ… æª”æ¡ˆå·²æ‰¾åˆ°: {file_path}")

    logger.info(f"ğŸš€ é–‹å§‹å¾ {file_path} é€²è¡Œæ‰¹æ¬¡åŒ¯å…¥ï¼Œæ¯æ‰¹æ¬¡ {batch_size} ç­†...")

    try:
        with shared.get_conn_cur_from_pool_b() as (conn, cur):
            logger.info("âœ… è³‡æ–™åº«é€£ç·šæˆåŠŸã€‚")
            
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                try:
                    header = next(reader)
                    logger.info(f"ğŸ” CSV æª”æ¡ˆæ¨™é ­ (å·²è·³é): {header}")
                except StopIteration:
                    logger.warning("âš ï¸ CSV æª”æ¡ˆæ˜¯ç©ºçš„ï¼Œæ²’æœ‰ä»»ä½•è³‡æ–™å¯åŒ¯å…¥ã€‚")
                    return

                sql = """
                    INSERT INTO stock_prices (
                        trade_datetime, open_price, high_price, low_price,
                        close_price, price_change, percentage_change, volume
                    ) VALUES %s;
                """
                
                batch_data = []
                total_rows_processed = 0
                for row in reader:
                    # åœ¨é€™è£¡å¯ä»¥åŠ å…¥è³‡æ–™æ¸…æ´—æˆ–è½‰æ›çš„é‚è¼¯
                    batch_data.append(row)
                    if len(batch_data) >= batch_size:
                        try:
                            logger.info(f"â³ æ­£åœ¨åŒ¯å…¥ä¸€æ‰¹æ¬¡ ({len(batch_data)} ç­†) è³‡æ–™...")
                            execute_values(cur, sql, batch_data)
                            conn.commit()
                            total_rows_processed += len(batch_data)
                            logger.info(f"âœ… æ‰¹æ¬¡åŒ¯å…¥æˆåŠŸã€‚ç›®å‰ç¸½è¨ˆåŒ¯å…¥ {total_rows_processed} ç­†ã€‚")
                            batch_data = [] # æ¸…ç©ºæ‰¹æ¬¡
                        except Exception as e:
                            logger.error(f"âŒ æ‰¹æ¬¡åŒ¯å…¥å¤±æ•—: {e}", exc_info=True)
                            conn.rollback()
                            # é¸æ“‡æ€§ï¼šå¯ä»¥å°‡å¤±æ•—çš„ batch_data å­˜åˆ°å¦ä¸€å€‹æª”æ¡ˆä»¥ä¾¿å¾ŒçºŒåˆ†æ
                            batch_data = []


                # è™•ç†æœ€å¾Œä¸€æ‰¹ä¸è¶³ batch_size çš„è³‡æ–™
                if batch_data:
                    try:
                        logger.info(f"â³ æ­£åœ¨åŒ¯å…¥æœ€å¾Œä¸€æ‰¹ ({len(batch_data)} ç­†) è³‡æ–™...")
                        execute_values(cur, sql, batch_data)
                        conn.commit()
                        total_rows_processed += len(batch_data)
                        logger.info(f"âœ… æœ€å¾Œä¸€æ‰¹åŒ¯å…¥æˆåŠŸã€‚")
                    except Exception as e:
                        logger.error(f"âŒ æœ€å¾Œä¸€æ‰¹åŒ¯å…¥å¤±æ•—: {e}", exc_info=True)
                        conn.rollback()

            logger.info(f"ğŸ è³‡æ–™åŒ¯å…¥å®Œæˆã€‚ç¸½å…±æˆåŠŸåŒ¯å…¥ {total_rows_processed} ç­†è³‡æ–™ã€‚")

    except Exception as e:
        logger.error(f"âŒ åŒ¯å…¥éç¨‹ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)

def main():
    """
    ä¸»å‡½å¼ï¼Œç”¨æ–¼åˆå§‹åŒ–ä¸¦åŸ·è¡Œè³‡æ–™åŒ¯å…¥ã€‚
    """
    logger.info("â–¶ï¸  è³‡æ–™åŒ¯å…¥ç¨‹å¼é–‹å§‹åŸ·è¡Œ...")

    try:
        init_all_db_pools()
        logger.info("âœ… è³‡æ–™åº«é€£ç·šæ± åˆå§‹åŒ–æˆåŠŸã€‚")
    except Exception as e:
        logger.error(f"âŒ è³‡æ–™åº«é€£ç·šæ± åˆå§‹åŒ–å¤±æ•—: {e}", exc_info=True)
        return

    # --- è¨­å®šä½ è¦åŒ¯å…¥çš„ CSV æª”æ¡ˆè·¯å¾‘ ---
    csv_file_path = "/Users/z/chromeä¸‹è¼‰/TX00_å°æŒ‡è¿‘_åˆ†é˜ç·š_clean - TX00_å°æŒ‡è¿‘_åˆ†é˜ç·š.csv" 

    import_stock_data(csv_file_path)

    logger.info("â¹ï¸  è³‡æ–™åŒ¯å…¥ç¨‹å¼åŸ·è¡Œå®Œç•¢ã€‚")

if __name__ == '__main__':
    main()
