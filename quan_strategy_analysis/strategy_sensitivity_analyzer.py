"""
ç­–ç•¥æ•æ„Ÿåº¦åˆ†æå™¨ - ä½¿ç”¨ SALib é€²è¡Œ Sobol æ•æ„Ÿåº¦åˆ†æ

ğŸ¯ è…³æœ¬ç›®çš„ï¼š
    é€™å€‹è…³æœ¬èƒ½å¤ åˆ©ç”¨ SALib å‡½å¼åº«ï¼Œå° Profit-Funded Risk å¤šå£äº¤æ˜“ç­–ç•¥é€²è¡Œ Sobol æ•æ„Ÿåº¦åˆ†æï¼Œ
    æ‰¾å‡ºåœ¨ç‰¹å®šæ™‚é–“å€æ®µå…§å°æœ€å¤§å›æ’¤ï¼ˆMDDï¼‰å½±éŸ¿æœ€å¤§çš„åƒæ•¸ã€‚

ğŸš€ ä¸»è¦åŠŸèƒ½ï¼š
    1. é‡æ§‹åŸå§‹å›æ¸¬ç¨‹å¼ï¼Œä½¿å…¶å¯è¢« SALib é‡è¤‡å‘¼å«
    2. å®šç¾©åƒæ•¸ç©ºé–“ï¼ŒåŒ…å« 7 å€‹æ•¸å€¼å‹åƒæ•¸
    3. åˆ†åˆ¥å°ä¸‰ç¨®äº¤æ˜“æ–¹å‘ï¼ˆå¤šé ­ã€ç©ºé ­ã€é›™å‘ï¼‰é€²è¡Œæ•æ„Ÿåº¦åˆ†æ
    4. ç”Ÿæˆè©³ç´°çš„æ•æ„Ÿåº¦åˆ†æå ±å‘Š

ğŸ“Š åˆ†æåƒæ•¸ï¼š
    - lot1_trigger: ç¬¬1å£è§¸ç™¼é» (10-30 é»)
    - lot1_pullback: ç¬¬1å£å›æª”ç™¾åˆ†æ¯” (5%-30%)
    - lot2_trigger: ç¬¬2å£è§¸ç™¼é» (25-60 é»)
    - lot2_pullback: ç¬¬2å£å›æª”ç™¾åˆ†æ¯” (5%-30%)
    - lot3_trigger: ç¬¬3å£è§¸ç™¼é» (40-80 é»)
    - lot3_pullback: ç¬¬3å£å›æª”ç™¾åˆ†æ¯” (10%-40%)
    - protection_multiplier: ä¿è­·æ€§åœæå€æ•¸ (1.0-3.0 å€)

ğŸ”§ å¦‚ä½•åŸ·è¡Œï¼š
    python strategy_sensitivity_analyzer.py

ğŸ“ˆ å¦‚ä½•è§£è®€çµæœï¼š
    ST (ç¸½æ•æ„Ÿåº¦æŒ‡æ•¸)ï¼š
        - ä»£è¡¨ä¸€å€‹åƒæ•¸å°æ¨¡å‹è¼¸å‡º(è² MDD)çš„ç¸½è²¢ç»åº¦
        - åŒ…å«åƒæ•¸è‡ªèº«çš„ç›´æ¥å½±éŸ¿ä»¥åŠèˆ‡å…¶ä»–åƒæ•¸çš„äº¤äº’ä½œç”¨å½±éŸ¿
        - STå€¼è¶Šé«˜çš„åƒæ•¸ï¼Œæ˜¯å½±éŸ¿MDDçš„é—œéµå› å­ï¼Œæ‡‰å„ªå…ˆé€²è¡Œå„ªåŒ–

    S1 (ä¸€éšæ•æ„Ÿåº¦æŒ‡æ•¸)ï¼š
        - ä»£è¡¨åƒæ•¸çš„ç›´æ¥å½±éŸ¿ï¼Œä¸åŒ…å«äº¤äº’ä½œç”¨
        - S1å€¼é«˜è¡¨ç¤ºè©²åƒæ•¸å–®ç¨å°çµæœæœ‰é‡è¦å½±éŸ¿

    è² MDDå€¼ï¼š
        - æˆ‘å€‘è¿”å› -MDD ä¾†é€²è¡Œæœ€å°åŒ–å„ªåŒ–
        - è² MDDå€¼è¶Šå¤§è¡¨ç¤ºMDDè¶Šå°ï¼ˆå›æ’¤è¶Šå°ï¼Œç­–ç•¥è¶Šç©©å®šï¼‰

âš ï¸ æ³¨æ„äº‹é …ï¼š
    1. ç¢ºä¿ stock_data.sqlite è³‡æ–™åº«å­˜åœ¨ä¸”åŒ…å«è¶³å¤ çš„æ­·å²æ•¸æ“š
    2. æ¨£æœ¬æ•¸å»ºè­°å¾å°å€¼ï¼ˆå¦‚64ï¼‰é–‹å§‹æ¸¬è©¦ï¼Œç¢ºèªç„¡èª¤å¾Œå†å¢åŠ 
    3. å®Œæ•´åˆ†æå¯èƒ½éœ€è¦æ•¸å°æ™‚ï¼Œå»ºè­°åœ¨æ€§èƒ½è¼ƒå¥½çš„æ©Ÿå™¨ä¸Šé‹è¡Œ

ä½œè€…ï¼šé‡åŒ–åˆ†æåœ˜éšŠ
æ—¥æœŸï¼š2025-07-14
ç‰ˆæœ¬ï¼š1.0
"""

import logging
import numpy as np
import pandas as pd
from datetime import time, date, datetime
from decimal import Decimal
from dataclasses import dataclass, field
from enum import Enum, auto
from typing import Dict, List, Tuple, Any, Optional
import multiprocessing
import os
import matplotlib.pyplot as plt
import seaborn as sns

# SALib å°å…¥
from SALib.analyze import sobol
from SALib.sample import sobol as sobol_sample  # æ–°ç‰ˆæœ¬ä½¿ç”¨ sobol.sample

# å°å…¥åŸå§‹å›æ¸¬æ¨¡çµ„
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ä½¿ç”¨ importlib ä¾†è™•ç†ç‰¹æ®Šå­—ç¬¦çš„æ–‡ä»¶å
import importlib.util
spec = importlib.util.spec_from_file_location("backtest_module", "multi_Profit-Funded Risk_å¤šå£.py")
if spec is not None and spec.loader is not None:
    backtest_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(backtest_module)

    # å¾æ¨¡çµ„ä¸­å°å…¥éœ€è¦çš„é¡å’Œå‡½æ•¸
    StrategyConfig = backtest_module.StrategyConfig
    LotRule = backtest_module.LotRule
    RangeFilter = backtest_module.RangeFilter
    RiskConfig = backtest_module.RiskConfig
    StopLossConfig = backtest_module.StopLossConfig
    StopLossType = backtest_module.StopLossType
    USE_SQLITE = backtest_module.USE_SQLITE
    apply_range_filter = backtest_module.apply_range_filter
    _run_multi_lot_logic = backtest_module._run_multi_lot_logic
else:
    raise ImportError("ç„¡æ³•è¼‰å…¥å›æ¸¬æ¨¡çµ„")

if USE_SQLITE:
    import sqlite_connection
else:
    import shared

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s [%(name)s.%(funcName)s:%(lineno)d] %(message)s', datefmt='%Y-%m-%dT%H:%M:%S%z')
logger = logging.getLogger(__name__)

# ==============================================================================
# Task 1: æ”¹é€ å›æ¸¬ç¨‹å¼ï¼Œä½¿å…¶å¯è¢«å‡½å¼å‘¼å«
# ==============================================================================

def calculate_backtest_metrics(config: StrategyConfig, start_date: str, end_date: str, 
                             range_start_time: str, range_end_time: str, silent: bool = True) -> Dict[str, float]:
    """
    åŸ·è¡Œå›æ¸¬ä¸¦è¿”å›ç¸¾æ•ˆæŒ‡æ¨™å­—å…¸ï¼ŒåŒ…å«æœ€å¤§å›æ’¤(MDD)
    
    Args:
        config: ç­–ç•¥é…ç½®
        start_date: é–‹å§‹æ—¥æœŸ (æ ¼å¼: 'YYYY-MM-DD')
        end_date: çµæŸæ—¥æœŸ (æ ¼å¼: 'YYYY-MM-DD')
        range_start_time: é–‹ç›¤å€é–“é–‹å§‹æ™‚é–“ (æ ¼å¼: 'HH:MM')
        range_end_time: é–‹ç›¤å€é–“çµæŸæ™‚é–“ (æ ¼å¼: 'HH:MM')
        silent: æ˜¯å¦éœé»˜æ¨¡å¼ï¼ˆä¸è¼¸å‡ºæ—¥èªŒï¼‰
        
    Returns:
        dict: åŒ…å« total_pnl, max_drawdown, win_rate, total_trades ç­‰æŒ‡æ¨™çš„å­—å…¸
    """
    # è™•ç†è‡ªå®šç¾©é–‹ç›¤å€é–“æ™‚é–“
    range_start_hour, range_start_min = map(int, range_start_time.split(':'))
    range_end_hour, range_end_min = map(int, range_end_time.split(':'))
    
    try:
        # æ ¹æ“šé…ç½®é¸æ“‡æ•¸æ“šæº
        if USE_SQLITE:
            context_manager = sqlite_connection.get_conn_cur_from_sqlite_with_adapter(as_dict=True)
        else:
            context_manager = shared.get_conn_cur_from_pool_b(as_dict=True)

        with context_manager as (conn, cur):
            # æ§‹å»ºSQLæŸ¥è©¢
            base_query = "SELECT DISTINCT trade_datetime::date as trade_day FROM stock_prices"
            conditions = ["trade_datetime::date >= %s", "trade_datetime::date <= %s"]
            params = [start_date, end_date]
            
            query = f"{base_query} WHERE {' AND '.join(conditions)} ORDER BY trade_day;"
            cur.execute(query, tuple(params))
            trade_days = [row['trade_day'] for row in cur.fetchall()]
            
            if not silent:
                logger.info(f"ğŸ” æ‰¾åˆ° {len(trade_days)} å€‹äº¤æ˜“æ—¥é€²è¡Œå›æ¸¬ã€‚")
            
            total_pnl, winning_trades, losing_trades = Decimal(0), 0, 0
            cumulative_pnl = Decimal(0)
            peak_pnl = Decimal(0)  # è¿½è¹¤ç´¯ç©æç›Šå³°å€¼
            max_drawdown = Decimal(0)  # è¿½è¹¤æœ€å¤§å›æ’¤
            
            # å¤šç©ºåˆ†åˆ¥çµ±è¨ˆ
            long_pnl, short_pnl = Decimal(0), Decimal(0)
            long_trades, short_trades = 0, 0
            long_wins, short_wins = 0, 0

            for day in trade_days:
                cur.execute("SELECT * FROM stock_prices WHERE trade_datetime::date = %s ORDER BY trade_datetime;", (day,))
                day_session_candles = [c for c in cur.fetchall() if time(8, 45) <= c['trade_datetime'].time() <= time(13, 45)]
                if len(day_session_candles) < 3: 
                    continue

                # ä½¿ç”¨è‡ªå®šç¾©çš„é–‹ç›¤å€é–“æ™‚é–“
                range_times = [time(range_start_hour, range_start_min), time(range_end_hour, range_end_min)]
                candles_range = [c for c in day_session_candles if c['trade_datetime'].time() in range_times]
                if len(candles_range) != 2:
                    continue

                range_high, range_low = max(c['high_price'] for c in candles_range), min(c['low_price'] for c in candles_range)

                # å¥—ç”¨å€é–“éæ¿¾æ¿¾ç¶²
                range_passed, range_msg = apply_range_filter(config, range_high, range_low, day)
                if not range_passed:
                    continue

                # äº¤æ˜“é–‹å§‹æ™‚é–“è¨­ç‚ºé–‹ç›¤å€é–“çµæŸå¾Œ1åˆ†é˜
                trade_start_hour = range_end_hour
                trade_start_min = range_end_min + 1
                if trade_start_min >= 60:
                    trade_start_hour += 1
                    trade_start_min -= 60

                trade_candles = [c for c in day_session_candles if c['trade_datetime'].time() >= time(trade_start_hour, trade_start_min)]

                # åŸ·è¡Œäº¤æ˜“é‚è¼¯
                day_pnl, trade_direction = _run_multi_lot_logic(day_session_candles, trade_candles, config, range_high, range_low)

                if day_pnl != 0:
                    is_long_trade = (trade_direction == 'LONG')

                    if day_pnl > 0:
                        winning_trades += 1
                        if is_long_trade: 
                            long_wins += 1
                        else: 
                            short_wins += 1
                    else:
                        losing_trades += 1

                    # æ›´æ–°å¤šç©ºçµ±è¨ˆ
                    if is_long_trade:
                        long_trades += 1
                        long_pnl += day_pnl
                    else:
                        short_trades += 1
                        short_pnl += day_pnl

                total_pnl += day_pnl
                cumulative_pnl += day_pnl
                
                # ğŸš€ è¨ˆç®—æœ€å¤§å›æ’¤
                if cumulative_pnl > peak_pnl:
                    peak_pnl = cumulative_pnl
                
                current_drawdown = peak_pnl - cumulative_pnl
                if current_drawdown > max_drawdown:
                    max_drawdown = current_drawdown

            # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
            trade_count = winning_trades + losing_trades
            win_rate = (winning_trades / trade_count) if trade_count > 0 else 0
            long_win_rate = (long_wins / long_trades) if long_trades > 0 else 0
            short_win_rate = (short_wins / short_trades) if short_trades > 0 else 0

            return {
                'total_pnl': float(total_pnl),
                'max_drawdown': float(max_drawdown),  # ğŸš€ é—œéµï¼šè¿”å›MDD
                'long_pnl': float(long_pnl),
                'short_pnl': float(short_pnl),
                'total_trades': trade_count,
                'long_trades': long_trades,
                'short_trades': short_trades,
                'winning_trades': winning_trades,
                'losing_trades': losing_trades,
                'long_wins': long_wins,
                'short_wins': short_wins,
                'win_rate': win_rate,
                'long_win_rate': long_win_rate,
                'short_win_rate': short_win_rate,
                'trade_days': len(trade_days)
            }

    except Exception as e:
        if not silent:
            logger.error(f"âŒ åŸ·è¡Œå›æ¸¬æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return {
            'total_pnl': 0.0, 'max_drawdown': 0.0, 'long_pnl': 0.0, 'short_pnl': 0.0,
            'total_trades': 0, 'long_trades': 0, 'short_trades': 0,
            'winning_trades': 0, 'losing_trades': 0, 'long_wins': 0, 'short_wins': 0,
            'win_rate': 0.0, 'long_win_rate': 0.0, 'short_win_rate': 0.0, 'trade_days': 0
        }


def evaluate_for_salib(params: np.ndarray, trading_direction: str, start_date: str, end_date: str, 
                      range_start_time: str, range_end_time: str) -> float:
    """
    SALib é©é…å™¨å‡½å¼ï¼šå°‡åƒæ•¸é™£åˆ—è½‰æ›ç‚ºç­–ç•¥é…ç½®ä¸¦åŸ·è¡Œå›æ¸¬
    
    Args:
        params: SALib ç”¢ç”Ÿçš„åƒæ•¸é™£åˆ— [lot1_trigger, lot1_pullback, lot2_trigger, lot2_pullback, 
                                   lot3_trigger, lot3_pullback, protection_multiplier]
        trading_direction: äº¤æ˜“æ–¹å‘ ("LONG_ONLY", "SHORT_ONLY", "BOTH")
        start_date: é–‹å§‹æ—¥æœŸ
        end_date: çµæŸæ—¥æœŸ
        range_start_time: é–‹ç›¤å€é–“é–‹å§‹æ™‚é–“
        range_end_time: é–‹ç›¤å€é–“çµæŸæ™‚é–“
        
    Returns:
        float: è² MDDå€¼ï¼ˆç”¨æ–¼æœ€å°åŒ–å„ªåŒ–ï¼‰
    """
    try:
        # è‡¨æ™‚è¨­ç½®æ—¥èªŒç´šåˆ¥ç‚º WARNING ä»¥æŠ‘åˆ¶ INFO ç´šåˆ¥çš„äº¤æ˜“æ—¥èªŒ
        original_level = logging.getLogger().level
        logging.getLogger().setLevel(logging.WARNING)

        # è§£æåƒæ•¸
        lot1_trigger, lot1_pullback, lot2_trigger, lot2_pullback, lot3_trigger, lot3_pullback, protection_multiplier = params

        # å‰µå»ºç­–ç•¥é…ç½®
        lot_rules = [
            LotRule(
                use_trailing_stop=True,
                trailing_activation=Decimal(str(lot1_trigger)),
                trailing_pullback=Decimal(str(lot1_pullback))
            ),
            LotRule(
                use_trailing_stop=True,
                trailing_activation=Decimal(str(lot2_trigger)),
                trailing_pullback=Decimal(str(lot2_pullback)),
                protective_stop_multiplier=Decimal(str(protection_multiplier))
            ),
            LotRule(
                use_trailing_stop=True,
                trailing_activation=Decimal(str(lot3_trigger)),
                trailing_pullback=Decimal(str(lot3_pullback)),
                protective_stop_multiplier=Decimal(str(protection_multiplier))
            )
        ]

        config = StrategyConfig(
            trade_size_in_lots=3,
            stop_loss_type=StopLossType.RANGE_BOUNDARY,
            lot_rules=lot_rules,
            trading_direction=trading_direction,
            range_filter=RangeFilter(),  # ä½¿ç”¨é è¨­å€¼
            risk_config=RiskConfig(),    # ä½¿ç”¨é è¨­å€¼
            stop_loss_config=StopLossConfig()  # ä½¿ç”¨é è¨­å€¼
        )

        # åŸ·è¡Œå›æ¸¬
        result = calculate_backtest_metrics(config, start_date, end_date, range_start_time, range_end_time, silent=True)

        # æ¢å¾©åŸå§‹æ—¥èªŒç´šåˆ¥
        logging.getLogger().setLevel(original_level)

        # è¿”å›è² MDDï¼ˆç”¨æ–¼æœ€å°åŒ–å„ªåŒ–ï¼‰
        mdd = result['max_drawdown']
        return -mdd

    except Exception as e:
        # æ¢å¾©åŸå§‹æ—¥èªŒç´šåˆ¥
        logging.getLogger().setLevel(original_level)

        # è¨˜éŒ„éŒ¯èª¤çš„åƒæ•¸çµ„åˆå’ŒéŒ¯èª¤è¨Šæ¯
        param_str = f"[{lot1_trigger:.2f}, {lot1_pullback:.3f}, {lot2_trigger:.2f}, {lot2_pullback:.3f}, {lot3_trigger:.2f}, {lot3_pullback:.3f}, {protection_multiplier:.2f}]"
        logger.error(f"âŒ SALib è©•ä¼°å‡½å¼éŒ¯èª¤: {e} | éŒ¯èª¤åƒæ•¸: {param_str} | äº¤æ˜“æ–¹å‘: {trading_direction}")
        return -999999.0  # è¿”å›æ¥µå¤§çš„è² å€¼è¡¨ç¤ºå¤±æ•—


# ==============================================================================
# Task 2: å®šç¾©SALibå•é¡Œèˆ‡åƒæ•¸ç©ºé–“
# ==============================================================================

# å®šç¾© SALib å•é¡Œç©ºé–“
problem = {
    'num_vars': 7,
    'names': [
        'lot1_trigger',      # ç¬¬1å£è§¸ç™¼é»
        'lot1_pullback',     # ç¬¬1å£å›æª”ç™¾åˆ†æ¯”
        'lot2_trigger',      # ç¬¬2å£è§¸ç™¼é»
        'lot2_pullback',     # ç¬¬2å£å›æª”ç™¾åˆ†æ¯”
        'lot3_trigger',      # ç¬¬3å£è§¸ç™¼é»
        'lot3_pullback',     # ç¬¬3å£å›æª”ç™¾åˆ†æ¯”
        'protection_multiplier'  # ä¿è­·æ€§åœæå€æ•¸
    ],
    'bounds': [
        [10, 30],      # lot1_trigger: 10-30 é»
        [0.05, 0.30],  # lot1_pullback: 5%-30%
        [25, 60],      # lot2_trigger: 25-60 é»
        [0.05, 0.30],  # lot2_pullback: 5%-30%
        [40, 80],      # lot3_trigger: 40-80 é»
        [0.10, 0.40],  # lot3_pullback: 10%-40%
        [1.0, 3.0]     # protection_multiplier: 1.0-3.0 å€
    ]
}

# äº¤æ˜“æ–¹å‘åˆ—è¡¨ï¼ˆåˆ†é¡è®Šæ•¸ï¼‰
TRADING_DIRECTIONS = ['LONG_ONLY', 'SHORT_ONLY', 'BOTH']


# ==============================================================================
# ä¸¦è¡Œè™•ç†è¼”åŠ©å‡½æ•¸
# ==============================================================================

def evaluate_single_param_set(args):
    """
    å–®å€‹åƒæ•¸çµ„åˆçš„è©•ä¼°å‡½æ•¸ï¼ˆç”¨æ–¼ä¸¦è¡Œè™•ç†ï¼‰

    Args:
        args: tuple containing (params, trading_direction, start_date, end_date, range_start_time, range_end_time)

    Returns:
        float: è² MDDå€¼
    """
    # åœ¨æ¯å€‹å­é€²ç¨‹ä¸­è¨­ç½®æ—¥èªŒç´šåˆ¥ç‚º WARNING ä»¥æŠ‘åˆ¶äº¤æ˜“æ—¥èªŒ
    import logging
    logging.getLogger().setLevel(logging.WARNING)

    params, trading_direction, start_date, end_date, range_start_time, range_end_time = args
    return evaluate_for_salib(params, trading_direction, start_date, end_date, range_start_time, range_end_time)


class ProgressTracker:
    """é€²åº¦è¿½è¹¤å™¨"""
    def __init__(self, total_tasks, update_interval=5):
        self.total_tasks = total_tasks
        self.completed_tasks = 0
        self.update_interval = update_interval  # æ¯5%æ›´æ–°ä¸€æ¬¡
        self.last_reported_percentage = 0

    def update(self, increment=1):
        """æ›´æ–°é€²åº¦"""
        self.completed_tasks += increment
        current_percentage = (self.completed_tasks / self.total_tasks) * 100

        # æ¯5%å ±å‘Šä¸€æ¬¡é€²åº¦
        if current_percentage - self.last_reported_percentage >= self.update_interval:
            logger.info(f"   ğŸ“Š é€²åº¦æ›´æ–°: {self.completed_tasks}/{self.total_tasks} ({current_percentage:.1f}%)")
            self.last_reported_percentage = current_percentage

        # å®Œæˆæ™‚å ±å‘Š
        if self.completed_tasks >= self.total_tasks:
            logger.info(f"   âœ… è¨ˆç®—å®Œæˆ: {self.total_tasks}/{self.total_tasks} (100.0%)")


def evaluate_with_progress(args_with_tracker):
    """å¸¶é€²åº¦è¿½è¹¤çš„è©•ä¼°å‡½æ•¸"""
    args, tracker = args_with_tracker
    result = evaluate_single_param_set(args)
    tracker.update()
    return result


# å…¨å±€é€²åº¦è¿½è¹¤å™¨ï¼ˆç”¨æ–¼ä¸¦è¡Œè™•ç†ï¼‰
_global_progress_tracker = None

def init_global_progress_tracker(total_tasks):
    """åˆå§‹åŒ–å…¨å±€é€²åº¦è¿½è¹¤å™¨"""
    global _global_progress_tracker
    _global_progress_tracker = ProgressTracker(total_tasks)

def update_global_progress():
    """æ›´æ–°å…¨å±€é€²åº¦"""
    global _global_progress_tracker
    if _global_progress_tracker:
        _global_progress_tracker.update()

def evaluate_single_param_set_with_progress(args):
    """å¸¶å…¨å±€é€²åº¦è¿½è¹¤çš„è©•ä¼°å‡½æ•¸"""
    # åœ¨æ¯å€‹å­é€²ç¨‹ä¸­è¨­ç½®æ—¥èªŒç´šåˆ¥ç‚º WARNING ä»¥æŠ‘åˆ¶äº¤æ˜“æ—¥èªŒ
    import logging
    logging.getLogger().setLevel(logging.WARNING)

    result = evaluate_single_param_set(args)
    update_global_progress()
    return result


def create_report_directory():
    """
    å‰µå»ºå¯¦é©—å ±å‘Šç›®éŒ„

    Returns:
        str: å ±å‘Šç›®éŒ„è·¯å¾‘
    """
    base_dir = "/Users/z/big/my-capital-project/quan_strategy_analysis/SALIB_report"
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_dir = os.path.join(base_dir, f"sensitivity_analysis_{timestamp}")

    os.makedirs(report_dir, exist_ok=True)
    logger.info(f"ğŸ“ å‰µå»ºå ±å‘Šç›®éŒ„: {report_dir}")

    return report_dir


def save_sensitivity_plot(df_results, trading_direction, report_dir):
    """
    ä¿å­˜æ•æ„Ÿåº¦åˆ†æåœ–è¡¨

    Args:
        df_results: åŒ…å«æ•æ„Ÿåº¦çµæœçš„DataFrame
        trading_direction: äº¤æ˜“æ–¹å‘
        report_dir: å ±å‘Šç›®éŒ„è·¯å¾‘
    """
    try:
        # è¨­å®šä¸­æ–‡å­—é«”ï¼ˆå¦‚æœéœ€è¦ï¼‰
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False

        # æŒ‰STå€¼æ’åºï¼ˆå‡åºï¼Œæ–¹ä¾¿ç¹ªåœ–ï¼‰
        df_plot = df_results.sort_values('ST', ascending=True)

        # å‰µå»ºåœ–è¡¨
        plt.figure(figsize=(12, 8))
        bars = plt.barh(df_plot['Parameter'], df_plot['ST'], color='skyblue')

        # è¨­å®šæ¨™é¡Œå’Œæ¨™ç±¤
        plt.title(f'Sobol æ•æ„Ÿåº¦åˆ†æçµæœ - {trading_direction} äº¤æ˜“æ–¹å‘', fontsize=16, fontweight='bold')
        plt.xlabel('ç¸½æ•æ„Ÿåº¦æŒ‡æ•¸ (ST)', fontsize=12)
        plt.ylabel('åƒæ•¸', fontsize=12)

        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bar, value in zip(bars, df_plot['ST']):
            plt.text(value + 0.01, bar.get_y() + bar.get_height()/2,
                    f'{value:.4f}', va='center', fontsize=10)

        # èª¿æ•´ä½ˆå±€
        plt.tight_layout()
        plt.grid(axis='x', alpha=0.3)

        # ä¿å­˜åœ–ç‰‡
        plot_path = os.path.join(report_dir, f'sensitivity_{trading_direction}.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        logger.info(f"ğŸ“Š ä¿å­˜æ•æ„Ÿåº¦åœ–è¡¨: {plot_path}")

        # é¡¯ç¤ºåœ–è¡¨ï¼ˆå¯é¸ï¼‰
        # plt.show()
        plt.close()

    except Exception as e:
        logger.error(f"âŒ ä¿å­˜åœ–è¡¨å¤±æ•— ({trading_direction}): {e}")


def save_sensitivity_csv(df_results, trading_direction, report_dir, additional_info=None):
    """
    ä¿å­˜æ•æ„Ÿåº¦åˆ†æCSVçµæœ

    Args:
        df_results: åŒ…å«æ•æ„Ÿåº¦çµæœçš„DataFrame
        trading_direction: äº¤æ˜“æ–¹å‘
        report_dir: å ±å‘Šç›®éŒ„è·¯å¾‘
        additional_info: é¡å¤–ä¿¡æ¯å­—å…¸
    """
    try:
        # æ·»åŠ é¡å¤–ä¿¡æ¯åˆ—
        if additional_info:
            for key, value in additional_info.items():
                df_results[key] = value

        # ä¿å­˜CSV
        csv_path = os.path.join(report_dir, f'sensitivity_results_{trading_direction}.csv')
        df_results.to_csv(csv_path, index=False, encoding='utf-8-sig')
        logger.info(f"ğŸ’¾ ä¿å­˜æ•æ„Ÿåº¦CSV: {csv_path}")

    except Exception as e:
        logger.error(f"âŒ ä¿å­˜CSVå¤±æ•— ({trading_direction}): {e}")


# ==============================================================================
# Task 3: å¯¦ç¾ä¸»åŸ·è¡Œæµç¨‹
# ==============================================================================

def run_sensitivity_analysis(target_time_slot: Tuple[str, str], sample_size: int = 64,
                           start_date: str = "2024-11-04", end_date: str = "2025-06-28",
                           use_parallel: bool = True, num_processes: Optional[int] = None) -> Dict[str, Any]:
    """
    åŸ·è¡Œå®Œæ•´çš„æ•æ„Ÿåº¦åˆ†ææµç¨‹

    Args:
        target_time_slot: ç›®æ¨™æ™‚é–“å€æ®µï¼Œä¾‹å¦‚ ('08:46', '08:47')
        sample_size: SALib æ¨£æœ¬æ•¸
        start_date: å›æ¸¬é–‹å§‹æ—¥æœŸ
        end_date: å›æ¸¬çµæŸæ—¥æœŸ
        use_parallel: æ˜¯å¦ä½¿ç”¨ä¸¦è¡Œè™•ç†
        num_processes: ä¸¦è¡Œè™•ç†æ ¸å¿ƒæ•¸ï¼ˆNoneæ™‚è‡ªå‹•è¨­å®šç‚ºCPUæ ¸å¿ƒæ•¸-4ï¼‰

    Returns:
        dict: åŒ…å«æ‰€æœ‰äº¤æ˜“æ–¹å‘åˆ†æçµæœçš„å­—å…¸
    """
    range_start_time, range_end_time = target_time_slot
    results = {}

    # è¨­å®šä¸¦è¡Œè™•ç†æ ¸å¿ƒæ•¸
    if num_processes is None:
        # æ ¹æ“šæ‚¨çš„CPUæ ¸å¿ƒæ•¸è¨­å®šé€²ç¨‹æ•¸ï¼Œé è¨­ä½¿ç”¨4æ ¸å¿ƒ
        num_processes = min(4, multiprocessing.cpu_count() - 1)
    if num_processes < 1:
        num_processes = 1

    # å‰µå»ºå ±å‘Šç›®éŒ„
    report_dir = create_report_directory()

    logger.info(f"ğŸ¯ é–‹å§‹æ•æ„Ÿåº¦åˆ†æ | æ™‚é–“å€æ®µ: {range_start_time}-{range_end_time} | æ¨£æœ¬æ•¸: {sample_size}")
    if use_parallel:
        logger.info(f"ğŸ”¥ ä½¿ç”¨ {num_processes} å€‹æ ¸å¿ƒä¸¦è¡Œè¨ˆç®—...")
    else:
        logger.info(f"ğŸ”„ ä½¿ç”¨å–®æ ¸å¿ƒé †åºè¨ˆç®—...")

    # åˆå§‹åŒ–æ•¸æ“šæº
    if USE_SQLITE:
        try:
            sqlite_connection.init_sqlite_connection()
            logger.info("âœ… SQLiteé€£æ¥åˆå§‹åŒ–æˆåŠŸã€‚")
        except Exception as e:
            logger.error(f"âŒ SQLiteé€£æ¥åˆå§‹åŒ–å¤±æ•—: {e}")
            return {}
    else:
        try:
            from app_setup import init_all_db_pools
            init_all_db_pools()
            logger.info("âœ… PostgreSQLé€£ç·šæ± åˆå§‹åŒ–æˆåŠŸã€‚")
        except Exception as e:
            logger.error(f"âŒ PostgreSQLé€£ç·šæ± åˆå§‹åŒ–å¤±æ•—: {e}")
            return {}

    # å°æ¯å€‹äº¤æ˜“æ–¹å‘åˆ†åˆ¥é€²è¡Œåˆ†æ
    for trading_direction in TRADING_DIRECTIONS:
        logger.info(f"\nğŸ“Š åˆ†æäº¤æ˜“æ–¹å‘: {trading_direction}")

        try:
            # 1. ç”Ÿæˆæ¨£æœ¬
            logger.info(f"   ğŸ² ç”Ÿæˆ Sobol æ¨£æœ¬...")
            param_values = sobol_sample.sample(problem, N=sample_size)
            logger.info(f"   âœ… ç”Ÿæˆäº† {len(param_values)} å€‹åƒæ•¸çµ„åˆ")

            # 2. åŸ·è¡Œå›æ¸¬
            logger.info(f"   ğŸ”„ åŸ·è¡Œå›æ¸¬...")
            Y = np.zeros(len(param_values))

            if use_parallel and len(param_values) > 10:  # åªæœ‰æ¨£æœ¬æ•¸è¶³å¤ å¤§æ™‚æ‰ä½¿ç”¨ä¸¦è¡Œ
                # ä¸¦è¡Œè™•ç†
                logger.info(f"   ğŸš€ ä½¿ç”¨ {num_processes} æ ¸å¿ƒä¸¦è¡Œè™•ç†...")

                # å‰µå»ºé€²åº¦è¿½è¹¤å™¨
                progress_tracker = ProgressTracker(len(param_values), update_interval=5)

                # æº–å‚™åƒæ•¸ï¼ˆä¸ä½¿ç”¨é€²åº¦è¿½è¹¤çš„ç°¡å–®ç‰ˆæœ¬ï¼‰
                args_list = [(params, trading_direction, start_date, end_date, range_start_time, range_end_time)
                           for params in param_values]

                # ä½¿ç”¨é€²ç¨‹æ± ä¸¦è¡Œè¨ˆç®—
                with multiprocessing.Pool(processes=num_processes) as pool:
                    # åŸ·è¡Œä¸¦è¡Œè¨ˆç®—
                    results_list = pool.map(evaluate_single_param_set, args_list)
                    Y = np.array(results_list)

                # æ‰‹å‹•æ›´æ–°é€²åº¦åˆ°100%
                logger.info(f"   âœ… ä¸¦è¡Œè¨ˆç®—å®Œæˆ: {len(param_values)}/{len(param_values)} (100.0%)")

            else:
                # é †åºè™•ç†
                progress_tracker = ProgressTracker(len(param_values), update_interval=5)

                for i, params in enumerate(param_values):
                    Y[i] = evaluate_for_salib(params, trading_direction, start_date, end_date,
                                            range_start_time, range_end_time)

                    # æ›´æ–°é€²åº¦ï¼ˆæ¯5%é¡¯ç¤ºä¸€æ¬¡ï¼‰
                    current_percentage = ((i + 1) / len(param_values)) * 100
                    if current_percentage - progress_tracker.last_reported_percentage >= 5:
                        logger.info(f"   ğŸ“Š é€²åº¦æ›´æ–°: {i+1}/{len(param_values)} ({current_percentage:.1f}%)")
                        progress_tracker.last_reported_percentage = current_percentage

                # å®Œæˆæ™‚å ±å‘Š
                logger.info(f"   âœ… é †åºè¨ˆç®—å®Œæˆ: {len(param_values)}/{len(param_values)} (100.0%)")

            logger.info(f"   âœ… å›æ¸¬å®Œæˆï¼Œæœ‰æ•ˆçµæœ: {np.sum(Y > -999999)} / {len(Y)}")

            # ğŸ” è¨ºæ–·ï¼šæª¢æŸ¥ Y å€¼çš„åˆ†ä½ˆ
            valid_Y = Y[Y > -999999]
            if len(valid_Y) > 0:
                logger.info(f"   ğŸ“Š MDD çµ±è¨ˆ: æœ€å°={-valid_Y.max():.2f}, æœ€å¤§={-valid_Y.min():.2f}, å¹³å‡={-valid_Y.mean():.2f}, æ¨™æº–å·®={valid_Y.std():.4f}")
                logger.info(f"   ğŸ“Š å”¯ä¸€å€¼æ•¸é‡: {len(np.unique(valid_Y))}")

                # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰å€¼éƒ½ç›¸åŒ
                if valid_Y.std() < 1e-10:
                    logger.warning(f"   âš ï¸ è­¦å‘Šï¼šæ‰€æœ‰ MDD å€¼å¹¾ä¹ç›¸åŒ ({-valid_Y.mean():.6f})ï¼Œæ•æ„Ÿåº¦åˆ†æå¯èƒ½ç„¡æ•ˆ")
                    logger.warning(f"   ğŸ’¡ å»ºè­°ï¼šæª¢æŸ¥åƒæ•¸ç¯„åœæ˜¯å¦åˆç†ï¼Œæˆ–å¢åŠ æ¨£æœ¬æ•¸")
            else:
                logger.error(f"   âŒ æ²’æœ‰æœ‰æ•ˆçš„å›æ¸¬çµæœï¼")
                continue

            # 3. åŸ·è¡Œ Sobol åˆ†æ
            logger.info(f"   ğŸ“ˆ åŸ·è¡Œ Sobol æ•æ„Ÿåº¦åˆ†æ...")
            Si = sobol.analyze(problem, Y)

            # 4. æ ¼å¼åŒ–çµæœ
            results[trading_direction] = {
                'Si': Si,
                'Y_values': Y,
                'param_values': param_values,
                'valid_results': np.sum(Y > -999999),
                'total_samples': len(Y)
            }

            # 5. é¡¯ç¤ºçµæœæ‘˜è¦
            logger.info(f"   ğŸ“‹ {trading_direction} æ•æ„Ÿåº¦åˆ†æçµæœ:")

            # æ‰‹å‹•å‰µå»º DataFrameï¼ˆå› ç‚ºæ–°ç‰ˆ SALib å¯èƒ½æ²’æœ‰ to_df æ–¹æ³•ï¼‰
            sensitivity_data = {
                'Parameter': problem['names'],
                'S1': Si['S1'],
                'ST': Si['ST']
            }
            df_results = pd.DataFrame(sensitivity_data)

            # é¡¯ç¤ºç¸½æ•æ„Ÿåº¦æŒ‡æ•¸ (ST) æ’åº
            st_sorted = df_results.sort_values('ST', ascending=False)
            logger.info(f"   ğŸ† ç¸½æ•æ„Ÿåº¦æŒ‡æ•¸ (ST) æ’å:")
            for rank, (_, row) in enumerate(st_sorted.iterrows(), 1):
                param_name = row['Parameter']
                logger.info(f"      {rank}. {param_name}: ST={row['ST']:.4f}, S1={row['S1']:.4f}")

            # 6. ä¿å­˜çµæœå’Œè¦–è¦ºåŒ–
            logger.info(f"   ğŸ’¾ ä¿å­˜åˆ†æçµæœ...")

            # æ·»åŠ é¡å¤–ä¿¡æ¯
            additional_info = {
                'Trading_Direction': trading_direction,
                'Sample_Size': sample_size,
                'Time_Slot': f"{range_start_time}-{range_end_time}",
                'Analysis_Date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'Valid_Results': np.sum(Y > -999999),
                'Total_Samples': len(Y)
            }

            # ä¿å­˜CSVçµæœ
            save_sensitivity_csv(df_results, trading_direction, report_dir, additional_info)

            # ä¿å­˜è¦–è¦ºåŒ–åœ–è¡¨
            save_sensitivity_plot(df_results, trading_direction, report_dir)

        except Exception as e:
            logger.error(f"âŒ {trading_direction} åˆ†æå¤±æ•—: {e}")
            results[trading_direction] = {'error': str(e)}

    return results


if __name__ == '__main__':
    # è¨­å®šåˆ†æç›®æ¨™
    TARGET_TIME_SLOT = ('11:00', '11:02')  # ç›®æ¨™æ™‚é–“å€æ®µ
    N = 64  # SALib æ¨£æœ¬æ•¸ï¼ˆå»ºè­°å¾å°å€¼é–‹å§‹æ¸¬è©¦ï¼‰

    logger.info("ğŸš€ ç­–ç•¥æ•æ„Ÿåº¦åˆ†æå™¨å•Ÿå‹•")
    logger.info(f"ğŸ“… åˆ†ææ™‚é–“å€æ®µ: {TARGET_TIME_SLOT[0]} - {TARGET_TIME_SLOT[1]} (é–‹ç›¤å€é–“)")
    logger.info(f"ğŸ² æ¨£æœ¬æ•¸: {N}")

    # åŸ·è¡Œåˆ†æ
    analysis_results = run_sensitivity_analysis(
        target_time_slot=TARGET_TIME_SLOT,
        sample_size=N,
        start_date="2024-11-04",
        end_date="2025-06-28",
        use_parallel=True,  # å•Ÿç”¨ä¸¦è¡Œè™•ç†
        num_processes=4     # ä½¿ç”¨4æ ¸å¿ƒ
    )

    # é¡¯ç¤ºæœ€çµ‚çµæœæ‘˜è¦
    logger.info("\n" + "="*60)
    logger.info("ğŸ“Š æ•æ„Ÿåº¦åˆ†æå®Œæ•´çµæœæ‘˜è¦")
    logger.info("="*60)

    for direction, result in analysis_results.items():
        if 'error' in result:
            logger.info(f"\nâŒ {direction}: åˆ†æå¤±æ•— - {result['error']}")
            continue

        logger.info(f"\nğŸ“ˆ {direction} äº¤æ˜“æ–¹å‘çµæœ:")
        logger.info(f"   æœ‰æ•ˆæ¨£æœ¬: {result['valid_results']} / {result['total_samples']}")

        # é¡¯ç¤ºæœ€é‡è¦çš„åƒæ•¸
        Si = result['Si']
        sensitivity_data = {
            'Parameter': problem['names'],
            'S1': Si['S1'],
            'ST': Si['ST']
        }
        df_results = pd.DataFrame(sensitivity_data)
        top_params = df_results.sort_values('ST', ascending=False).head(3)

        logger.info(f"   ğŸ† å½±éŸ¿MDDæœ€å¤§çš„å‰3å€‹åƒæ•¸:")
        for rank, (_, row) in enumerate(top_params.iterrows(), 1):
            param_name = row['Parameter']
            logger.info(f"      {rank}. {param_name}: ST={row['ST']:.4f}")

    logger.info("\nâœ… æ•æ„Ÿåº¦åˆ†æå®Œæˆï¼")
