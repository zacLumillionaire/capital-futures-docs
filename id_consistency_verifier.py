#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ID Consistency Verifier (IDä¸€è‡´æ€§è‡ªå‹•é©—è­‰å™¨)

æ­¤è…³æœ¬åŸ·è¡Œéœæ…‹ç¨‹å¼ç¢¼åˆ†æï¼Œç”¨æ–¼æª¢æ¸¬ç¨‹å¼ç¢¼ä¸­ group_id å’Œ position_id ä½¿ç”¨çš„æ½›åœ¨å•é¡Œã€‚
å®ƒæœ‰åŠ©æ–¼ç¢ºä¿æ•´å€‹äº¤æ˜“ç³»çµ±ä¸­ä½¿ç”¨ä¸€è‡´çš„å‘½åè¦ç¯„å’Œæ­£ç¢ºçš„IDç”¨æ³•ã€‚

ä½¿ç”¨æ–¹æ³•:
    python id_consistency_verifier.py [ç›®éŒ„è·¯å¾‘]

å¦‚æœæœªæŒ‡å®šç›®éŒ„ï¼Œé è¨­æœƒåˆ†æ Capital_Official_Framework ç›®éŒ„ã€‚

åŠŸèƒ½:
1. è‡ªå‹•éæ­·æŒ‡å®šç›®éŒ„ä¸‹çš„æ‰€æœ‰ .py æª”æ¡ˆ
2. ä½¿ç”¨ AST é€²è¡Œéœæ…‹åˆ†æï¼Œç„¡éœ€åŸ·è¡Œç¨‹å¼ç¢¼
3. æª¢æ¸¬ä»¥ä¸‹å•é¡Œé¡å‹:
   - æ¨¡ç³Šè®Šæ•¸: ä½¿ç”¨æ¨¡ç³Šçš„è®Šæ•¸åç¨±å¦‚ 'group_id', 'position_id', 'id'
   - å‡½å¼ç°½åæ¨¡ç³Š: å‡½å¼åƒæ•¸ä½¿ç”¨æ¨¡ç³Šçš„åç¨±
   - æ¨¡ç³Šå­—å…¸éµ: å­—å…¸ä¸­ä½¿ç”¨æ¨¡ç³Šçš„éµå
   - SQLæŸ¥è©¢ä¸è¦ç¯„: SQLæŸ¥è©¢ä¸­æœªä½¿ç”¨ AS é‡å‘½å
   - SQLæ¢ä»¶æ¨¡ç³Š: WHERE å­å¥ä¸­ä½¿ç”¨æ¨¡ç³Šçš„æ¢ä»¶
4. ç”Ÿæˆè©³ç´°å ±å‘Šï¼Œåˆ—å‡ºæ‰€æœ‰ç™¼ç¾çš„å•é¡Œ

å»ºè­°ä½¿ç”¨æµç¨‹:
1. é‡æ§‹å‰é‹è¡Œ: åŸ·è¡Œæ­¤è…³æœ¬ç²å–ã€Œå•é¡Œæ¸…å–®ã€ï¼Œä½œç‚ºé‡æ§‹çš„ç›®æ¨™
2. é‡æ§‹å¾Œé‹è¡Œ: å†æ¬¡åŸ·è¡Œè…³æœ¬ï¼Œå¦‚æœå ±å‘Šç‚ºç©ºå‰‡è­‰æ˜é‡æ§‹æˆåŠŸä¸”å®Œæ•´
3. å„ªå…ˆè™•ç†: å‡½å¼ç°½åæ¨¡ç³Š > æ¨¡ç³Šè®Šæ•¸ > SQLæŸ¥è©¢ä¸è¦ç¯„ > æ¨¡ç³Šå­—å…¸éµ
4. å»ºè­°å‘½å: ä½¿ç”¨ group_pk, logical_group_id, position_pk, position_logical_id
"""

import os
import sys
import ast
import re
import time
from typing import List, Dict, Any, Optional, Tuple


class IDVerifier(ast.NodeVisitor):
    """
    AST node visitor that checks for potential ID consistency issues.

    This class traverses the AST of Python files and identifies potential issues
    with group_id and position_id usage.
    """

    def __init__(self, file_path: str):
        """
        Initialize the IDVerifier.

        Args:
            file_path: Path to the file being analyzed
        """
        self.file_path = file_path
        self.issues = []
        self.current_function = None
        self.current_class = None

        # List of ambiguous ID names to check for
        self.ambiguous_id_names = [
            "group_id", "id", "position_id", "pos_id", "group", "position"
        ]

        # List of preferred ID names
        self.preferred_id_names = [
            "group_pk", "logical_group_id", "position_pk", "position_logical_id"
        ]

    def add_issue(self, line_number: int, issue_type: str, message: str):
        """
        Add an issue to the list of issues found.

        Args:
            line_number: Line number where the issue was found
            issue_type: Type of issue (e.g., "æ¨¡ç³Šè®Šæ•¸", "å‡½å¼ç°½åæ¨¡ç³Š", etc.)
            message: Detailed description of the issue
        """
        self.issues.append({
            "file_path": self.file_path,
            "line_number": line_number,
            "issue_type": issue_type,
            "message": message
        })

    def visit_Name(self, node):
        """
        Visit a variable name node and check for ambiguous ID names.

        This method is called for each variable name in the AST.
        """
        # Check if the variable name is in our list of ambiguous names
        if node.id in self.ambiguous_id_names:
            self.add_issue(
                node.lineno,
                "æ¨¡ç³Šè®Šæ•¸",
                f"ç™¼ç¾æ½›åœ¨çš„æ¨¡ç³Šè®Šæ•¸ '{node.id}'ã€‚å»ºè­°ä½¿ç”¨æ›´æ˜ç¢ºçš„åç¨±ï¼Œå¦‚ {', '.join(self.preferred_id_names)}"
            )

        # Continue visiting child nodes
        self.generic_visit(node)

    def visit_FunctionDef(self, node):
        """
        Visit a function definition node and check for ambiguous parameter names.

        This method is called for each function definition in the AST.
        """
        # Save the current function name for context
        old_function = self.current_function
        self.current_function = node.name

        # Check function parameters for ambiguous names
        for arg in node.args.args:
            if hasattr(arg, 'arg') and arg.arg in self.ambiguous_id_names:
                self.add_issue(
                    node.lineno,
                    "å‡½å¼ç°½åæ¨¡ç³Š",
                    f"å‡½å¼ '{node.name}' ä½¿ç”¨äº†æ¨¡ç³Šåƒæ•¸ '{arg.arg}'ã€‚å»ºè­°ä½¿ç”¨æ›´æ˜ç¢ºçš„åç¨±ï¼Œå¦‚ {', '.join(self.preferred_id_names)}"
                )

        # Visit child nodes
        self.generic_visit(node)

        # Restore the previous function context
        self.current_function = old_function

    def visit_Constant(self, node):
        """
        Visit a constant node and check for SQL queries with ambiguous ID usage.

        This method is called for each string constant in the AST.
        """
        # Check if this is a string constant
        if isinstance(node.value, str):
            self._check_sql_string(node.value, node.lineno)

        # Continue visiting child nodes
        self.generic_visit(node)

    def visit_Str(self, node):
        """
        Visit a string node (for Python < 3.8 compatibility).

        This method is called for each string literal in the AST.
        """
        self._check_sql_string(node.s, node.lineno)

        # Continue visiting child nodes
        self.generic_visit(node)

    def _check_sql_string(self, string_value: str, line_number: int):
        """
        Check a string for SQL-related ID issues.

        Args:
            string_value: The string content to check
            line_number: Line number where the string was found
        """
        # Skip empty strings
        if not string_value:
            return

        try:
            # Convert to lowercase for case-insensitive matching
            lower_string = string_value.lower()

            # Simple check for SQL keywords
            sql_keywords = ['select', 'insert', 'update', 'delete', 'where']
            is_sql = any(keyword in lower_string for keyword in sql_keywords)

            if is_sql:
                # Check for SELECT queries without AS aliases for ambiguous columns
                if 'select' in lower_string:
                    # Simple pattern matching
                    if ('id' in lower_string or 'group_id' in lower_string or 'position_id' in lower_string) and ' as ' not in lower_string:
                        self.add_issue(
                            line_number,
                            "SQLæŸ¥è©¢ä¸è¦ç¯„",
                            f"SELECTæŸ¥è©¢æœªå° 'id', 'group_id', æˆ– 'position_id' ä½¿ç”¨ AS é€²è¡Œé‡å‘½åã€‚å»ºè­°ä½¿ç”¨ AS æ˜ç¢ºæŒ‡å®šåˆ—å"
                        )

                # Check for WHERE clauses with ambiguous conditions
                if 'where' in lower_string:
                    if 'group_id =' in lower_string or 'position_id =' in lower_string:
                        self.add_issue(
                            line_number,
                            "SQLæ¢ä»¶æ¨¡ç³Š",
                            f"WHEREå­å¥ä½¿ç”¨äº†æ¨¡ç³Šçš„IDæ¢ä»¶ã€‚å»ºè­°ä½¿ç”¨æ›´æ˜ç¢ºçš„æ¬„ä½åç¨±"
                        )
        except Exception as e:
            # Silently ignore errors in string checking
            pass

    def visit_Subscript(self, node):
        """
        Visit a subscript node and check for dictionary key access with ambiguous IDs.

        This method is called for each dictionary/list access (e.g., dict['key']).
        """
        try:
            # Try to extract the key from the subscript
            key = None

            # Handle different Python versions and AST structures
            if hasattr(node, 'slice'):
                # Try to get the string value from various AST node types
                slice_node = node.slice

                # For ast.Constant (Python 3.8+)
                if hasattr(slice_node, 'value') and isinstance(slice_node.value, str):
                    key = slice_node.value
                # For ast.Str (older Python versions)
                elif hasattr(slice_node, 's'):
                    key = slice_node.s
                # For ast.Index wrapper (Python 3.8 and earlier)
                elif hasattr(slice_node, 'value'):
                    inner = slice_node.value
                    if hasattr(inner, 'value') and isinstance(inner.value, str):
                        key = inner.value
                    elif hasattr(inner, 's'):
                        key = inner.s

            # Check if we found a key and it's in our list of ambiguous names
            if key and key in self.ambiguous_id_names:
                self.add_issue(
                    node.lineno,
                    "æ¨¡ç³Šå­—å…¸éµ",
                    f"ç™¼ç¾æ½›åœ¨çš„æ¨¡ç³Šå­—å…¸éµè¨ªå• '{key}'ã€‚å»ºè­°ä½¿ç”¨æ›´æ˜ç¢ºçš„éµå"
                )
        except Exception as e:
            # Silently ignore errors in subscript checking
            pass

        # Continue visiting child nodes
        self.generic_visit(node)


def find_python_files(directory: str) -> List[str]:
    """
    Recursively find all Python files in the given directory.

    Args:
        directory: The root directory to start searching from

    Returns:
        A list of absolute paths to all Python files found
    """
    python_files = []

    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith('.py'):
                # Get the absolute path to the file
                file_path = os.path.abspath(os.path.join(root, file))
                python_files.append(file_path)

    return python_files


def analyze_file(file_path: str) -> List[Dict[str, Any]]:
    """
    Analyze a Python file for ID consistency issues.

    Args:
        file_path: Path to the Python file to analyze

    Returns:
        A list of issues found in the file
    """
    try:
        print(f"    ğŸ“– è®€å–æª”æ¡ˆ...")
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        print(f"    ğŸ” è§£æ AST...")
        # Parse the file into an AST
        tree = ast.parse(content, filename=file_path)

        print(f"    âš™ï¸  å‰µå»ºé©—è­‰å™¨...")
        # Create an IDVerifier instance and visit the AST
        verifier = IDVerifier(file_path)

        print(f"    ğŸš€ é–‹å§‹åˆ†æ...")
        verifier.visit(tree)

        print(f"    âœ… åˆ†æå®Œæˆï¼Œç™¼ç¾ {len(verifier.issues)} å€‹å•é¡Œ")
        return verifier.issues
    except UnicodeDecodeError:
        print(f"    âŒ ç·¨ç¢¼éŒ¯èª¤ï¼Œå˜—è©¦å…¶ä»–ç·¨ç¢¼...")
        # Try with a different encoding
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                content = f.read()
            tree = ast.parse(content, filename=file_path)
            verifier = IDVerifier(file_path)
            verifier.visit(tree)
            return verifier.issues
        except Exception as e:
            print(f"    âŒ ç·¨ç¢¼å•é¡Œç„¡æ³•è§£æ±º: {str(e)}")
            return [{
                "file_path": file_path,
                "line_number": 0,
                "issue_type": "è§£æéŒ¯èª¤",
                "message": f"ç„¡æ³•è§£ææª”æ¡ˆ (ç·¨ç¢¼å•é¡Œ): {str(e)}"
            }]
    except Exception as e:
        print(f"    âŒ åˆ†æéŒ¯èª¤: {str(e)}")
        # Handle parsing errors (e.g., syntax errors in the file)
        return [{
            "file_path": file_path,
            "line_number": 0,
            "issue_type": "è§£æéŒ¯èª¤",
            "message": f"ç„¡æ³•è§£ææª”æ¡ˆ: {str(e)}"
        }]


def generate_report(all_issues: List[Dict[str, Any]]) -> str:
    """
    Generate a formatted report from the list of issues.

    Args:
        all_issues: List of all issues found across all files

    Returns:
        A formatted report string
    """
    if not all_issues:
        return "--- ID Consistency Verification Report ---\n\nâœ… No potential issues found. Great job!\n"

    # Group issues by file
    issues_by_file = {}
    for issue in all_issues:
        file_path = issue['file_path']
        if file_path not in issues_by_file:
            issues_by_file[file_path] = []
        issues_by_file[file_path].append(issue)

    # Generate report
    report = "--- ID Consistency Verification Report ---\n\n"

    for file_path, file_issues in issues_by_file.items():
        report += f"Scanning file: {file_path}\n"

        # Group issues by type for better organization
        issues_by_type = {}
        for issue in file_issues:
            issue_type = issue['issue_type']
            if issue_type not in issues_by_type:
                issues_by_type[issue_type] = []
            issues_by_type[issue_type].append(issue)

        # Display issues by type
        for issue_type, type_issues in sorted(issues_by_type.items()):
            report += f"  [{issue_type}] ({len(type_issues)} issues):\n"
            for issue in sorted(type_issues, key=lambda x: x['line_number']):
                report += f"    - L_{issue['line_number']}: {issue['message']}\n"

        report += "\n"

    # Summary
    report += f"Found {len(all_issues)} potential issues across {len(issues_by_file)} files.\n\n"

    # Recommendations
    report += "ğŸ“‹ Recommendations:\n"
    report += "1. é‡æ§‹å‰é‹è¡Œï¼šåŸ·è¡Œæ­¤è…³æœ¬ç²å–ã€Œå•é¡Œæ¸…å–®ã€ï¼Œä½œç‚ºé‡æ§‹çš„ç›®æ¨™\n"
    report += "2. é‡æ§‹å¾Œé‹è¡Œï¼šå†æ¬¡åŸ·è¡Œè…³æœ¬ï¼Œå¦‚æœå ±å‘Šç‚ºç©ºå‰‡è­‰æ˜é‡æ§‹æˆåŠŸä¸”å®Œæ•´\n"
    report += "3. å„ªå…ˆè™•ç†ï¼šå‡½å¼ç°½åæ¨¡ç³Š > æ¨¡ç³Šè®Šæ•¸ > SQLæŸ¥è©¢ä¸è¦ç¯„ > æ¨¡ç³Šå­—å…¸éµ\n"
    report += "4. å»ºè­°å‘½åï¼šä½¿ç”¨ group_pk, logical_group_id, position_pk, position_logical_id\n\n"

    return report


def main():
    """Main function to run the ID consistency verifier."""
    print("=== IDä¸€è‡´æ€§è‡ªå‹•é©—è­‰å™¨ ===\n")

    # Get the directory to analyze from command line arguments or use default
    if len(sys.argv) > 1:
        directory = sys.argv[1]
    else:
        # Default to Capital_Official_Framework for comprehensive analysis
        directory = os.path.join(os.getcwd(), "Capital_Official_Framework")

        # If the directory doesn't exist, fall back to current directory
        if not os.path.exists(directory):
            directory = os.getcwd()

    # æª¢æŸ¥æ•´å€‹å°ˆæ¡ˆ
    # specific_file = os.path.join(directory, "multi_group_position_manager.py")

    print(f"ğŸ“ åˆ†æç›®éŒ„: {directory}")

    # Find all Python files in the directory
    python_files = find_python_files(directory)

    print(f"ğŸ” æ‰¾åˆ° {len(python_files)} å€‹ Python æª”æ¡ˆ")

    # For demonstration, limit to first 20 files to include key files
    max_files = 20

    # ç¢ºä¿åŒ…å«é—œéµæª”æ¡ˆ
    key_files = ['multi_group_position_manager.py', 'multi_group_database.py', 'simple_integrated.py']
    priority_files = []
    other_files = []

    for file_path in python_files:
        file_name = file_path.split('\\')[-1] if '\\' in file_path else file_path.split('/')[-1]
        if file_name in key_files:
            priority_files.append(file_path)
        else:
            other_files.append(file_path)

    # å„ªå…ˆåˆ†æé—œéµæª”æ¡ˆï¼Œç„¶å¾Œåˆ†æå…¶ä»–æª”æ¡ˆ
    python_files = priority_files + other_files

    if len(python_files) > max_files:
        print(f"âš ï¸  ç‚ºé¿å…è¼¸å‡ºéå¤šï¼Œåƒ…åˆ†æå‰ {max_files} å€‹æª”æ¡ˆï¼ˆå„ªå…ˆåˆ†æé—œéµæª”æ¡ˆï¼‰ã€‚")
        python_files = python_files[:max_files]

    # Analyze each file
    all_issues = []
    print("\nğŸ”„ é–‹å§‹åˆ†æ...")

    for i, file_path in enumerate(python_files, 1):
        print(f"  ({i}/{len(python_files)}) åˆ†æ: {os.path.basename(file_path)}")
        issues = analyze_file(file_path)
        all_issues.extend(issues)

    # Generate and display the report
    print("\n" + "="*60)
    report = generate_report(all_issues)
    print(report)

    # Save report to file
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    report_filename = f"id_consistency_report_{timestamp}_{len(all_issues)}_issues.txt"
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"ğŸ“„ å ±å‘Šå·²å„²å­˜è‡³: {report_filename}")

    return len(all_issues)


if __name__ == "__main__":
    main()
