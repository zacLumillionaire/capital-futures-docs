#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å•Ÿç”¨è©³ç´°æ—¥èªŒè¨ºæ–·è…³æœ¬
ç”¨æ–¼è¨ºæ–·AsyncUpdaterå¤±æ•—åŸå› 
"""

import sqlite3
import os

def enable_async_detailed_logging():
    """å•Ÿç”¨AsyncUpdaterè©³ç´°æ—¥èªŒçš„ä»£ç¢¼ç‰‡æ®µ"""
    print("ğŸ” AsyncUpdaterè©³ç´°æ—¥èªŒå•Ÿç”¨ä»£ç¢¼:")
    print("=" * 60)
    print("åœ¨ simple_integrated.py çš„Consoleä¸­åŸ·è¡Œä»¥ä¸‹ä»£ç¢¼:")
    print()
    print("# 1. å•Ÿç”¨AsyncUpdaterè©³ç´°æ—¥èªŒ")
    print("if hasattr(self, 'async_updater') and self.async_updater:")
    print("    self.async_updater.enable_task_completion_logs = True")
    print("    print('âœ… å·²å•Ÿç”¨AsyncUpdaterä»»å‹™å®Œæˆæ—¥èªŒ')")
    print("else:")
    print("    print('âŒ AsyncUpdaterä¸å­˜åœ¨')")
    print()
    print("# 2. æª¢æŸ¥ç•¶å‰çµ±è¨ˆ")
    print("if hasattr(self, 'async_updater') and self.async_updater:")
    print("    stats = self.async_updater.stats")
    print("    print(f'ğŸ“Š ç•¶å‰çµ±è¨ˆ: ç¸½ä»»å‹™:{stats[\"total_tasks\"]}, å®Œæˆ:{stats[\"completed_tasks\"]}, å¤±æ•—:{stats[\"failed_tasks\"]}')")
    print("    print(f'ğŸ“Š éšŠåˆ—å¤§å°: {self.async_updater.update_queue.qsize()}')")
    print()
    print("# 3. æª¢æŸ¥å·¥ä½œç·šç¨‹ç‹€æ…‹")
    print("if hasattr(self, 'async_updater') and self.async_updater:")
    print("    if hasattr(self.async_updater, 'worker_thread'):")
    print("        thread = self.async_updater.worker_thread")
    print("        print(f'ğŸ§µ å·¥ä½œç·šç¨‹ç‹€æ…‹: {\"æ´»èº\" if thread and thread.is_alive() else \"éæ´»èº\"}')")
    print()

def check_database_constraints():
    """æª¢æŸ¥æ•¸æ“šåº«ç´„æŸ"""
    print("\nğŸ” æ•¸æ“šåº«ç´„æŸæª¢æŸ¥:")
    print("=" * 60)
    
    db_path = "multi_group_strategy.db"
    
    if not os.path.exists(db_path):
        print("âŒ è³‡æ–™åº«æª”æ¡ˆä¸å­˜åœ¨")
        return
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # 1. æª¢æŸ¥é¢¨éšªç®¡ç†ç‹€æ…‹è¡¨çµæ§‹
        print("ğŸ“‹ 1. é¢¨éšªç®¡ç†ç‹€æ…‹è¡¨çµæ§‹:")
        cursor.execute("PRAGMA table_info(risk_management_states)")
        columns = cursor.fetchall()
        
        for col in columns:
            col_id, name, type_name, not_null, default, pk = col
            constraints = []
            if not_null:
                constraints.append("NOT NULL")
            if pk:
                constraints.append("PRIMARY KEY")
            if default:
                constraints.append(f"DEFAULT {default}")
            
            constraint_str = f" ({', '.join(constraints)})" if constraints else ""
            print(f"   - {name}: {type_name}{constraint_str}")
        
        # 2. æª¢æŸ¥è¡¨çš„å®Œæ•´ç´„æŸ
        print("\nğŸ“‹ 2. è¡¨çš„å®Œæ•´ç´„æŸå®šç¾©:")
        cursor.execute("SELECT sql FROM sqlite_master WHERE type='table' AND name='risk_management_states'")
        table_sql = cursor.fetchone()
        if table_sql:
            print("   CREATE TABLE èªå¥:")
            print(f"   {table_sql[0]}")
        
        # 3. æª¢æŸ¥ç´¢å¼•
        print("\nğŸ“‹ 3. ç›¸é—œç´¢å¼•:")
        cursor.execute("SELECT name, sql FROM sqlite_master WHERE type='index' AND tbl_name='risk_management_states'")
        indexes = cursor.fetchall()
        
        if indexes:
            for idx_name, idx_sql in indexes:
                print(f"   - {idx_name}: {idx_sql}")
        else:
            print("   - ç„¡è‡ªå®šç¾©ç´¢å¼•")
        
        # 4. æª¢æŸ¥ç•¶å‰æ•¸æ“š
        print("\nğŸ“‹ 4. ç•¶å‰é¢¨éšªç®¡ç†ç‹€æ…‹æ•¸æ“š:")
        cursor.execute("SELECT COUNT(*) FROM risk_management_states")
        count = cursor.fetchone()[0]
        print(f"   - ç¸½è¨˜éŒ„æ•¸: {count}")
        
        if count > 0:
            cursor.execute("""
                SELECT position_id, peak_price, update_reason, last_update_time 
                FROM risk_management_states 
                ORDER BY position_id DESC 
                LIMIT 5
            """)
            recent_records = cursor.fetchall()
            print("   - æœ€è¿‘5æ¢è¨˜éŒ„:")
            for record in recent_records:
                print(f"     éƒ¨ä½{record[0]}: å³°å€¼={record[1]}, åŸå› ='{record[2]}', æ™‚é–“={record[3]}")
        
        # 5. æª¢æŸ¥å¯èƒ½çš„ç´„æŸè¡çª
        print("\nğŸ“‹ 5. æª¢æŸ¥å¯èƒ½çš„ç´„æŸå•é¡Œ:")
        
        # æª¢æŸ¥é‡è¤‡çš„position_id
        cursor.execute("""
            SELECT position_id, COUNT(*) as count 
            FROM risk_management_states 
            GROUP BY position_id 
            HAVING COUNT(*) > 1
        """)
        duplicates = cursor.fetchall()
        
        if duplicates:
            print("   âš ï¸ ç™¼ç¾é‡è¤‡çš„position_id:")
            for pos_id, count in duplicates:
                print(f"     éƒ¨ä½{pos_id}: {count}æ¢è¨˜éŒ„")
        else:
            print("   âœ… ç„¡é‡è¤‡çš„position_id")
        
        # 6. æª¢æŸ¥update_reasonçš„å€¼
        print("\nğŸ“‹ 6. update_reasonå€¼åˆ†æ:")
        cursor.execute("""
            SELECT update_reason, COUNT(*) as count 
            FROM risk_management_states 
            GROUP BY update_reason 
            ORDER BY count DESC
        """)
        reasons = cursor.fetchall()
        
        if reasons:
            print("   ç•¶å‰ä½¿ç”¨çš„update_reasonå€¼:")
            for reason, count in reasons:
                print(f"     '{reason}': {count}æ¬¡")
        
        conn.close()
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šåº«æª¢æŸ¥å¤±æ•—: {e}")

def check_peak_update_logic():
    """æª¢æŸ¥å³°å€¼æ›´æ–°é‚è¼¯çš„ä»£ç¢¼ç‰‡æ®µ"""
    print("\nğŸ” å³°å€¼æ›´æ–°é‚è¼¯æª¢æŸ¥:")
    print("=" * 60)
    print("åœ¨ simple_integrated.py çš„Consoleä¸­åŸ·è¡Œä»¥ä¸‹ä»£ç¢¼ä¾†æª¢æŸ¥å³°å€¼æ›´æ–°é‚è¼¯:")
    print()
    print("# 1. æª¢æŸ¥é¢¨éšªç®¡ç†å¼•æ“çš„å³°å€¼æ›´æ–°è¨­ç½®")
    print("if hasattr(self, 'multi_group_risk_engine'):")
    print("    engine = self.multi_group_risk_engine")
    print("    print(f'ğŸ”§ ç•°æ­¥å³°å€¼æ›´æ–°å•Ÿç”¨: {getattr(engine, \"enable_async_peak_update\", \"æœªè¨­ç½®\")}')")
    print("    print(f'ğŸ”§ ç•°æ­¥æ›´æ–°å™¨é€£æ¥: {\"æ˜¯\" if getattr(engine, \"async_updater\", None) else \"å¦\"}')")
    print()
    print("# 2. æª¢æŸ¥æœ€è¿‘çš„å³°å€¼æ›´æ–°ä»»å‹™")
    print("if hasattr(self, 'async_updater') and self.async_updater:")
    print("    cache = self.async_updater.memory_cache.get('risk_states', {})")
    print("    print(f'ğŸ“Š å…§å­˜ä¸­çš„é¢¨éšªç‹€æ…‹æ•¸é‡: {len(cache)}')")
    print("    if cache:")
    print("        latest_positions = list(cache.keys())[-3:]  # æœ€è¿‘3å€‹éƒ¨ä½")
    print("        for pos_id in latest_positions:")
    print("            state = cache[pos_id]")
    print("            print(f'   éƒ¨ä½{pos_id}: å³°å€¼={state.get(\"peak_price\")}, åŸå› ={state.get(\"update_reason\")}')")
    print()
    print("# 3. æ‰‹å‹•æ¸¬è©¦å³°å€¼æ›´æ–°")
    print("# æ³¨æ„ï¼šåªåœ¨ç¢ºå¯¦éœ€è¦æ™‚åŸ·è¡Œï¼Œé¿å…ç”¢ç”ŸéŒ¯èª¤æ•¸æ“š")
    print("# test_position_id = 146  # æ›¿æ›ç‚ºå¯¦éš›çš„éƒ¨ä½ID")
    print("# test_peak_price = 22573.0  # æ›¿æ›ç‚ºå¯¦éš›çš„å³°å€¼åƒ¹æ ¼")
    print("# try:")
    print("#     success = self.multi_group_db_manager.update_risk_management_state(")
    print("#         position_id=test_position_id,")
    print("#         peak_price=test_peak_price,")
    print("#         update_time='12:30:00',")
    print("#         update_reason='åƒ¹æ ¼æ›´æ–°'")
    print("#     )")
    print("#     print(f'æ‰‹å‹•å³°å€¼æ›´æ–°æ¸¬è©¦: {\"æˆåŠŸ\" if success else \"å¤±æ•—\"}')")
    print("# except Exception as e:")
    print("#     print(f'æ‰‹å‹•å³°å€¼æ›´æ–°å¤±æ•—: {e}')")

def analyze_peak_update_frequency():
    """åˆ†æå³°å€¼æ›´æ–°é »ç‡"""
    print("\nğŸ” å³°å€¼æ›´æ–°é »ç‡åˆ†æ:")
    print("=" * 60)
    print("åœ¨ simple_integrated.py çš„Consoleä¸­åŸ·è¡Œä»¥ä¸‹ä»£ç¢¼:")
    print()
    print("# æª¢æŸ¥å³°å€¼æ›´æ–°çš„è§¸ç™¼é »ç‡")
    print("import time")
    print("start_time = time.time()")
    print("if hasattr(self, 'async_updater') and self.async_updater:")
    print("    initial_stats = self.async_updater.stats.copy()")
    print("    print(f'ğŸ“Š é–‹å§‹ç›£æ§ - ç•¶å‰ä»»å‹™æ•¸: {initial_stats[\"total_tasks\"]}')")
    print("    print('ç­‰å¾…30ç§’å¾Œå†æ¬¡æª¢æŸ¥...')")
    print("    ")
    print("    # 30ç§’å¾ŒåŸ·è¡Œ:")
    print("    # current_stats = self.async_updater.stats")
    print("    # new_tasks = current_stats['total_tasks'] - initial_stats['total_tasks']")
    print("    # elapsed = time.time() - start_time")
    print("    # print(f'ğŸ“Š {elapsed:.1f}ç§’å…§æ–°å¢ä»»å‹™: {new_tasks}å€‹')")
    print("    # print(f'ğŸ“Š å¹³å‡ä»»å‹™é »ç‡: {new_tasks/elapsed:.2f}å€‹/ç§’')")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” AsyncUpdaterè©³ç´°è¨ºæ–·å·¥å…·")
    print("=" * 60)
    
    # 1. å•Ÿç”¨è©³ç´°æ—¥èªŒçš„æŒ‡ä»¤
    enable_async_detailed_logging()
    
    # 2. æª¢æŸ¥æ•¸æ“šåº«ç´„æŸ
    check_database_constraints()
    
    # 3. å³°å€¼æ›´æ–°é‚è¼¯æª¢æŸ¥
    check_peak_update_logic()
    
    # 4. å³°å€¼æ›´æ–°é »ç‡åˆ†æ
    analyze_peak_update_frequency()
    
    print("\nğŸ’¡ è¨ºæ–·å»ºè­°:")
    print("1. å…ˆåŸ·è¡Œä¸Šè¿°ä»£ç¢¼ç‰‡æ®µå•Ÿç”¨è©³ç´°æ—¥èªŒ")
    print("2. è§€å¯ŸConsoleè¼¸å‡ºä¸­çš„å…·é«”éŒ¯èª¤ä¿¡æ¯")
    print("3. æª¢æŸ¥å³°å€¼æ›´æ–°æ˜¯å¦åœ¨éå‰µé«˜æ™‚ä¹Ÿè¢«è§¸ç™¼")
    print("4. ç¢ºèªupdate_reasonå€¼æ˜¯å¦ç¬¦åˆæ•¸æ“šåº«ç´„æŸ")
    print("5. ç›£æ§å³°å€¼æ›´æ–°çš„è§¸ç™¼é »ç‡æ˜¯å¦ç•°å¸¸")

if __name__ == "__main__":
    main()
