#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»»å‹™2ï¼šæ•¸æ“šæºèˆ‡è¼¸å…¥é©—è­‰è…³æœ¬
æª¢æŸ¥ mdd_gui.py å’Œ rev_web_trading_gui.py æ˜¯å¦ä½¿ç”¨ç›¸åŒçš„æ•¸æ“šæº
"""

import os
import sys
import json
import hashlib
from datetime import datetime, time
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å°å…¥å…±äº«æ¨¡çµ„
import shared

def get_database_info():
    """ç²å–æ•¸æ“šåº«é€£æ¥ä¿¡æ¯"""
    try:
        # æª¢æŸ¥æ•¸æ“šåº«æ–‡ä»¶
        db_files = []
        
        # æª¢æŸ¥ç•¶å‰ç›®éŒ„çš„ SQLite æ–‡ä»¶
        current_dir = Path(__file__).parent
        for db_file in current_dir.glob("*.sqlite"):
            stat = db_file.stat()
            db_files.append({
                'path': str(db_file.absolute()),
                'size': stat.st_size,
                'modified': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                'exists': True
            })
        
        return {
            'database_files': db_files,
            'shared_module_path': shared.__file__ if hasattr(shared, '__file__') else 'Unknown'
        }
    except Exception as e:
        return {'error': f'ç²å–æ•¸æ“šåº«ä¿¡æ¯å¤±æ•—: {str(e)}'}

def get_data_sample(start_date="2024-11-04", end_date="2024-11-05", limit=10):
    """ç²å–æ•¸æ“šæ¨£æœ¬é€²è¡Œæ¯”è¼ƒ"""
    try:
        # ä½¿ç”¨èˆ‡å›æ¸¬å¼•æ“ç›¸åŒçš„æ•¸æ“šåº«é€£æ¥æ–¹å¼
        context_manager = shared.get_conn_cur_from_pool_b(as_dict=True)
        
        with context_manager as (conn, cur):
            # ç²å–äº¤æ˜“æ—¥åˆ—è¡¨
            base_query = "SELECT DISTINCT trade_datetime::date as trade_day FROM stock_prices"
            conditions = ["trade_datetime::date >= %s", "trade_datetime::date <= %s"]
            params = [start_date, end_date]
            
            query = f"{base_query} WHERE {' AND '.join(conditions)} ORDER BY trade_day"
            cur.execute(query, tuple(params))
            trade_days = [row['trade_day'] for row in cur.fetchall()]
            
            if not trade_days:
                return {'error': 'æ‰¾ä¸åˆ°æŒ‡å®šæ—¥æœŸç¯„åœçš„æ•¸æ“š'}
            
            # ç²å–ç¬¬ä¸€å€‹äº¤æ˜“æ—¥çš„æ•¸æ“šæ¨£æœ¬
            first_day = trade_days[0]
            cur.execute(
                "SELECT * FROM stock_prices WHERE trade_datetime::date = %s ORDER BY trade_datetime LIMIT %s;", 
                (first_day, limit)
            )
            sample_data = cur.fetchall()
            
            # è¨ˆç®—æ•¸æ“šæŒ‡ç´‹
            data_str = json.dumps(sample_data, default=str, sort_keys=True)
            data_hash = hashlib.md5(data_str.encode()).hexdigest()
            
            return {
                'trade_days_count': len(trade_days),
                'first_trade_day': str(first_day),
                'sample_records_count': len(sample_data),
                'sample_data_head': sample_data[:3] if sample_data else [],
                'sample_data_tail': sample_data[-3:] if len(sample_data) > 3 else [],
                'data_hash': data_hash,
                'query_used': f"SELECT * FROM stock_prices WHERE trade_datetime::date = '{first_day}' ORDER BY trade_datetime LIMIT {limit}"
            }
            
    except Exception as e:
        return {'error': f'ç²å–æ•¸æ“šæ¨£æœ¬å¤±æ•—: {str(e)}'}

def check_data_consistency():
    """æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§"""
    try:
        # æª¢æŸ¥å…©å€‹å›æ¸¬å¼•æ“ä½¿ç”¨çš„æ•¸æ“šæ˜¯å¦ä¸€è‡´
        
        # 1. æª¢æŸ¥ exp_rev_multi_Profit-Funded Risk_å¤šå£.py çš„æ•¸æ“š
        exp_data = get_data_sample()
        
        # 2. æª¢æŸ¥ rev_multi_Profit-Funded Risk_å¤šå£.py çš„æ•¸æ“š
        rev_data = get_data_sample()
        
        # 3. æ¯”è¼ƒæ•¸æ“šæŒ‡ç´‹
        consistency_check = {
            'exp_engine_data': exp_data,
            'rev_engine_data': rev_data,
            'data_hash_match': exp_data.get('data_hash') == rev_data.get('data_hash'),
            'trade_days_match': exp_data.get('trade_days_count') == rev_data.get('trade_days_count')
        }
        
        return consistency_check
        
    except Exception as e:
        return {'error': f'æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥å¤±æ•—: {str(e)}'}

def check_time_filtering():
    """æª¢æŸ¥æ™‚é–“éæ¿¾é‚è¼¯"""
    try:
        context_manager = shared.get_conn_cur_from_pool_b(as_dict=True)
        
        with context_manager as (conn, cur):
            # æ¸¬è©¦ç‰¹å®šæ—¥æœŸçš„æ™‚é–“éæ¿¾
            test_date = "2024-11-04"
            
            # ç²å–å…¨å¤©æ•¸æ“š
            cur.execute(
                "SELECT * FROM stock_prices WHERE trade_datetime::date = %s ORDER BY trade_datetime;", 
                (test_date,)
            )
            all_data = cur.fetchall()
            
            # æ¨¡æ“¬å›æ¸¬å¼•æ“çš„æ™‚é–“éæ¿¾é‚è¼¯
            day_session_candles = [
                c for c in all_data 
                if time(8, 45) <= c['trade_datetime'].time() <= time(13, 45)
            ]
            
            # æ¨¡æ“¬é–‹ç›¤å€é–“éæ¿¾ (08:46-08:47)
            range_start_time_obj = time(8, 46)
            range_end_time_obj = time(8, 47)
            
            candles_range = [
                c for c in day_session_candles
                if range_start_time_obj <= c['trade_datetime'].time() <= range_end_time_obj
            ]
            
            return {
                'test_date': test_date,
                'total_records': len(all_data),
                'day_session_records': len(day_session_candles),
                'range_records': len(candles_range),
                'first_record_time': str(all_data[0]['trade_datetime']) if all_data else None,
                'last_record_time': str(all_data[-1]['trade_datetime']) if all_data else None,
                'range_sample': [
                    {
                        'time': str(c['trade_datetime']),
                        'open': float(c['open_price']),
                        'high': float(c['high_price']),
                        'low': float(c['low_price']),
                        'close': float(c['close_price'])
                    }
                    for c in candles_range[:5]
                ]
            }
            
    except Exception as e:
        return {'error': f'æ™‚é–“éæ¿¾æª¢æŸ¥å¤±æ•—: {str(e)}'}

def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 60)
    print("ä»»å‹™2ï¼šæ•¸æ“šæºèˆ‡è¼¸å…¥é©—è­‰")
    print("=" * 60)
    
    # 1. æª¢æŸ¥æ•¸æ“šåº«ä¿¡æ¯
    print("\n1. æ•¸æ“šåº«ä¿¡æ¯æª¢æŸ¥")
    print("-" * 30)
    db_info = get_database_info()
    print(json.dumps(db_info, indent=2, ensure_ascii=False))
    
    # 2. æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§
    print("\n2. æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥")
    print("-" * 30)
    consistency = check_data_consistency()
    print(json.dumps(consistency, indent=2, ensure_ascii=False))
    
    # 3. æª¢æŸ¥æ™‚é–“éæ¿¾é‚è¼¯
    print("\n3. æ™‚é–“éæ¿¾é‚è¼¯æª¢æŸ¥")
    print("-" * 30)
    time_filter = check_time_filtering()
    print(json.dumps(time_filter, indent=2, ensure_ascii=False))
    
    # 4. ç”Ÿæˆå ±å‘Š
    report = {
        'timestamp': datetime.now().isoformat(),
        'database_info': db_info,
        'data_consistency': consistency,
        'time_filtering': time_filter,
        'summary': {
            'database_accessible': 'error' not in db_info,
            'data_consistent': consistency.get('data_hash_match', False),
            'time_filtering_working': 'error' not in time_filter
        }
    }
    
    # ä¿å­˜å ±å‘Š
    report_file = 'rev_strategy_analysis/ä»»å‹™2_æ•¸æ“šæºé©—è­‰å ±å‘Š.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print("\nâœ… æ•¸æ“šæºé©—è­‰å®Œæˆ")

if __name__ == "__main__":
    main()
