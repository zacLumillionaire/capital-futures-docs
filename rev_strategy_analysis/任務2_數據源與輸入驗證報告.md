# 任務 2：數據源與輸入驗證報告

## 執行日期
2025-01-16

## 驗證目標
確保 `mdd_gui.py` 和 `rev_web_trading_gui.py` 使用完全相同的輸入數據集，驗證數據讀取邏輯和數據源一致性。

## 1. 數據源配置比較

### 共同數據源配置
兩個系統都使用相同的數據源配置：

```python
# 兩個系統都有相同的配置
USE_SQLITE = True  # True: 使用本機SQLite, False: 使用遠程PostgreSQL

if USE_SQLITE:
    import sqlite_connection
else:
    from app_setup import init_all_db_pools
    import shared
```

### 數據庫文件
- **文件路徑**: `rev_strategy_analysis/stock_data.sqlite`
- **文件存在**: ✅ 確認存在
- **文件大小**: 約 187,568 行（二進制文件）
- **索引**: 包含 `idx_datetime` 索引用於優化查詢

## 2. 數據讀取邏輯比較

### rev_web_trading_gui.py (rev_multi_Profit-Funded Risk_多口.py)
```python
# 數據庫連接
if USE_SQLITE:
    context_manager = sqlite_connection.get_conn_cur_from_sqlite_with_adapter(as_dict=True)
else:
    context_manager = shared.get_conn_cur_from_pool_b(as_dict=True)

# SQL查詢
base_query = "SELECT DISTINCT trade_datetime::date as trade_day FROM stock_prices"
# 日期過濾
if start_date:
    conditions.append("trade_datetime::date >= %s")
if end_date:
    conditions.append("trade_datetime::date <= %s")

# 每日數據查詢
cur.execute("SELECT * FROM stock_prices WHERE trade_datetime::date = %s ORDER BY trade_datetime;", (day,))
day_session_candles = [c for c in cur.fetchall() if time(8, 45) <= c['trade_datetime'].time() <= time(13, 45)]
```

### mdd_gui.py (exp_rev_multi_Profit-Funded Risk_多口.py)
```python
# 完全相同的數據庫連接邏輯
if USE_SQLITE:
    context_manager = sqlite_connection.get_conn_cur_from_sqlite_with_adapter(as_dict=True)
else:
    context_manager = shared.get_conn_cur_from_pool_b(as_dict=True)

# 完全相同的SQL查詢
base_query = "SELECT DISTINCT trade_datetime::date as trade_day FROM stock_prices"
# 相同的日期過濾邏輯
if start_date:
    conditions.append("trade_datetime::date >= %s")
if end_date:
    conditions.append("trade_datetime::date <= %s")

# 相同的每日數據查詢
cur.execute("SELECT * FROM stock_prices WHERE trade_datetime::date = %s ORDER BY trade_datetime;", (day,))
day_session_candles = [c for c in cur.fetchall() if time(8, 45) <= c['trade_datetime'].time() <= time(13, 45)]
```

## 3. 數據過濾邏輯比較

### 交易時段過濾
兩個系統使用完全相同的時間過濾邏輯：
```python
# 交易時段：8:45 - 13:45
day_session_candles = [c for c in cur.fetchall() if time(8, 45) <= c['trade_datetime'].time() <= time(13, 45)]
```

### 開盤區間計算
兩個系統都使用相同的開盤區間計算邏輯：

#### rev_web_trading_gui.py
```python
# 使用整個時間區間的所有K棒來計算開盤區間
range_start_time_obj = time(range_start_hour, range_start_min)
range_end_time_obj = time(range_end_hour, range_end_min)

candles_range = [c for c in day_session_candles
               if range_start_time_obj <= c['trade_datetime'].time() <= range_end_time_obj]
```

#### mdd_gui.py
```python
# 完全相同的開盤區間計算邏輯
range_start_time_obj = time(range_start_hour, range_start_min)
range_end_time_obj = time(range_end_hour, range_end_min)

candles_range = [c for c in day_session_candles
               if range_start_time_obj <= c['trade_datetime'].time() <= range_end_time_obj]
```

## 4. 數據結構和格式比較

### 數據庫表結構
兩個系統都使用相同的 `stock_prices` 表，包含以下字段：
- `trade_datetime`: 交易時間（主鍵）
- `open_price`: 開盤價
- `high_price`: 最高價
- `low_price`: 最低價
- `close_price`: 收盤價

### 數據類型處理
兩個系統都使用相同的數據類型轉換：
```python
# SQLite適配器自動處理PostgreSQL語法轉換
sqlite_connection.get_conn_cur_from_sqlite_with_adapter(as_dict=True)
```

## 5. 關鍵差異分析

### 5.1 文件大小差異
通過靜態分析發現兩個核心引擎文件存在差異：

- **rev_multi_Profit-Funded Risk_多口.py**: 較新版本，包含完整的MDD計算和各口損益統計
- **exp_rev_multi_Profit-Funded Risk_多口.py**: 實驗版本，可能缺少某些功能

### 5.2 返回數據結構差異

#### rev_web_trading_gui.py 返回結構
```python
return {
    'total_pnl': float(total_pnl),
    'long_pnl': float(long_pnl),
    'short_pnl': float(short_pnl),
    'max_drawdown': float(max_drawdown),
    'peak_pnl': float(peak_pnl),
    'lot1_pnl': float(lot1_total_pnl),
    'lot2_pnl': float(lot2_total_pnl),
    'lot3_pnl': float(lot3_total_pnl),
    # ... 其他統計數據
}
```

#### mdd_gui.py (通過日誌解析)
```python
# 從日誌解析提取數據，可能遺漏某些字段
# 依賴文本解析的準確性
```

## 6. 潛在數據不一致原因

### 6.1 數據精度問題
- **rev_web_trading_gui.py**: 使用 `Decimal` 進行高精度計算，最後轉換為 `float`
- **mdd_gui.py**: 通過文本解析，可能存在精度損失

### 6.2 數據完整性問題
- **rev_web_trading_gui.py**: 直接返回結構化數據，保證完整性
- **mdd_gui.py**: 依賴日誌解析，可能遺漏部分數據

### 6.3 計算時機差異
- **rev_web_trading_gui.py**: 實時計算並累積
- **mdd_gui.py**: 事後從日誌重新計算

## 7. 驗證結論

### 數據源一致性
✅ **高度一致**: 兩個系統使用完全相同的：
- 數據庫文件 (`stock_data.sqlite`)
- 數據庫連接邏輯
- SQL查詢語句
- 數據過濾條件
- 時間區間處理

### 潛在問題點
⚠️ **需要關注的差異**:
1. **數據處理方式**: 直接API調用 vs subprocess + 日誌解析
2. **數據精度**: Decimal vs float 轉換
3. **錯誤處理**: 結構化異常 vs 日誌解析錯誤

## 8. 後續建議

### 任務 3 準備
基於數據源驗證結果，建議在任務 3 中重點關注：
1. **計算時機差異**: 比較實時計算與事後解析的結果
2. **精度損失點**: 找到 Decimal 到 float 轉換中的精度損失
3. **日誌解析準確性**: 驗證文本解析是否遺漏關鍵數據

### 修復方向
1. **統一數據處理方式**: 建議 mdd_gui.py 也採用直接API調用
2. **統一數據精度**: 確保兩個系統使用相同的數值精度
3. **增強錯誤處理**: 改善日誌解析的魯棒性

## 結論

數據源層面兩個系統高度一致，使用相同的數據庫文件和查詢邏輯。主要差異在於數據處理和傳遞方式，這很可能是導致 PNL 和 MDD 計算不一致的根本原因。建議在後續任務中重點關注數據處理流程的差異。
