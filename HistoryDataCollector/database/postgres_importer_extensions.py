#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PostgreSQLåŒ¯å…¥å™¨æ“´å±•
åŒ…å« Tick å’Œ Best5 è³‡æ–™çš„åŒ¯å…¥æ–¹æ³•
"""

import logging
import sqlite3
import time
from datetime import datetime
from decimal import Decimal

logger = logging.getLogger(__name__)

class PostgreSQLImporterExtensions:
    """PostgreSQLåŒ¯å…¥å™¨æ“´å±•é¡åˆ¥"""
    
    def import_best5_to_postgres(self, symbol='MTX00', batch_size=5000, optimize_performance=True):
        """åŒ¯å…¥äº”æª”è³‡æ–™åˆ°PostgreSQL"""
        if not self.postgres_initialized:
            logger.error("âŒ PostgreSQLæœªåˆå§‹åŒ–ï¼Œç„¡æ³•åŒ¯å…¥")
            return False

        try:
            total_start_time = time.time()
            
            logger.info(f"ğŸš€ é–‹å§‹åŒ¯å…¥ {symbol} äº”æª”è³‡æ–™åˆ°PostgreSQL...")
            logger.info(f"âš¡ æ€§èƒ½å„ªåŒ–æ¨¡å¼: {'é–‹å•Ÿ' if optimize_performance else 'é—œé–‰'}")
            logger.info(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}")
            
            # é€£æ¥SQLiteè®€å–è³‡æ–™
            sqlite_conn = sqlite3.connect(self.sqlite_db_path)
            sqlite_conn.row_factory = sqlite3.Row
            
            # æŸ¥è©¢äº”æª”è³‡æ–™
            query_sql = """
                SELECT * FROM best5_data
                WHERE symbol = ?
                ORDER BY trade_date, trade_time
            """
            logger.info(f"ğŸ” åŸ·è¡ŒSQLiteæŸ¥è©¢: {query_sql.strip()}")
            logger.info(f"ğŸ” æŸ¥è©¢åƒæ•¸: symbol='{symbol}'")

            sqlite_cursor = sqlite_conn.execute(query_sql, (symbol,))
            all_rows = sqlite_cursor.fetchall()
            logger.info(f"ğŸ“Š å¾SQLiteæŸ¥è©¢åˆ° {len(all_rows)} ç­† {symbol} äº”æª”è³‡æ–™")

            if len(all_rows) == 0:
                logger.warning(f"âš ï¸ æ²’æœ‰æ‰¾åˆ° {symbol} äº”æª”è³‡æ–™")
                sqlite_conn.close()
                return False

            # ä½¿ç”¨PostgreSQLé€£æ¥
            import shared
            with shared.get_conn_cur_from_pool_b(as_dict=False) as (pg_conn, pg_cursor):
                
                # æ€§èƒ½å„ªåŒ–è¨­å®š
                if optimize_performance:
                    logger.info("âš¡ å•Ÿç”¨æ€§èƒ½å„ªåŒ–è¨­å®š...")
                    try:
                        pg_cursor.execute("SET synchronous_commit = OFF")
                        pg_cursor.execute("SET work_mem = '256MB'")
                        logger.info("âœ… æ€§èƒ½å„ªåŒ–è¨­å®šå®Œæˆ")
                    except Exception as e:
                        logger.warning(f"âš ï¸ éƒ¨åˆ†æ€§èƒ½è¨­å®šå¤±æ•— (å¯å¿½ç•¥): {e}")
                
                # æª¢æŸ¥best5_pricesè¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡å‰µå»º
                pg_cursor.execute("""
                    CREATE TABLE IF NOT EXISTS best5_prices (
                        trade_datetime timestamp without time zone NOT NULL,
                        symbol varchar(20) NOT NULL,
                        
                        -- äº”æª”è²·åƒ¹è²·é‡
                        bid_price_1 numeric(10,2), bid_volume_1 integer,
                        bid_price_2 numeric(10,2), bid_volume_2 integer,
                        bid_price_3 numeric(10,2), bid_volume_3 integer,
                        bid_price_4 numeric(10,2), bid_volume_4 integer,
                        bid_price_5 numeric(10,2), bid_volume_5 integer,
                        
                        -- äº”æª”è³£åƒ¹è³£é‡
                        ask_price_1 numeric(10,2), ask_volume_1 integer,
                        ask_price_2 numeric(10,2), ask_volume_2 integer,
                        ask_price_3 numeric(10,2), ask_volume_3 integer,
                        ask_price_4 numeric(10,2), ask_volume_4 integer,
                        ask_price_5 numeric(10,2), ask_volume_5 integer,
                        
                        -- å»¶ä¼¸è²·è³£
                        extend_bid numeric(10,2), extend_bid_qty integer,
                        extend_ask numeric(10,2), extend_ask_qty integer,
                        
                        CONSTRAINT pk_best5_prices PRIMARY KEY (trade_datetime, symbol)
                    )
                """)
                logger.info("âœ… ç¢ºèªbest5_pricesè¡¨å­˜åœ¨")
                
                # é å…ˆè½‰æ›æ‰€æœ‰è³‡æ–™
                logger.info("ğŸ”„ é å…ˆè½‰æ›æ‰€æœ‰äº”æª”è³‡æ–™...")
                conversion_start = time.time()
                converted_data = []
                conversion_errors = 0
                
                for row in all_rows:
                    best5_postgres_data = self.convert_best5_to_postgres_format(dict(row))
                    if best5_postgres_data is None:
                        conversion_errors += 1
                        continue
                    converted_data.append(best5_postgres_data)
                
                conversion_time = time.time() - conversion_start
                logger.info(f"âœ… äº”æª”è³‡æ–™è½‰æ›å®Œæˆ (è€—æ™‚: {conversion_time:.2f}ç§’)")
                logger.info(f"ğŸ“Š æˆåŠŸè½‰æ›: {len(converted_data)} ç­†ï¼ŒéŒ¯èª¤: {conversion_errors} ç­†")
                
                if len(converted_data) == 0:
                    logger.warning("âš ï¸ æ²’æœ‰æœ‰æ•ˆçš„äº”æª”è³‡æ–™å¯åŒ¯å…¥")
                    sqlite_conn.close()
                    return False
                
                # æ‰¹é‡è™•ç†è³‡æ–™
                total_inserted = 0
                batch_count = 0
                
                # åˆ†æ‰¹è™•ç†
                for i in range(0, len(converted_data), batch_size):
                    batch_data = converted_data[i:i + batch_size]
                    batch_count += 1
                    
                    batch_start = time.time()
                    inserted_count = self._insert_best5_batch_to_postgres(pg_cursor, batch_data, optimize_performance)
                    batch_time = time.time() - batch_start
                    
                    total_inserted += inserted_count
                    
                    # æ¯å€‹æ‰¹æ¬¡æäº¤
                    pg_conn.commit()
                    
                    # æ¸›å°‘æ—¥èªŒè¼¸å‡ºé »ç‡
                    if batch_count % 5 == 0 or batch_count == 1:
                        logger.info(f"ğŸ“¦ äº”æª”æ‰¹æ¬¡ {batch_count}: {inserted_count}/{len(batch_data)} ç­† (è€—æ™‚: {batch_time:.2f}ç§’)")
                
                # æ¢å¾©æ­£å¸¸è¨­å®š
                if optimize_performance:
                    try:
                        pg_cursor.execute("SET synchronous_commit = ON")
                        logger.info("âœ… å·²æ¢å¾©åŒæ­¥æäº¤è¨­å®š")
                    except:
                        pass
                
                total_time = time.time() - total_start_time
                logger.info(f"âœ… äº”æª”è³‡æ–™åŒ¯å…¥å®Œæˆï¼")
                logger.info(f"ğŸ“Š çµ±è¨ˆçµæœ:")
                logger.info(f"  - ç¸½è™•ç†ç­†æ•¸: {len(all_rows)}")
                logger.info(f"  - æˆåŠŸè½‰æ›: {len(converted_data)}")
                logger.info(f"  - æˆåŠŸæ’å…¥: {total_inserted}")
                logger.info(f"  - è½‰æ›éŒ¯èª¤: {conversion_errors}")
                logger.info(f"  - ç¸½è€—æ™‚: {total_time:.2f}ç§’")
                logger.info(f"  - å¹³å‡é€Ÿåº¦: {total_inserted/total_time:.0f} ç­†/ç§’")
                
            sqlite_conn.close()
            return True
            
        except Exception as e:
            logger.error(f"âŒ åŒ¯å…¥äº”æª”è³‡æ–™éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return False

    def import_all_data_to_postgres(self, symbol='MTX00', batch_size=5000, optimize_performance=True):
        """åŒ¯å…¥æ‰€æœ‰é¡å‹è³‡æ–™åˆ°PostgreSQL"""
        logger.info(f"ğŸš€ é–‹å§‹åŒ¯å…¥ {symbol} æ‰€æœ‰è³‡æ–™åˆ°PostgreSQL...")
        
        results = {
            'kline': False,
            'tick': False,
            'best5': False
        }
        
        # åŒ¯å…¥Kç·šè³‡æ–™
        logger.info("ğŸ“ˆ åŒ¯å…¥Kç·šè³‡æ–™...")
        try:
            results['kline'] = self.import_kline_to_postgres(
                symbol=symbol, 
                kline_type='MINUTE',
                batch_size=batch_size,
                optimize_performance=optimize_performance
            )
        except Exception as e:
            logger.error(f"âŒ Kç·šè³‡æ–™åŒ¯å…¥å¤±æ•—: {e}")
        
        # åŒ¯å…¥é€ç­†è³‡æ–™
        logger.info("ğŸ“Š åŒ¯å…¥é€ç­†è³‡æ–™...")
        try:
            results['tick'] = self.import_tick_to_postgres(
                symbol=symbol,
                batch_size=batch_size,
                optimize_performance=optimize_performance
            )
        except Exception as e:
            logger.error(f"âŒ é€ç­†è³‡æ–™åŒ¯å…¥å¤±æ•—: {e}")
        
        # åŒ¯å…¥äº”æª”è³‡æ–™
        logger.info("ğŸ“‹ åŒ¯å…¥äº”æª”è³‡æ–™...")
        try:
            results['best5'] = self.import_best5_to_postgres(
                symbol=symbol,
                batch_size=batch_size,
                optimize_performance=optimize_performance
            )
        except Exception as e:
            logger.error(f"âŒ äº”æª”è³‡æ–™åŒ¯å…¥å¤±æ•—: {e}")
        
        # ç¸½çµçµæœ
        success_count = sum(1 for success in results.values() if success)
        total_count = len(results)
        
        logger.info(f"âœ… å…¨éƒ¨è³‡æ–™åŒ¯å…¥å®Œæˆï¼")
        logger.info(f"ğŸ“Š åŒ¯å…¥çµæœ: {success_count}/{total_count} æˆåŠŸ")
        logger.info(f"  - Kç·šè³‡æ–™: {'âœ…' if results['kline'] else 'âŒ'}")
        logger.info(f"  - é€ç­†è³‡æ–™: {'âœ…' if results['tick'] else 'âŒ'}")
        logger.info(f"  - äº”æª”è³‡æ–™: {'âœ…' if results['best5'] else 'âŒ'}")
        
        return success_count == total_count

    def get_postgres_data_statistics(self):
        """å–å¾—PostgreSQLè³‡æ–™çµ±è¨ˆ"""
        if not self.postgres_initialized:
            logger.error("âŒ PostgreSQLæœªåˆå§‹åŒ–")
            return None
        
        try:
            import shared
            with shared.get_conn_cur_from_pool_b(as_dict=True) as (pg_conn, pg_cursor):
                stats = {}
                
                # Kç·šè³‡æ–™çµ±è¨ˆ
                try:
                    pg_cursor.execute("SELECT COUNT(*) as count FROM stock_prices")
                    result = pg_cursor.fetchone()
                    stats['kline_count'] = result['count'] if result else 0
                except:
                    stats['kline_count'] = 0
                
                # é€ç­†è³‡æ–™çµ±è¨ˆ
                try:
                    pg_cursor.execute("SELECT COUNT(*) as count FROM tick_prices")
                    result = pg_cursor.fetchone()
                    stats['tick_count'] = result['count'] if result else 0
                except:
                    stats['tick_count'] = 0
                
                # äº”æª”è³‡æ–™çµ±è¨ˆ
                try:
                    pg_cursor.execute("SELECT COUNT(*) as count FROM best5_prices")
                    result = pg_cursor.fetchone()
                    stats['best5_count'] = result['count'] if result else 0
                except:
                    stats['best5_count'] = 0
                
                stats['total_count'] = stats['kline_count'] + stats['tick_count'] + stats['best5_count']
                
                return stats
                
        except Exception as e:
            logger.error(f"âŒ å–å¾—PostgreSQLçµ±è¨ˆè³‡æ–™å¤±æ•—: {e}")
            return None
